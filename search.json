[
  {
    "objectID": "chapters/01-2-Intro_tidyverse.html",
    "href": "chapters/01-2-Intro_tidyverse.html",
    "title": "Loading packages and exploring data",
    "section": "",
    "text": "Now that we have loaded the PISA_2022 data set we can start to explore it.\nYou can check that the tables have loaded correctly by typing the object name and running the line (control|command ⌘ and Enter)\n\nPISA_2022\n\n# A tibble: 613,744 × 83\n   CNT     CNTSCHID CNTSTUID REGION  OECD  LANGTEST_QQQ ST003D02T ST003D03T\n * &lt;fct&gt;      &lt;dbl&gt;    &lt;dbl&gt; &lt;fct&gt;   &lt;fct&gt; &lt;fct&gt;        &lt;fct&gt;     &lt;fct&gt;    \n 1 Albania   800282   800001 Albania No    Albanian     May       2006     \n 2 Albania   800115   800002 Albania No    Albanian     February  2006     \n 3 Albania   800242   800003 Albania No    Albanian     August    2006     \n 4 Albania   800245   800005 Albania No    Albanian     July      2006     \n 5 Albania   800285   800006 Albania No    Albanian     January   2006     \n 6 Albania   800172   800007 Albania No    Albanian     May       2006     \n 7 Albania   800082   800008 Albania No    Albanian     May       2006     \n 8 Albania   800274   800009 Albania No    Albanian     December  2006     \n 9 Albania   800057   800010 Albania No    Albanian     August    2006     \n10 Albania   800132   800012 Albania No    Albanian     September 2006     \n# ℹ 613,734 more rows\n# ℹ 75 more variables: ST004D01T &lt;fct&gt;, ST250Q01JA &lt;fct&gt;, ST250Q02JA &lt;fct&gt;,\n#   ST250Q03JA &lt;fct&gt;, ST250Q05JA &lt;fct&gt;, ST251Q01JA &lt;fct&gt;, ST251Q06JA &lt;fct&gt;,\n#   ST251Q07JA &lt;fct&gt;, ST253Q01JA &lt;fct&gt;, ST254Q01JA &lt;fct&gt;, ST254Q02JA &lt;fct&gt;,\n#   ST254Q03JA &lt;fct&gt;, ST254Q04JA &lt;fct&gt;, ST254Q05JA &lt;fct&gt;, ST254Q06JA &lt;fct&gt;,\n#   ST255Q01JA &lt;fct&gt;, ST256Q02JA &lt;fct&gt;, ST005Q01JA &lt;fct&gt;, ST007Q01JA &lt;fct&gt;,\n#   ST019AQ01T &lt;fct&gt;, ST019BQ01T &lt;fct&gt;, ST019CQ01T &lt;fct&gt;, ST125Q01NA &lt;fct&gt;, …\n\n\nWe can see from this that the tibble (another word for dataframe, basically a spreadsheet table) is 613744 rows, with 83 columns 1. This is data for all the students from around the world that took part in PISA 2022. The actual PISA dataset has many more columns than this, but for the examples here we have selected 83 of the more interesting data variables. The column names might seem rather confusing and you might want to refer to the PISA 2022 code book to find out what everything means.\nThe data shown in the console window is only the top few rows and first few columns. To see the whole table click on the Environment panel and the table icon  to explore the table:\n\nAlternatively, you can also hold down command ⌘|control and click on the table name in your R Script to view the table. You can also type View(&lt;table_name&gt;). Note: this has a capital “V”\nIn the table view mode you can read the label attached to each column, this will give you more detail about what the column stores. If you hover over columns it will display the label:\n\nAlternatively, to read the full label of a column, the following code can be used:\n\n# You might also want to read the label of a field\nattr(PISA_2022$ST324Q11JA, \"label\")\n\n[1] \"Agree/disagree: School has been a waste of time.\"\n\n\nEach view only shows you 50 columns, to see more use the navigation panel:\n\n\n\n\n\n\n\nNote\n\n\n\nTo learn more about loading data from in other formats, e.g. SPSS and STATA, look at the tidyverse documentation for haven.\n\n\nThe PISA_2022 dataframe is made up of multiple columns, with each column acting like a vector, which means each column stores values of only one datatype. If we look at the first four columns of the schools table, you can see the CNTSTUID, ESCS and PV1MATH columns are &lt;dbl&gt; (numeric) and the other three columns are of &lt;fctr&gt; (factor), a special datatype in R that helps store categorical and ordinal variables, see Chapter 10 for more information on how factors work.\n\n\n# A tibble: 5 × 5\n  CNTSTUID ST004D01T CNT       ESCS PV1MATH\n     &lt;dbl&gt; &lt;fct&gt;     &lt;fct&gt;    &lt;dbl&gt;   &lt;dbl&gt;\n1   800001 Female    Albania  1.11     180.\n2   800002 Male      Albania -3.05     308.\n3   800003 Male      Albania -0.187    268.\n4   800005 Female    Albania -3.22     273.\n5   800006 Female    Albania -1.05     435.\n\n\n\n\n\n\n\n\nNote\n\n\n\nVectors are data structures that bring together one or more data elements of the same datatype. E.g. we might have a numeric vector recording the grades of a class, or a character vector storing the gender of a set of students. To define a vector we use c(item, item, ...), where c stands for combine. Vectors are very important to R, even declaring a single object, x &lt;- 6, is creating a vector of size one. To find out more about vectors see: ?@sec-vectors\n\n\nWe can find out some general information about the table we have loaded. nrow and ncol tell you about the dimensions of the table\n\nnrow(PISA_2022)  # how many rows are in the results table\n\n[1] 613744\n\nncol(PISA_2022)  # how many columns are in the results table\n\n[1] 83\n\n\nIf we want to know the names of the columns we can use the names() command that returns a vector. This can be a little confusing as it’ll return the names used in the dataframe, which can be hard to interpret, e.g. ST004D01T is PISA’s way of encoding gender. You might find the labels in the view of the table available through View(PISA_2022) (note: the capital V in View) and the Environment panel easier to navigate:\n\nnames(PISA_2022) # the column names of a table\n\n [1] \"CNT\"          \"CNTSCHID\"     \"CNTSTUID\"     \"REGION\"       \"OECD\"        \n [6] \"LANGTEST_QQQ\" \"ST003D02T\"    \"ST003D03T\"    \"ST004D01T\"    \"ST250Q01JA\"  \n[11] \"ST250Q02JA\"   \"ST250Q03JA\"   \"ST250Q05JA\"   \"ST251Q01JA\"   \"ST251Q06JA\"  \n[16] \"ST251Q07JA\"   \"ST253Q01JA\"   \"ST254Q01JA\"   \"ST254Q02JA\"   \"ST254Q03JA\"  \n[21] \"ST254Q04JA\"   \"ST254Q05JA\"   \"ST254Q06JA\"   \"ST255Q01JA\"   \"ST256Q02JA\"  \n[26] \"ST005Q01JA\"   \"ST007Q01JA\"   \"ST019AQ01T\"   \"ST019BQ01T\"   \"ST019CQ01T\"  \n[31] \"ST125Q01NA\"   \"ST261Q01JA\"   \"ST261Q04JA\"   \"ST062Q02TA\"   \"ST038Q08NA\"  \n[36] \"ST016Q01NA\"   \"ST337Q07JA\"   \"ST324Q11JA\"   \"ST355Q03JA\"   \"FL150Q02TA\"  \n [ reached getOption(\"max.print\") -- omitted 43 entries ]\n\n\nAs mentioned, the columns in the tables are very much like a collection of vectors, to access these columns we can put a $ [dollar sign] after the name of a table. This allows us to see all the columns that table has, using the up and down arrows to select, press the Tab key to complete:\n\n\nPISA_2022$ST038Q08NA\n\n [1] Never or almost never A few times a year    &lt;NA&gt;                 \n [4] A few times a month   Never or almost never Never or almost never\n [7] Never or almost never Never or almost never Never or almost never\n[10] &lt;NA&gt;                  Never or almost never &lt;NA&gt;                 \n[13] Once a week or more   Never or almost never Never or almost never\n[16] Never or almost never Never or almost never Never or almost never\n[19] A few times a month   Never or almost never &lt;NA&gt;                 \n[22] Never or almost never Never or almost never Never or almost never\n[25] &lt;NA&gt;                  Never or almost never Never or almost never\n[28] Never or almost never Never or almost never Never or almost never\n[31] A few times a year    Never or almost never Never or almost never\n[34] Never or almost never Never or almost never Never or almost never\n[37] Never or almost never &lt;NA&gt;                  Once a week or more  \n[40] Never or almost never\n [ reached getOption(\"max.print\") -- omitted 613704 entries ]\nattr(,\"label\")\n[1] In past 12 months, how often: Other students spread nasty rumours about me.\n8 Levels: Never or almost never A few times a year ... No Response\n\n\nWe can apply functions to the returned column/vector, for example: sum, mean, median, max, min, sd, round, unique, summary, length. To find all the different/unique values contained in a column we can write:\n\nunique(PISA_2022$CNT) # the unique values in this column\n\n [1] Albania               Baku (Azerbaijan)     Argentina            \n [4] Australia             Austria               Belgium              \n [7] Brazil                Brunei Darussalam     Bulgaria             \n[10] Cambodia              Canada                Chile                \n[13] Chinese Taipei        Colombia              Costa Rica           \n[16] Croatia               Czech Republic        Denmark              \n[19] Dominican Republic    El Salvador           Estonia              \n[22] Finland               France                Georgia              \n[25] Palestinian Authority Germany               Greece               \n[28] Guatemala             Hong Kong (China)     Hungary              \n[31] Iceland               Indonesia             Ireland              \n[34] Israel                Italy                 Kosovo               \n[37] Jamaica               Japan                 Kazakhstan           \n[40] Jordan               \n [ reached getOption(\"max.print\") -- omitted 40 entries ]\n81 Levels: Albania United Arab Emirates Argentina Australia Austria ... Viet Nam\n\n\nWe can also combine commands, with length(&lt;vector&gt;) telling you how many items are in the unique(PISA_2022$CNT) command\n\n# tells you the number of countries in PISA 2022\nlength(unique(PISA_2022$CNT))\n\n[1] 80\n\n\nYou might meet errors when you try and run some of the commands because a field has missing data, recorded as NA. In the case below it doesn’t know what to do with the NA values in ESCS, so it gives up and returns NA:\n\nmax(PISA_2022$ESCS) # max cultural capital value for all students\n\n[1] NA\n\n\nYou can see one of the NAs by just looking at this column:\n\nPISA_2022$ESCS # NAs present in data\n\n [1]  1.1112 -3.0507 -0.1867 -3.2198 -1.0548  1.0855 -0.7623 -1.0237 -1.1697\n[10]  0.2857 -1.9799  0.0630 -0.1699 -2.5828 -1.1781 -0.5965 -1.0903  0.7457\n[19] -0.8850 -1.6258 -0.3345 -2.0967 -1.1041 -1.0403      NA  0.3638 -2.7519\n[28] -0.1190 -1.2030 -0.4250 -0.1505 -1.7077 -1.6741 -1.0123 -1.0653 -0.4197\n[37] -1.7776 -0.2216 -1.1821  0.3523\n [ reached getOption(\"max.print\") -- omitted 613704 entries ]\nattr(,\"label\")\n[1] \"Index of economic, social and cultural status\"\n\n\nTo get around this you can tell R to remove the NA values when performing maths calculations:\n\n# max cultural capital score for all students\nmax(PISA_2022$ESCS, na.rm = TRUE) \n\n[1] 7.38\n\n\n\n\n\n\n\n\nTip\n\n\n\nR’s inbuilt mode function doesn’t calculate the mathematical mode, instead it tells you what type of data you are dealing with. You can work out the mode of data by using the modeest package:\n\nlibrary(modeest)\nmlv(PISA_2022$PV1MATH, method = \"mfv\", na.rm = TRUE)\n\n[1] 386.086\n\n\nThere is more discussion on how to use modes in R here\n\n\nCalculations might also be upset when you try to perform maths on a column that you think is a number but is actually stored as another datatype. For example if you wanted to work out the mean number of “How many [digital devices] with screens are there in your [home]?” - ST253Q01JA:\n\nmean(PISA_2022$ST253Q01JA, na.rm=TRUE)\n\n[1] NA\n\n\nLooking at the structure of this column, we can see it is stored as a factor, not as a numeric. Factors are a special datatype that use numbers to link to categorical values. For ST253Q01JA there are 12 different levels that you can explore using the str() and levels() commands:\n\nstr(PISA_2022$ST253Q01JA)\n\n Factor w/ 12 levels \"There are no &lt;digital devices&gt; with screens.\",..: 8 2 8 2 7 8 7 NA 6 7 ...\n - attr(*, \"label\")= chr \"How many [digital devices] with screens are there in your [home]?\"\n\nlevels(PISA_2022$ST253Q01JA)\n\n [1] \"There are no &lt;digital devices&gt; with screens.\"\n [2] \"One\"                                         \n [3] \"Two\"                                         \n [4] \"Three\"                                       \n [5] \"Four\"                                        \n [6] \"Five\"                                        \n [7] \"6 to 10\"                                     \n [8] \"More than 10\"                                \n [9] \"Valid Skip\"                                  \n[10] \"Not Applicable\"                              \n[11] \"Invalid\"                                     \n[12] \"No Response\"                                 \n\n\nYou can change the type of the column to make it work with the mean command, changing the column to as.numeric(&lt;column&gt;) for the calculation:\n\n# note: this isn't ideal for proper analysis!\nmean(as.numeric(PISA_2022$ST253Q01JA), na.rm = TRUE)\n\n[1] 6.312233\n\n\nThis is far from ideal as we are now treating a categorical field as a numeric! Looking at the coding for the numbers in the field and the corresponding levels, we see that 1 is actually no digital devices. For more details on datatypes, see ?@sec-datatypes.\n\npaste(1:length(levels(PISA_2022$ST253Q01JA)), \":\", levels(PISA_2022$ST253Q01JA))\n\n [1] \"1 : There are no &lt;digital devices&gt; with screens.\"\n [2] \"2 : One\"                                         \n [3] \"3 : Two\"                                         \n [4] \"4 : Three\"                                       \n [5] \"5 : Four\"                                        \n [6] \"6 : Five\"                                        \n [7] \"7 : 6 to 10\"                                     \n [8] \"8 : More than 10\"                                \n [9] \"9 : Valid Skip\"                                  \n[10] \"10 : Not Applicable\"                             \n[11] \"11 : Invalid\"                                    \n[12] \"12 : No Response\"                                \n\n\n\n\n\n\n\n\nTip\n\n\n\nTo get a good overview of what a table contains, you can use the str(&lt;table_name&gt;) and summary(&lt;table_name&gt;) commands.\n\n\n\n\n\nUsing the PISA_2022 dataset:\n\nUse the Environment window to view the dataset, what is the name and the label of the 26th column?\n\n\n\nanswer\n# the 26th column is ST005Q01JA\n#\"What is the [highest level of schooling] completed by your mother?\"\n\n# you could use View() instead of the environment window, note the capital V\nView(PISA_2022)\n# use could use the vector subset to fetch the 100th name\nnames(PISA_2022)[26]\n# [1] \"ST005Q01JA\"\n\n# you could use the attr function to find the label\nattr(PISA_2022$ST005Q01JA, \"label\")\n# \"What is the [highest level of schooling] completed by your mother?\"\n\n# or using the dollar sign to load this field will also give the label\nPISA_2022$ST005Q01JA\n\n\n\nUse the dollar sign $ to return the column ST004D01T. What is stored in this column?\n\n\n\nanswer\n# Student (Standardized) Gender\nPISA_2022$ST004D01T\n\n#  [1] Female Male   Male   Female Female Male   Male   Female Female Female Male  \n#  [12] Male   Male   Male   Female Female Male   Female Female Female Male   Male  \n#  [23] Male   Female Female Female Female Female Male   Female Male   Male   Male  \n#  [34] Female Female Male   Female Female Female Female Female Male   Female Male  \n#   [ reached getOption(\"max.print\") -- omitted 612744 entries ]\n# attr(,\"label\")\n# [1] Student (Standardized) Gender\n# Levels: Female Male Valid Skip Not Applicable Invalid No Response\n\n\n\nHow many students results are in the whole table?\n\n\n\nanswer\nnrow(PISA_2022)\n# [1] 613744\n\n\n\nWhat unique values does the dataset hold for Mother’s occupation OCOD1 and Father’s occupation OCOD2? Which is larger?\n\n\n\nanswer\nunique(PISA_2022$OCOD1)\nunique(PISA_2022$OCOD2)\n\n# you can read the length from the above, or you could use the\n# length command to tell you the length of the vector\n\nlength(unique(PISA_2022$OCOD1))\n# [1] 590\nlength(unique(PISA_2022$OCOD2))\n# [1] 590\n\n# Both fields are the same size implying there are no jobs that women do, but men don't.\n# to confirm this we can use the set difference command `setdiff(vector1, vector2)`.\n\nsetdiff(unique(PISA_2022$OCOD1),\n        unique(PISA_2022$OCOD2))\n# character(0)\n\n\n\nWhat are the maximum, mean, median and minumum science grades PV1SCIE achieved by any student\n\n\n\nanswer\n# remember to set the na.rm = TRUE\nmax(PISA_2022$PV1SCIE, na.rm=TRUE)\n# [1] 895.375\nmean(PISA_2022$PV1SCIE, na.rm=TRUE)\n# [1] 450.4625\nmedian(PISA_2022$PV1SCIE, na.rm=TRUE)\n# [1] 444.464\nmin(PISA_2022$PV1SCIE, na.rm=TRUE)\n# [1] 0\n\n\n\nExplore the dataset and makes notes about the range of values of 2 other columns\n\n\n\n\n\nPiping allows us to break down complex tasks into manageable chunks that can be written and tested one after another. There are several powerful commands in the tidyverse as part of the dplyr package that can help us group, filter, select, mutate and summarise datasets. With this small set of commands we can use piping to convert massive datasets into simple and useful results.\nUsing the pipe %&gt;% command, we can feed the results from one command into the next command making for reusable and easy to read code.\n\n\n\nhow piping works\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe pipe command we are using %&gt;% is from the magrittr package which is installed alongside the tidyverse. Recently R introduced another pipe |&gt; which offers very similar functionality and tutorials online might use either. The examples below use the %&gt;% pipe.\n\n\nLet’s look at an example of using the pipe on the PISA_2022 table to calculate the best performing OECD countries for maths PV1MATH by gender ST004D01T:\n\n1PISA_2022 %&gt;%\n2  filter(OECD == \"Yes\") %&gt;%\n3  group_by(CNT, ST004D01T) %&gt;%\n4  summarise(mean_maths = mean(PV1MATH, na.rm=TRUE),\n            sd_maths = sd(PV1MATH, na.rm=TRUE),       \n            students = n()) %&gt;%                       \n5  filter(!is.na(ST004D01T)) %&gt;%\n6  arrange(desc(mean_maths))\n\n\n1\n\nline 1 passes the whole PISA_2022 dataset and pipes it into the next line using %&gt;%\n\n2\n\nline 2 filters out any results that are from non-OECD countries by finding all the rows where OECD equals == “Yes”, this is then piped to the next line\n\n3\n\nline 3 groups the data by country CNT and by student gender ST004D01T, this is then piped to the next line\n\n4\n\nline 4-6 the summarise command performs a calculation on the country and gender groupings returning three new columns, each command is described by code on a new line and separated by a comma: the mean value for maths mean_maths, the standard deviation sd_maths, and a column telling us how many students were in each grouping using the n() which returns the number of rows in a group. These new columns and the grouping columns are then piped to the next line, all other columns are dropped\n\n5\n\nline 7 filters out any gender ST004D01T that is NA. First is finds all the students that have NA as their gender by using is.na(ST004D01T), then it NOTs/flips the result using the exclamation mark !, giving those students who don’t have their gender set to NA. The filtered data is then piped to the next line\n\n6\n\nline 8, finally we arrange/sort the results in descending order by the mean_maths column. The default for arrange is ascending order, leave out the desc(  ) for the numbers to be ordered in the opposite way.\n\n\n\n\n# A tibble: 74 × 5\n# Groups:   CNT [37]\n   CNT            ST004D01T mean_maths sd_maths students\n   &lt;fct&gt;          &lt;fct&gt;          &lt;dbl&gt;    &lt;dbl&gt;    &lt;int&gt;\n 1 Japan          Male            540.     99.0     2856\n 2 Korea          Male            534.    112.      3325\n 3 Japan          Female          531.     88.1     2904\n 4 Korea          Female          528.     99.1     3129\n 5 Estonia        Male            515.     87.4     3272\n 6 Switzerland    Male            511.     99.3     3540\n 7 Estonia        Female          510.     81.5     3120\n 8 Czech Republic Male            502.    100.      4232\n 9 Switzerland    Female          501.     90.9     3289\n10 Austria        Male            500.     94.5     3110\n# ℹ 64 more rows\n\n\nAcross the top few countries, Males get a slightly better maths score PV1MATH than Females, other scores are available, please read ?@sec-PV to find out more about the limitations of using a “PV” value.\n\n\n\n\n\n\nNote\n\n\n\nwe met the assignment command earlier &lt;-. Within the tidyverse commands we use the equals sign instead =.\n\n\nThe commands we have just used come from a package within the tidyverse called dplyr, let’s take a look at what they do:\n\n\n\n\n\n\n\n\ncommand\npurpose\nexample\n\n\n\n\nselect\nreduce the dataframe to the fields that you specify\nselect(&lt;field&gt;, &lt;field&gt;, &lt;field&gt;)\n\n\nfilter\nget rid of rows that don’t meet one or more criteria\nfilter(&lt;field&gt; &lt;comparison&gt;)\n\n\ngroup\ngroup fields together to perform calculations\ngroup_by(&lt;field&gt;, &lt;field&gt;))\n\n\nmutate\nadd new fields or change values in current fields\nmutate(&lt;new_field&gt; = &lt;field&gt; / 2)\n\n\nsummarise\ncreate summary data optionally using a grouping command\nsummarise(&lt;new_field&gt; = max(&lt;field&gt;))\n\n\narrange\norder the results by one or more fields\narrange(desc(&lt;field&gt;))\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nIf you want to explore more of the functions of dplyr, take a look at the helpsheet\n\n\n\nAdjust the code above to find out the lowest performing countries for reading PV1READ by gender that are not in the OECD\n\n\nanswer\nPISA_2022 %&gt;% \n  filter(OECD == \"No\") %&gt;%\n  group_by(CNT, ST004D01T) %&gt;% \n  summarise(mean_read = mean(PV1READ, na.rm=TRUE),\n            sd_read = sd(PV1READ, na.rm=TRUE),\n            students = n()) %&gt;%\n  filter(!is.na(ST004D01T)) %&gt;%\n  arrange(mean_read)",
    "crumbs": [
      "Introduction to R",
      "Loading packages and exploring data"
    ]
  },
  {
    "objectID": "chapters/01-2-Intro_tidyverse.html#questions",
    "href": "chapters/01-2-Intro_tidyverse.html#questions",
    "title": "Loading packages and exploring data",
    "section": "",
    "text": "Using the PISA_2022 dataset:\n\nUse the Environment window to view the dataset, what is the name and the label of the 26th column?\n\n\n\nanswer\n# the 26th column is ST005Q01JA\n#\"What is the [highest level of schooling] completed by your mother?\"\n\n# you could use View() instead of the environment window, note the capital V\nView(PISA_2022)\n# use could use the vector subset to fetch the 100th name\nnames(PISA_2022)[26]\n# [1] \"ST005Q01JA\"\n\n# you could use the attr function to find the label\nattr(PISA_2022$ST005Q01JA, \"label\")\n# \"What is the [highest level of schooling] completed by your mother?\"\n\n# or using the dollar sign to load this field will also give the label\nPISA_2022$ST005Q01JA\n\n\n\nUse the dollar sign $ to return the column ST004D01T. What is stored in this column?\n\n\n\nanswer\n# Student (Standardized) Gender\nPISA_2022$ST004D01T\n\n#  [1] Female Male   Male   Female Female Male   Male   Female Female Female Male  \n#  [12] Male   Male   Male   Female Female Male   Female Female Female Male   Male  \n#  [23] Male   Female Female Female Female Female Male   Female Male   Male   Male  \n#  [34] Female Female Male   Female Female Female Female Female Male   Female Male  \n#   [ reached getOption(\"max.print\") -- omitted 612744 entries ]\n# attr(,\"label\")\n# [1] Student (Standardized) Gender\n# Levels: Female Male Valid Skip Not Applicable Invalid No Response\n\n\n\nHow many students results are in the whole table?\n\n\n\nanswer\nnrow(PISA_2022)\n# [1] 613744\n\n\n\nWhat unique values does the dataset hold for Mother’s occupation OCOD1 and Father’s occupation OCOD2? Which is larger?\n\n\n\nanswer\nunique(PISA_2022$OCOD1)\nunique(PISA_2022$OCOD2)\n\n# you can read the length from the above, or you could use the\n# length command to tell you the length of the vector\n\nlength(unique(PISA_2022$OCOD1))\n# [1] 590\nlength(unique(PISA_2022$OCOD2))\n# [1] 590\n\n# Both fields are the same size implying there are no jobs that women do, but men don't.\n# to confirm this we can use the set difference command `setdiff(vector1, vector2)`.\n\nsetdiff(unique(PISA_2022$OCOD1),\n        unique(PISA_2022$OCOD2))\n# character(0)\n\n\n\nWhat are the maximum, mean, median and minumum science grades PV1SCIE achieved by any student\n\n\n\nanswer\n# remember to set the na.rm = TRUE\nmax(PISA_2022$PV1SCIE, na.rm=TRUE)\n# [1] 895.375\nmean(PISA_2022$PV1SCIE, na.rm=TRUE)\n# [1] 450.4625\nmedian(PISA_2022$PV1SCIE, na.rm=TRUE)\n# [1] 444.464\nmin(PISA_2022$PV1SCIE, na.rm=TRUE)\n# [1] 0\n\n\n\nExplore the dataset and makes notes about the range of values of 2 other columns",
    "crumbs": [
      "Introduction to R",
      "Loading packages and exploring data"
    ]
  },
  {
    "objectID": "chapters/01-2-Intro_tidyverse.html#piping-and-dplyr",
    "href": "chapters/01-2-Intro_tidyverse.html#piping-and-dplyr",
    "title": "Loading packages and exploring data",
    "section": "",
    "text": "Piping allows us to break down complex tasks into manageable chunks that can be written and tested one after another. There are several powerful commands in the tidyverse as part of the dplyr package that can help us group, filter, select, mutate and summarise datasets. With this small set of commands we can use piping to convert massive datasets into simple and useful results.\nUsing the pipe %&gt;% command, we can feed the results from one command into the next command making for reusable and easy to read code.\n\n\n\nhow piping works\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe pipe command we are using %&gt;% is from the magrittr package which is installed alongside the tidyverse. Recently R introduced another pipe |&gt; which offers very similar functionality and tutorials online might use either. The examples below use the %&gt;% pipe.\n\n\nLet’s look at an example of using the pipe on the PISA_2022 table to calculate the best performing OECD countries for maths PV1MATH by gender ST004D01T:\n\n1PISA_2022 %&gt;%\n2  filter(OECD == \"Yes\") %&gt;%\n3  group_by(CNT, ST004D01T) %&gt;%\n4  summarise(mean_maths = mean(PV1MATH, na.rm=TRUE),\n            sd_maths = sd(PV1MATH, na.rm=TRUE),       \n            students = n()) %&gt;%                       \n5  filter(!is.na(ST004D01T)) %&gt;%\n6  arrange(desc(mean_maths))\n\n\n1\n\nline 1 passes the whole PISA_2022 dataset and pipes it into the next line using %&gt;%\n\n2\n\nline 2 filters out any results that are from non-OECD countries by finding all the rows where OECD equals == “Yes”, this is then piped to the next line\n\n3\n\nline 3 groups the data by country CNT and by student gender ST004D01T, this is then piped to the next line\n\n4\n\nline 4-6 the summarise command performs a calculation on the country and gender groupings returning three new columns, each command is described by code on a new line and separated by a comma: the mean value for maths mean_maths, the standard deviation sd_maths, and a column telling us how many students were in each grouping using the n() which returns the number of rows in a group. These new columns and the grouping columns are then piped to the next line, all other columns are dropped\n\n5\n\nline 7 filters out any gender ST004D01T that is NA. First is finds all the students that have NA as their gender by using is.na(ST004D01T), then it NOTs/flips the result using the exclamation mark !, giving those students who don’t have their gender set to NA. The filtered data is then piped to the next line\n\n6\n\nline 8, finally we arrange/sort the results in descending order by the mean_maths column. The default for arrange is ascending order, leave out the desc(  ) for the numbers to be ordered in the opposite way.\n\n\n\n\n# A tibble: 74 × 5\n# Groups:   CNT [37]\n   CNT            ST004D01T mean_maths sd_maths students\n   &lt;fct&gt;          &lt;fct&gt;          &lt;dbl&gt;    &lt;dbl&gt;    &lt;int&gt;\n 1 Japan          Male            540.     99.0     2856\n 2 Korea          Male            534.    112.      3325\n 3 Japan          Female          531.     88.1     2904\n 4 Korea          Female          528.     99.1     3129\n 5 Estonia        Male            515.     87.4     3272\n 6 Switzerland    Male            511.     99.3     3540\n 7 Estonia        Female          510.     81.5     3120\n 8 Czech Republic Male            502.    100.      4232\n 9 Switzerland    Female          501.     90.9     3289\n10 Austria        Male            500.     94.5     3110\n# ℹ 64 more rows\n\n\nAcross the top few countries, Males get a slightly better maths score PV1MATH than Females, other scores are available, please read ?@sec-PV to find out more about the limitations of using a “PV” value.\n\n\n\n\n\n\nNote\n\n\n\nwe met the assignment command earlier &lt;-. Within the tidyverse commands we use the equals sign instead =.\n\n\nThe commands we have just used come from a package within the tidyverse called dplyr, let’s take a look at what they do:\n\n\n\n\n\n\n\n\ncommand\npurpose\nexample\n\n\n\n\nselect\nreduce the dataframe to the fields that you specify\nselect(&lt;field&gt;, &lt;field&gt;, &lt;field&gt;)\n\n\nfilter\nget rid of rows that don’t meet one or more criteria\nfilter(&lt;field&gt; &lt;comparison&gt;)\n\n\ngroup\ngroup fields together to perform calculations\ngroup_by(&lt;field&gt;, &lt;field&gt;))\n\n\nmutate\nadd new fields or change values in current fields\nmutate(&lt;new_field&gt; = &lt;field&gt; / 2)\n\n\nsummarise\ncreate summary data optionally using a grouping command\nsummarise(&lt;new_field&gt; = max(&lt;field&gt;))\n\n\narrange\norder the results by one or more fields\narrange(desc(&lt;field&gt;))\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nIf you want to explore more of the functions of dplyr, take a look at the helpsheet\n\n\n\nAdjust the code above to find out the lowest performing countries for reading PV1READ by gender that are not in the OECD\n\n\nanswer\nPISA_2022 %&gt;% \n  filter(OECD == \"No\") %&gt;%\n  group_by(CNT, ST004D01T) %&gt;% \n  summarise(mean_read = mean(PV1READ, na.rm=TRUE),\n            sd_read = sd(PV1READ, na.rm=TRUE),\n            students = n()) %&gt;%\n  filter(!is.na(ST004D01T)) %&gt;%\n  arrange(mean_read)",
    "crumbs": [
      "Introduction to R",
      "Loading packages and exploring data"
    ]
  },
  {
    "objectID": "chapters/01-2-Intro_tidyverse.html#questions-1",
    "href": "chapters/01-2-Intro_tidyverse.html#questions-1",
    "title": "Loading packages and exploring data",
    "section": "2.1 Questions",
    "text": "2.1 Questions\n\n\nSpot the three errors with the following select statement\n\n\nPISA_2022 \n  select(CNT BELONG) %&gt;%\n\n\n\nanswer\nPISA_2022 %&gt;%  #1 missing pipe\n  select(CNT, BELONG) #2 no comma between column names, #3 stray pipe on end\n\n\n\nWrite a select statement to display the month ST003D02T and year of birth ST003D03T and the gender ST004D01T of each student.\n\n\n\nanswer\nPISA_2022 %&gt;% \n  select(ST003D02T, ST003D03T, ST004D01T)\n\n\n\nWrite a select statement to show all the fields that are to do with well being and health, e.g. WB150Q01HA “How is your health?”\n\n\n\nanswer\nPISA_2022 %&gt;% \n  select(starts_with(\"WB15\"))\n\n\n\n[EXTENSION] Adjust your answer to Q3 so that you select the gender ST004D01T and the ID CNTSTUID of each student in addition to the ST254____ fields looking at digital devices in the home:\n\n\n\nanswer\nPISA_2022 %&gt;% \n  select(CNTSTUID, ST004D01T, starts_with(\"ST254\")) %&gt;% na.omit()",
    "crumbs": [
      "Introduction to R",
      "Loading packages and exploring data"
    ]
  },
  {
    "objectID": "chapters/01-2-Intro_tidyverse.html#questions-2",
    "href": "chapters/01-2-Intro_tidyverse.html#questions-2",
    "title": "Loading packages and exploring data",
    "section": "3.1 Questions",
    "text": "3.1 Questions\n\n\nSpot the two errors with the following select statement\n\n\nPISA_2022\n  select(CNT, PV1READ) %&gt;%\n  filter(CNT = \"Finland\")\n\n\n\nanswer\nPISA_2022 %&gt;%  #1 missing pipe command\n  select(CNT, PV1READ) %&gt;%\n  filter(CNT == \"Finland\") #2 you need a double equals\n\n\n\nUse filter to find all the students with PV1READ grade equal to 333.\n\n\n\nanswer\nPISA_2022 %&gt;% \n  filter(PV1READ == 333)\n\n\n\nUse filter to find all the students with PV1READ, PV1SCIE, and PV1MATH grades over 800.\n\n\n\nanswer\nPISA_2022 %&gt;% \n  filter(PV1READ &gt; 800,\n         PV1SCIE &gt; 800,\n         PV1MATH &gt; 800)\n\n\n\nSpot the three errors with the following select statement\n\n\nPISA_2022 %&gt;% \n  select(CNT) %&gt;%\n  filter(CNT in c(\"France\", \"belgium\")\n         ESCS &lt; 0)\n\n\n\nanswer\nPISA_2022 %&gt;% \n  select(CNT, ESCS) %&gt;% #1 you have ESCS in the filter, it needs to be in the select as well\n  filter(CNT %in% c(\"France\", \"Belgium\"), #2 Belgium needs a capital letter\n                                          #3 the %in% command needs percentages\n                                          #4 you need a comma (or &) at the end of the line\n         ESCS &lt; 0)\n\n\n\nUse filter to find all the students with Three or more cars in their home ST251Q01JA. How does this compare to those with no None cars?\n\n\n\nanswer\n# cars 3+ \nPISA_2022 %&gt;%\n  select(CNT, ST251Q01JA) %&gt;%\n  filter(ST251Q01JA == \"Three or more\")\n\n# cars 0\nPISA_2022 %&gt;%\n  select(CNT, ST251Q01JA) %&gt;%\n  filter(ST251Q01JA == \"None\")\n\n\n\nAdjust your code in Q2. to find the number of students with Three or more cars in their home ST251Q01JA in Italy, how does this compare with Spain?\n\n\n\nanswer\nPISA_2022 %&gt;%\n  select(CNT, ST251Q01JA) %&gt;%\n  filter(ST251Q01JA == \"Three or more\",\n         CNT == \"Italy\")\n\nPISA_2022 %&gt;%\n  select(CNT, ST251Q01JA) %&gt;%\n  filter(ST251Q01JA == \"Three or more\",\n         CNT == \"Spain\")\n\n# EXTENSION:\n# Note we would need to know the percentage of students \n# in each country with that number of cars to make a proper\n# comparison. Spain might have more students taking the PISA\n# test than Italy, or vice-versa\n\nPISA_2022 %&gt;%\n  select(CNT, ST251Q01JA) %&gt;%\n  filter(CNT %in% c(\"Italy\", \"Spain\")) %&gt;%\n  group_by(CNT) %&gt;%\n  mutate(total_stus = n()) %&gt;%\n  filter(ST251Q01JA == \"Three or more\") %&gt;%\n  summarise(three_more = n(),\n            per_three_more = three_more/unique(total_stus))\n\n\n\nWrite a filter to create a table for the number of Female students with reading PV1READ scores lower than 400 in the United Kingdom, store the result as read_low_female, repeat but for Male students and store as read_low_male. Use nrow() to work out if there are more males or females with a low reading score in the UK\n\n\n\nanswer\nread_low_female &lt;- PISA_2022 %&gt;% \n  filter(CNT == \"United Kingdom\",\n         PV1READ &lt; 400,\n         ST004D01T == \"Female\")\n\nread_low_male &lt;- PISA_2022 %&gt;% \n  filter(CNT == \"United Kingdom\",\n         PV1READ &lt; 400,\n         ST004D01T == \"Male\")\n\nnrow(read_low_female)\nnrow(read_low_male)\n\n# You could also pipe the whole dataframe into nrow()\nPISA_2022 %&gt;% \n  filter(CNT == \"United Kingdom\",\n         PV1READ &lt; 400,\n         ST004D01T == \"Female\") %&gt;% \n  nrow()\n\n\n\nHow many students in the United Kingdom had no television ST254Q01JA OR no connection to the internet ST250Q05JA. HINT: use levels(PISA_2022$ST254Q01JA) to look at the levels available for each column.\n\n\n\nanswer\nPISA_2022 %&gt;% filter(CNT == \"United Kingdom\", \n                     ST254Q01JA == \"None\" |\n                     ST250Q05JA == \"None\")\n\n\n\nWhich countr[y|ies] had students with NA for Gender, remember to check for NA using is.na()?\n\n\n\nanswer\nPISA_2022 %&gt;% \n  filter(is.na(ST004D01T)) %&gt;%\n  select(CNT) %&gt;%\n  distinct()",
    "crumbs": [
      "Introduction to R",
      "Loading packages and exploring data"
    ]
  },
  {
    "objectID": "chapters/01-2-Intro_tidyverse.html#questions-3",
    "href": "chapters/01-2-Intro_tidyverse.html#questions-3",
    "title": "Loading packages and exploring data",
    "section": "5.1 Questions",
    "text": "5.1 Questions\n\n\nSpot the three errors with the following summarise statement\n\n\nPISA_2022 %&gt;% \n  group(CNT)\n  summarise(num_stus = n)\n\n\n\nanswer\nPISA_2022 %&gt;% \n  group_by(CNT) %&gt;% #1 group_by NOT group #2 missing pipe %&gt;%\n  summarise(num_stus = n()) #3 = n() not = n\n\n\n\nuse group_by and summarise to count (n()) the number of students who are male or female\n\n\n\nanswer\nPISA_2022 %&gt;% \n  group_by(ST004D01T) %&gt;%\n  summarise(num_stus = n())\n  \n# Also, if you only want a count, you can use:\nPISA_2022 %&gt;% \n  group_by(ST004D01T) %&gt;%\n  count()\n\n\n\nsummarise the number of students who are male or female by country\n\n\n\nanswer\nPISA_2022 %&gt;% \n  group_by(CNT, ST004D01T) %&gt;%\n  summarise(num_stus = n())\n\n\n\nWrite a group_by and summarise statement to work out the mean and median cultural capital value ESCS for each student by country CNT\n\n\n\nanswer\nPISA_2022 %&gt;%\n  group_by(CNT) %&gt;%\n  summarise(escs_mean = mean(ESCS, na.rm=TRUE),\n            escs_median = median(ESCS, na.rm=TRUE))\n\n\n\nUsing summarise work out, Yes or No, by country CNT and gender ST004D01T, whether students have in their home A room of your own ST250Q01JA. Filter out any NA values on ST250Q01JA:\n\n\n\nanswer\nPISA_2022 %&gt;%\n  filter(!is.na(ST250Q01JA)) %&gt;%\n  group_by(CNT, ST004D01T, ST250Q01JA) %&gt;% \n  summarise(n=n())",
    "crumbs": [
      "Introduction to R",
      "Loading packages and exploring data"
    ]
  },
  {
    "objectID": "chapters/01-2-Intro_tidyverse.html#ifelse",
    "href": "chapters/01-2-Intro_tidyverse.html#ifelse",
    "title": "Loading packages and exploring data",
    "section": "9.1 ifelse",
    "text": "9.1 ifelse\nA common way to recode values is through an ifelse statement:\n\nifelse(&lt;statement(s)&gt;, &lt;value_if_true&gt;, &lt;value_if_false&gt;)\n\nifelse allows us to recode the data. In the example below, we are going to add a new column to the PISA_2022 dataset (using mutate) noting whether a student got a higher grade in their Maths PV1MATH or Reading PV1READ tests. if PV1MATH is bigger then PV1READ, then maths_better is TRUE, else maths_better is FALSE, or in dplyr format:\n\nmaths_data &lt;- PISA_2022 %&gt;%\n  mutate(maths_better = \n1           ifelse(PV1MATH &gt; PV1READ,\n2                  TRUE,\n3                  FALSE)) %&gt;%\n  select(CNT, ST004D01T, maths_better, PV1MATH, PV1READ)\n\nprint(maths_data)\n\n\n1\n\nthe condition of the ifelse statement, if this is true we run command 2, if false we run command 3\n\n2\n\nthe value that will be stored in maths_better if 1 is true\n\n3\n\nthe value that will be stored in maths_better if 1 is false\n\n\n\n\n# A tibble: 613,744 × 5\n   CNT     ST004D01T maths_better PV1MATH PV1READ\n   &lt;fct&gt;   &lt;fct&gt;     &lt;lgl&gt;          &lt;dbl&gt;   &lt;dbl&gt;\n 1 Albania Female    FALSE           180.    248.\n 2 Albania Male      TRUE            308.    258.\n 3 Albania Male      FALSE           268.    285.\n 4 Albania Female    FALSE           273.    322.\n 5 Albania Female    FALSE           435.    464.\n 6 Albania Male      TRUE            534.    451.\n 7 Albania Male      FALSE           382.    391.\n 8 Albania Female    FALSE           273.    308.\n 9 Albania Female    FALSE           355.    429.\n10 Albania Female    TRUE            430.    420.\n# ℹ 613,734 more rows\n\n\nWe now take this new data set maths_data and look at whether the difference between relative performance in maths and reading is the same for girls and boys:\n\nmaths_data %&gt;% \n  rename(gender = ST004D01T) %&gt;%\n  filter(!is.na(gender), !is.na(maths_better)) %&gt;%\n  group_by(gender, maths_better) %&gt;%\n  summarise(n = n())\n\n# A tibble: 4 × 3\n# Groups:   gender [2]\n  gender maths_better      n\n  &lt;fct&gt;  &lt;lgl&gt;         &lt;int&gt;\n1 Female FALSE        180350\n2 Female TRUE         125409\n3 Male   FALSE        118341\n4 Male   TRUE         189565\n\n\n\nAdjust the code above to work out the percentages of Males and Females ST004D01T in each group. Check to see if the pattern also exists between science PV1SCIE and reading PV1READ:\n\n\nadding percentage column\nPISA_2022 %&gt;%\n  mutate(maths_better = \n           ifelse(PV1MATH &gt; PV1READ,\n                  TRUE, \n                  FALSE)) %&gt;%\n  select(CNT, ST004D01T, maths_better, PV1MATH, PV1READ) %&gt;% \n  filter(!is.na(ST004D01T), !is.na(maths_better)) %&gt;%\n  group_by(ST004D01T) %&gt;%\n  mutate(students_n = n()) %&gt;%\n  group_by(ST004D01T, maths_better) %&gt;%\n  summarise(n = n(),\n            per = n/unique(students_n))\n\n# or\n\nPISA_2022 %&gt;%\n  mutate(maths_better = \n           ifelse(PV1MATH &gt; PV1READ,\n                  TRUE, \n                  FALSE)) %&gt;%\n  rename(gender = ST004D01T) %&gt;%\n  filter(!is.na(gender), !is.na(maths_better)) %&gt;%\n  group_by(gender, maths_better) %&gt;%\n  summarise(n = n()) %&gt;%\n  group_by(gender) %&gt;%\n  mutate(total_n = sum(n),\n         gender_per = 100* n/total_n)\n\n\n\n\ncomparing science and reading\nPISA_2022 %&gt;%\n  mutate(sci_better = \n           ifelse(PV1SCIE &gt; PV1READ,\n                  TRUE, \n                  FALSE)) %&gt;%\n  select(CNT, ST004D01T, sci_better, PV1SCIE, PV1READ) %&gt;% \n  filter(!is.na(ST004D01T), !is.na(sci_better)) %&gt;%\n  group_by(ST004D01T) %&gt;%\n  mutate(students_n = n()) %&gt;%\n  group_by(ST004D01T, sci_better) %&gt;%\n  summarise(n = n(),\n            per = n/unique(students_n))\n\n\n\n\ncomparing science and maths\nPISA_2022 %&gt;%\n  mutate(sci_better = \n           ifelse(PV1SCIE &gt; PV1MATH,\n                  TRUE, \n                  FALSE)) %&gt;%\n  select(CNT, ST004D01T, sci_better, PV1SCIE, PV1MATH) %&gt;% \n  filter(!is.na(ST004D01T), !is.na(sci_better)) %&gt;%\n  group_by(ST004D01T) %&gt;%\n  mutate(students_n = n()) %&gt;%\n  group_by(ST004D01T, sci_better) %&gt;%\n  summarise(n = n(),\n            per = n/unique(students_n))",
    "crumbs": [
      "Introduction to R",
      "Loading packages and exploring data"
    ]
  },
  {
    "objectID": "chapters/01-2-Intro_tidyverse.html#nested-ifelse",
    "href": "chapters/01-2-Intro_tidyverse.html#nested-ifelse",
    "title": "Loading packages and exploring data",
    "section": "9.2 Nested ifelse",
    "text": "9.2 Nested ifelse\nIt’s possible to nest our ifelse statements - that is to put an ifelse inside another ifelse statement. You can do this by writing an ifelse where you would have the &lt;value_if_false&gt;, for example we might want to note what season a student was born in, to see if this impacted their results. We might roughly state (and with a Northern hemisphere’s view of things!) that anyone born in the months (ST003D02T) “September”, “October” or “November” is an Autumn child, those born in “December”, “January” and “February” are Winter children and so on, we can write multiple ifelse statements to do this:\n\nstu_seaonal &lt;- PISA_2022 %&gt;% \n  filter(!is.na(ST003D02T)) %&gt;% \n1  mutate(birth_season = ifelse(ST003D02T %in% c(\"September\", \"October\", \"November\"),\n                               \"Autumn\",\n                               \"Other\")) %&gt;%\n2  mutate(birth_season = ifelse(ST003D02T %in% c(\"December\", \"January\", \"February\"),\n                               \"Winter\",\n                               birth_season)) %&gt;%\n3  mutate(birth_season = ifelse(ST003D02T %in% c(\"March\", \"April\", \"May\"),\n                               \"Spring\",\n                               birth_season)) %&gt;%\n  mutate(birth_season = ifelse(ST003D02T %in% c(\"June\", \"July\", \"August\"),\n                               \"Summer\",\n                               birth_season)) %&gt;%\n  select(CNT, ST004D01T, ST003D02T, birth_season, starts_with(\"PV1\"))\n\n\nstu_seaonal %&gt;% \n  group_by(birth_season) %&gt;% \n  summarise(mean_maths = mean(PV1MATH),\n            mean_scie = mean(PV1READ),\n            mean_read = mean(PV1SCIE)) %&gt;% \n  arrange(desc(mean_maths))\n\n\n1\n\nthe first ifelse statement looks for all instances of when month of birth is in the vector c(\"September\", \"October\", \"November\") and codes the birth_season column as “Autumn”. Any birth month that isn’t in this range is given the temporary value of “Other”\n\n2\n\nthe second ifelse statement looks for all the winter months and codes the birth_season column as “Winter”. Note that it doesn’t set the false command to be “Other” , but uses the existing values already in this column, birth_season = birth_season if the month of birth isn’t in the Winter months.\n\n3\n\nand so on.\n\n\n\n\nThe above looks rather cumbersome, and we can achieve the same using a single mutate statement with nested ifelse:\n\nstu_seaonal &lt;- PISA_2022 %&gt;% \n  filter(!is.na(ST003D02T)) %&gt;% \n  mutate(birth_season = \n1           ifelse(ST003D02T %in% c(\"September\", \"October\", \"November\"),\n                  \"Autumn\",\n2                  ifelse(ST003D02T %in% c(\"December\", \"January\", \"February\"),\n                         \"Winter\", \n3                         ifelse(ST003D02T %in% c(\"March\", \"April\", \"May\"),\n                               \"Spring\", \n4                               ifelse(ST003D02T %in% c(\"June\", \"July\", \"August\"),\n                                    \"Summer\",\n                                    \"Other\"))))) %&gt;%\n  select(CNT, ST004D01T, ST003D02T, birth_season, starts_with(\"PV1\"))\n\n\n1\n\nifelse statement as before, but instead of a “Other” being returned if the month isn’t in the Autumn, if gives another ifelse statement, 2\n\n2\n\nthis other ifelse statement does the same thing, if the month isn’t in the Winter, then another ifelse statement is calcuated\n\n3\n\nditto, but for the Spring\n\n4\n\nThis final ifelse statement checks for Summer months, if the month isn’t in the Summer (or the Autumn, Winter and Spring), then it records “Other”, i.e. the month hasn’t been recorded or it has been mistyped.",
    "crumbs": [
      "Introduction to R",
      "Loading packages and exploring data"
    ]
  },
  {
    "objectID": "chapters/01-2-Intro_tidyverse.html#case_when",
    "href": "chapters/01-2-Intro_tidyverse.html#case_when",
    "title": "Loading packages and exploring data",
    "section": "9.3 case_when",
    "text": "9.3 case_when\nThe above nested ifelse statements might feel a little cumbersome and hard to follow. A neater way to perform multiple ifelse statements all at the same time is to use a case_when command. This command has the following structure, where each statement is checked in order, returning the value if true and not checking the other statements if true, e.g. if statement 1 is true, then it doesn’t check statements 2, 3, etc. If none of the statements are true, then it uses the .default value. Not that the tilde ~ command is used to assign values, rather than the arrow or the equals, but not for the .default command which uses =. The .default line is optional:\n\ncase_when( &lt;statement(s)1&gt; ~ , &lt;statement(s)2&gt; ~ , &lt;statement(s)3&gt; ~ , …, .default = )\n\n\nstu_seaonal &lt;- PISA_2022 %&gt;% \n  mutate(birth_season = case_when(\n    ST003D02T %in% c(\"September\", \"October\", \"November\") ~ \"Autumn\",\n    ST003D02T %in% c(\"December\", \"January\", \"February\") ~ \"Winter\",\n    ST003D02T %in% c(\"March\", \"April\", \"May\") ~ \"Spring\",\n    ST003D02T %in% c(\"June\", \"July\", \"August\") ~ \"Summer\",\n    .default = \"Other\"\n  )) %&gt;%\n  select(CNT, ST004D01T, ST003D02T, birth_season, starts_with(\"PV1\"))\n\n\n\n\n\n\n\nNote\n\n\n\nIn R, you can use traditional if else statements similar to those found in other programming languages. This construct evaluates a single logical condition and executes code based on whether the condition is TRUE or FALSE. For example:\n\nage &lt;- 17\nif(age &gt;= 18){\n  print(\"You can vote\")\n}else{\n  print(\"you can't vote\")\n}\n\n[1] \"you can't vote\"\n\n\nIn this example, the condition age &gt;= 18 is checked. Since age is 17, the else block is executed, printing “You can’t vote”.\nThe ifelse function, on the other hand, is vectorised. This means it operates on entire vectors at once, allowing you to apply a condition to each element of a vector and return a result for each element. In this example, ifelse checks the condition ages &gt;= 18 for each element in the ages vector. For elements where the condition is TRUE, it returns “You can vote”; for elements where the condition is FALSE, it returns “You can’t vote”. The result is a vector:\n\nages &lt;- c(15, 22, 18, 17, 20)\nvoting_eligibility &lt;- ifelse(ages &gt;= 18, \"You can vote\", \"You can't vote\")\nprint(voting_eligibility)\n\n[1] \"You can't vote\" \"You can vote\"   \"You can vote\"   \"You can't vote\"\n[5] \"You can vote\"  \n\n\nAs our pipe commands are dealing with entire columns of data, we use ifelse rather than if else to apply the condition to each row of the column all at the same time.",
    "crumbs": [
      "Introduction to R",
      "Loading packages and exploring data"
    ]
  },
  {
    "objectID": "chapters/01-2-Intro_tidyverse.html#ifelse-and-factors",
    "href": "chapters/01-2-Intro_tidyverse.html#ifelse-and-factors",
    "title": "Loading packages and exploring data",
    "section": "9.4 ifelse and factors",
    "text": "9.4 ifelse and factors\nifelse statements can get a little complicated when using factors (see: Chapter 10). Take this example. Let’s flag students who have a different home language LANGN to the language that is being used in the PISA assessment tool LANGTEST_QQQ. We make an assumption here that the assessment tool will be the language used at school, so these students will be learning in a different language to their mother tongue. if LANGN equals LANGTEST_QQQ, the lang_diff is FALSE, else lang_diff is TRUE, this raises an error:\n\nlang_data &lt;- PISA_2022 %&gt;%\n  mutate(lang_diff = \n           ifelse(LANGN == LANGTEST_QQQ,\n                  FALSE, \n                  TRUE)) %&gt;%\n  select(CNT, lang_diff, LANGTEST_QQQ, LANGN)\n\nError in `mutate()`:\nℹ In argument: `lang_diff = ifelse(LANGN == LANGTEST_QQQ, FALSE, TRUE)`.\nCaused by error in `Ops.factor()`:\n! level sets of factors are different\n\n\nThe levels in each field are different, i.e. the range of home languages is larger than the range of test languages. To fix this, all we need to do is change the datatype of the factors LANGN and LANGTEST_QQQ to characters using as.character(&lt;field&gt;). This will then allow the comparison of the text stored in each row:\n\nlang_data &lt;- PISA_2022 %&gt;%\n  mutate(lang_diff = \n           ifelse(as.character(LANGN) == as.character(LANGTEST_QQQ),\n                  FALSE, \n                  TRUE)) %&gt;%\n  select(CNT, lang_diff, LANGTEST_QQQ, LANGN)\n\nprint(lang_data)\n\n# A tibble: 613,744 × 4\n   CNT     lang_diff LANGTEST_QQQ LANGN   \n   &lt;fct&gt;   &lt;lgl&gt;     &lt;fct&gt;        &lt;fct&gt;   \n 1 Albania FALSE     Albanian     Albanian\n 2 Albania FALSE     Albanian     Albanian\n 3 Albania FALSE     Albanian     Albanian\n 4 Albania FALSE     Albanian     Albanian\n 5 Albania FALSE     Albanian     Albanian\n 6 Albania FALSE     Albanian     Albanian\n 7 Albania FALSE     Albanian     Albanian\n 8 Albania FALSE     Albanian     Albanian\n 9 Albania FALSE     Albanian     Albanian\n10 Albania FALSE     Albanian     Albanian\n# ℹ 613,734 more rows\n\n\nWe can now look at this dataset to get an idea of which countries have the largest percentage of students learning in a language other than their mother tongue:\n\nlang_data_diff &lt;- lang_data %&gt;% \n  group_by(CNT) %&gt;%\n  mutate(student_n = n()) %&gt;%\n  group_by(CNT, lang_diff) %&gt;%\n  summarise(n = n(),\n            percentage = 100*(n / max(student_n))) %&gt;%\n    filter(!is.na(lang_diff),\n         lang_diff == TRUE)\n\nprint(lang_data_diff)\n\n# A tibble: 80 × 4\n# Groups:   CNT [80]\n   CNT                  lang_diff     n percentage\n   &lt;fct&gt;                &lt;lgl&gt;     &lt;int&gt;      &lt;dbl&gt;\n 1 Albania              TRUE        720      11.7 \n 2 United Arab Emirates TRUE      13933      56.6 \n 3 Argentina            TRUE        788       6.51\n 4 Australia            TRUE       1827      13.6 \n 5 Austria              TRUE       1455      23.7 \n 6 Belgium              TRUE       2445      29.5 \n 7 Bulgaria             TRUE        961      15.7 \n 8 Brazil               TRUE        559       5.18\n 9 Brunei Darussalam    TRUE       4831      86.6 \n10 Canada               TRUE       5971      25.9 \n# ℹ 70 more rows\n\n\nThis looks like a promising dataset, but there are some strange results:\n\nlang_data_diff %&gt;% filter(percentage &gt; 92)\n\n# A tibble: 8 × 4\n# Groups:   CNT [8]\n  CNT                          lang_diff     n percentage\n  &lt;fct&gt;                        &lt;lgl&gt;     &lt;int&gt;      &lt;dbl&gt;\n1 Hong Kong (China)            TRUE       5626       95.2\n2 Macao (China)                TRUE       4384      100  \n3 Montenegro                   TRUE       5596       96.6\n4 Norway                       TRUE       6611      100  \n5 Philippines                  TRUE       6693       93.0\n6 Ukrainian regions (18 of 27) TRUE       3747       96.7\n7 Singapore                    TRUE       6567       99.4\n8 Chinese Taipei               TRUE       5821       99.4\n\n\nExploring data for Ukraine, we can see that a different spelling has been used in each field, Ukrainian and Ukranain, an incorrect spelling.\n\nlang_data %&gt;% filter(CNT == \"Ukrainian regions (18 of 27)\")\n\n# A tibble: 3,876 × 4\n   CNT                          lang_diff LANGTEST_QQQ LANGN    \n   &lt;fct&gt;                        &lt;lgl&gt;     &lt;fct&gt;        &lt;fct&gt;    \n 1 Ukrainian regions (18 of 27) TRUE      Ukranian     Ukrainian\n 2 Ukrainian regions (18 of 27) TRUE      Ukranian     Ukrainian\n 3 Ukrainian regions (18 of 27) TRUE      Ukranian     Russian  \n 4 Ukrainian regions (18 of 27) TRUE      Ukranian     Ukrainian\n 5 Ukrainian regions (18 of 27) TRUE      Ukranian     Ukrainian\n 6 Ukrainian regions (18 of 27) TRUE      Ukranian     Ukrainian\n 7 Ukrainian regions (18 of 27) TRUE      Ukranian     Russian  \n 8 Ukrainian regions (18 of 27) TRUE      Ukranian     Ukrainian\n 9 Ukrainian regions (18 of 27) TRUE      Ukranian     Ukrainian\n10 Ukrainian regions (18 of 27) TRUE      Ukranian     Ukrainian\n# ℹ 3,866 more rows\n\n\nifelse can help here too. If we pick the spelling we want to stick to, we can recode fields to match:\n\nlang_data %&gt;% \n  mutate(LANGTEST_QQQ = \n           ifelse(as.character(LANGTEST_QQQ) == \"Ukranian\",\n                 \"Ukrainian\",\n                 as.character(LANGTEST_QQQ))) %&gt;%\n  mutate(lang_diff = \n           ifelse(as.character(LANGN) == as.character(LANGTEST_QQQ),\n                  FALSE, \n                  TRUE)) %&gt;%\n  filter(CNT == \"Ukrainian regions (18 of 27)\")\n\n# A tibble: 3,876 × 4\n   CNT                          lang_diff LANGTEST_QQQ LANGN    \n   &lt;fct&gt;                        &lt;lgl&gt;     &lt;chr&gt;        &lt;fct&gt;    \n 1 Ukrainian regions (18 of 27) FALSE     Ukrainian    Ukrainian\n 2 Ukrainian regions (18 of 27) FALSE     Ukrainian    Ukrainian\n 3 Ukrainian regions (18 of 27) TRUE      Ukrainian    Russian  \n 4 Ukrainian regions (18 of 27) FALSE     Ukrainian    Ukrainian\n 5 Ukrainian regions (18 of 27) FALSE     Ukrainian    Ukrainian\n 6 Ukrainian regions (18 of 27) FALSE     Ukrainian    Ukrainian\n 7 Ukrainian regions (18 of 27) TRUE      Ukrainian    Russian  \n 8 Ukrainian regions (18 of 27) FALSE     Ukrainian    Ukrainian\n 9 Ukrainian regions (18 of 27) FALSE     Ukrainian    Ukrainian\n10 Ukrainian regions (18 of 27) FALSE     Ukrainian    Ukrainian\n# ℹ 3,866 more rows\n\n\nUnfortunately, if you explore this dataset a little further, the language fields don’t conform well with each other (see: “Slovenian”, “Arabic” etc) and a lot more work with ifelse will be needed before you could put together any full analysis around students who speak different languages at home and at school.",
    "crumbs": [
      "Introduction to R",
      "Loading packages and exploring data"
    ]
  },
  {
    "objectID": "chapters/01-2-Intro_tidyverse.html#questions-4",
    "href": "chapters/01-2-Intro_tidyverse.html#questions-4",
    "title": "Loading packages and exploring data",
    "section": "9.5 Questions",
    "text": "9.5 Questions\n\n\nSpot the four errors with the following ifelse statement\n\n\nPISA_2022 %&gt;%\n  rename(gender == ST004D01T) %&gt;%\n  mutate(top_reading = if else(PV1READ &gt; 550,\n                               TRUE\n                               FALSE)\n\n\n\nanswer\nPISA_2022 %&gt;%\n  rename(gender = ST004D01T) %&gt;% #1 double equals not needed for assignment\n  mutate(top_reading = ifelse(PV1READ &gt; 550, #2 ifelse doesn't need a space\n                               TRUE, #3 missing comma\n                               FALSE)) #4 missing bracket\n\n\n\nWrite an ifelse statement to create a new column read_low that stores whether a student got a PV1READ score of &lt;= 400. Select the country, gender, PV1READ and read_low columns\n\n\n\nanswer\nPISA_2022 %&gt;%\n  mutate(read_low = ifelse(PV1READ &lt;= 400,\n                               TRUE, \n                               FALSE)) %&gt;%\n  select(CNT, ST004D01T, PV1READ, read_low)\n\n\n\nWrite an ifelse statement to create a new column sub_strength that stores “reading” when their reading grade is higher than their maths grade, and “mathematics” when their maths grade is greater than their reading grade. Select just the country, gender, PV1READ, PV1MATH and sub_strength columns\n\n\n\nanswer\n# You could try\n\nPISA_2022 %&gt;%\n  mutate(sub_strength = ifelse(PV1READ &gt; PV1MATH,\n                               \"reading\", \n                               \"mathematics\")) %&gt;%\n  select(CNT, ST004D01T, PV1READ, PV1MATH, sub_strength)\n\n# But what if they have the same grade? You could try a nested if instead:\n\nPISA_2022 %&gt;%\n  mutate(sub_strength = ifelse(PV1READ &gt; PV1MATH,\n                               \"reading\", \n                               ifelse(PV1READ &lt; PV1MATH,\n                                      \"mathematics\",\n                                      \"equal\"))) %&gt;%\n  select(CNT, ST004D01T, PV1READ, PV1MATH, sub_strength) %&gt;%\n  filter(sub_strength == \"equal\") # and find out which students get equal!\n\n\n\nWrite an ifelse to make a new column called “continent” to record whether a country is in “South America” (i.e. “Argentina”, “Brazil”, “Chile”, “Colombia”, “Peru”, “Paraguay”, “Uruguay”; not including “Panama”), or “Other”:\n\n\n\nanswer\ncounts &lt;- PISA_2022 %&gt;% \n  mutate(continent = ifelse(CNT %in% c(\"Brazil\", \"Chile\", \"Colombia\", \"Peru\", \"Paraguay\", \"Uruguay\"),\n                             \"South America\",\n                             \"Other\"))\n\n\n\nWrite an ifelse statement to make a new column called high_escs which will calculate whether students are more than one standard deviation above the mean of the ESCS score ESCS. HINT: calculate the sd and mean of ESCS first, then use that for your ifelse statement:\n\n\n\nanswer sd and mean\nsd_escs &lt;- sd(PISA_2022$ESCS, na.rm=TRUE)\nmean_escs &lt;- mean(PISA_2022$ESCS, na.rm=TRUE)\n\n\n\n\nanswer high_escs\nPISA_2022_highescs &lt;-PISA_2022 %&gt;%\n  mutate(high_escs = ifelse(ESCS &gt; (mean_escs + sd_escs),\n                            TRUE,\n                            FALSE)) %&gt;%\n  select(CNT, ST004D01T, ESCS, high_escs)\n\n# you might also want to find the 'richest' countries\nPISA_2022_highescs %&gt;%\n  group_by(CNT) %&gt;%\n  mutate(total = n()) %&gt;%\n  group_by(CNT, high_escs) %&gt;%\n  summarise(n = n(),\n            per = 100 * n / unique(total)) %&gt;%\n  filter(high_escs == TRUE) %&gt;%\n  arrange(desc(per))\n\n\n\nAdjust the code from Q2 above to write a nested ifelse and the equivalent case_when statement to code whether a country is in continents of “North America” or the “Middle East” (i.e. “Israel”, “Palestinian Authority”, “Qatar”, “Saudi Arabia”, “United Arab Emirates”):\n\n\n\nanswer\ncontis &lt;- PISA_2022 %&gt;% \n  mutate(continent = \n            ifelse(CNT %in% c(\"Brazil\", \"Chile\", \"Colombia\", \"Peru\", \n                              \"Paraguay\", \"Uruguay\"),\n                   \"South America\",\n                   ifelse(CNT %in% c(\"United Arab Emirates\", \"Israel\", \n                                     \"Saudi Arabia\", \"Qatar\", \"Palestinian Authority\"),\n                          \"Middle East\", \n                          \"Other\")))\n\n# You can get distinct values for the recoded data using:\ncontis %&gt;% distinct(CNT, continent)\n\n# case_when alternative\ncounts &lt;- PISA_2022 %&gt;% \n  mutate(continent = case_when(\n    CNT %in% c(\"Brazil\", \"Chile\", \"Colombia\", \"Peru\", \n               \"Paraguay\", \"Uruguay\") ~ \"South America\",\n    CNT %in% c(\"United Arab Emirates\", \"Israel\", \n               \"Saudi Arabia\", \"Qatar\", \n               \"Palestinian Authority\") ~ \"Middle East\",\n    .default = \"Other\"))\n\ncontis %&gt;% distinct(CNT, continent)",
    "crumbs": [
      "Introduction to R",
      "Loading packages and exploring data"
    ]
  },
  {
    "objectID": "chapters/01-2-Intro_tidyverse.html#student-dataset",
    "href": "chapters/01-2-Intro_tidyverse.html#student-dataset",
    "title": "Loading packages and exploring data",
    "section": "11.1 Student dataset",
    "text": "11.1 Student dataset\n\n\nHow many unique values are there in the OCOD3 field for student intended future occupation?\n\n\n\nanswer\nPISA_2022$OCOD3 %&gt;% unique() %&gt;% length()\n\n\n\nHow does the most desired career OCOD3 vary by gender?\n\n\n\nanswer\nPISA_2022 %&gt;% \n  group_by(ST004D01T, OCOD3) %&gt;%\n  summarise(n =n()) %&gt;%\n  arrange(desc(n))\n\n\n\nwrite code to work out the mean and median PV1MATH score for each country CNT.\n\n\n\nanswer\nPISA_2022 %&gt;% \n  group_by(CNT) %&gt;%\n  summarise(mean_PV1MATH = mean(PV1MATH, na.rm=TRUE),\n            median_PV1MATH = median(PV1MATH, na.rm=TRUE)) %&gt;%\n  arrange(desc(median_PV1MATH))\n\n\n\nwhat is the fourth most popular language at home LANGN spoken by students in schools in the Ireland, how does this compare to Germany?\n\n\n\nanswer\nPISA_2022 %&gt;% \n  filter(CNT %in% c(\"Germany\", \"Ireland\")) %&gt;%\n  group_by(CNT, LANGN) %&gt;%\n  summarise(n = n()) %&gt;%\n  arrange(desc(n))\n\n\n\nSpot the five errors with the following code. Can you make it work? What does it do?\n\n\n# Work out when science scores are better than maths\nPISA_2022_scimath &lt; PISA_2022 %&gt;%\n  rename(gender = ST004D01T) %&gt;%\n  mutate(sci better = PV1SCIE - PV1MATH) %&gt;%\n  filter(is.na(scibetter) %&gt;%\n  group_by(CNT gender) %&gt;%\n  summarise(students = n,\n            sci_win = sum(scibetter &gt;= 0),\n            per_scibetter = 100*(sci_win/students))\n\n\n\nanswer\n# Work out when more time spent in language lessons than maths lessons\nPISA_2022_scimath &lt;- PISA_2022 %&gt;%  #1 make sure you have the assignment arrow &lt;-\n  rename(gender = ST004D01T) %&gt;%\n  mutate(sci_better = PV1MATH - PV1SCIE) %&gt;% #2 _ not space in name of field\n  filter(!is.na(sci_better)) %&gt;%  #3 this needs to be !is.na, otherwise it'll return nothing\n  group_by(CNT, gender) %&gt;% #4 missing comma\n  summarise(students = n(),   #5 missing brackets on the n() command\n            sci_win = sum(sci_better &gt;= 0),\n            per_sci_win = 100*(sci_win/students))\n\n\n\nBy country and gender work out the mean, median and standard deviations of STUBMI, order by the descending mean.\n\n\n\nanswer\npisa_bmi &lt;- PISA_2022 %&gt;%\n  rename(gender = ST004D01T) %&gt;%\n  group_by(CNT, gender) %&gt;%\n  summarise(n=n(),\n            bmi_mean = mean(STUBMI, na.rm=TRUE),\n            bmi_median = median(STUBMI, na.rm=TRUE),\n            bmi_sd = sd(STUBMI, na.rm=TRUE)) %&gt;%\n  arrange(desc(bmi_mean))\n\n\n\nBody Mass Index STUBMI is recorded in the 2022 PISA data set for some students (HINT: you need to filter out the rest). The US Center for Disease Control and Prevention (CDC) define adult BMI as follows 2, so this isn’t an ideal measure for this data set, but it will give you an idea of the spread of BMI in the data:\n\n\nUnderweight: BMI is less than 18.5\nHealthy weight: BMI is 18.5 to &lt;25\nOverweight: BMI is 25 to &lt;30\nObesity: BMI is 30 or more\n\nWork out the percentage of students of a “Healthy weight” by country\n\n\nanswer\nPISA_2022 %&gt;% \n  select(CNT, STUBMI) %&gt;% \n  filter(!is.na(STUBMI)) %&gt;%\n  mutate(bmi_group = case_when(\n    STUBMI &lt; 18.5                ~ \"Underweight\",\n    STUBMI &gt;= 18.5 & STUBMI &lt; 25 ~ \"Healthy weight\",\n    STUBMI &gt;= 25 & STUBMI &lt; 30   ~ \"Overweight\",\n    STUBMI &gt;= 30                 ~ \"Obese\")) %&gt;%\n  group_by(CNT) %&gt;%\n  mutate(total = n()) %&gt;%\n  group_by(CNT, bmi_group) %&gt;%\n  summarise(n = n(),\n            per = 100*(n/unique(total))) %&gt;%\n  filter(bmi_group == \"Healthy weight\") %&gt;% \n  arrange(desc(per))\n\n# you can write the same code without the need for the \n# double check at each case_when stage\n\nPISA_2022 %&gt;% \n  select(CNT, STUBMI) %&gt;% \n  filter(!is.na(STUBMI)) %&gt;%\n  mutate(bmi_group = case_when(\n    STUBMI &lt; 18.5                ~ \"Underweight\",\n    STUBMI STUBMI &lt; 25 ~ \"Healthy weight\",\n    STUBMI STUBMI &lt; 30   ~ \"Overweight\",\n    STUBMI &gt;= 30                 ~ \"Obese\")) %&gt;%\n  group_by(CNT) %&gt;%\n  mutate(total = n()) %&gt;%\n  group_by(CNT, bmi_group) %&gt;%\n  summarise(n = n(),\n            per = 100*(n/unique(total))) %&gt;%\n  filter(bmi_group == \"Healthy weight\") %&gt;% \n  arrange(desc(per))",
    "crumbs": [
      "Introduction to R",
      "Loading packages and exploring data"
    ]
  },
  {
    "objectID": "chapters/01-2-Intro_tidyverse.html#teacher-data-set",
    "href": "chapters/01-2-Intro_tidyverse.html#teacher-data-set",
    "title": "Loading packages and exploring data",
    "section": "11.2 Teacher data set",
    "text": "11.2 Teacher data set\nTo further check your understanding of this section you will be attempting to analyse the 2022 teacher dataset. This data set includes records for 68054 teachers from 18 countries, including 544 columns, covering attitudinal, demographic and workplace data. You can find the data set here in the .parquet format.\n\n\nexample loading code\n# download the file then\n# Work out when more time spent in language lessons than maths lessons\nPISA_2022_teacher &lt;- read_parquet(\"C:/Users/Peter/Downloads/PISA_2012_teacher.parquet\")\n\n\n\n\nWork out how many teachers are in the data set for Portugal\n\n\n\nanswer\nPISA_2022_teacher %&gt;% \n  group_by(CNTRYID) %&gt;%\n  summarise(n=n()) %&gt;%\n  filter(CNTRYID == \"Portugal\")\n\n\n\nFor each country CNTRYID by gender TC001Q01NA, what is the mean time that a teacher has been in the teaching profession TC007Q02NA? Include the number of teachers in each group. Order this to show the country with the longest serving workforce:\n\n\n\nanswer\nPISA_2022_teacher %&gt;%\n  group_by(CNTRYID, TC001Q01NA) %&gt;%\n  summarise(avg_years = mean(TC007Q02NA, na.rm=TRUE),\n            n = n()) %&gt;%\n  arrange(desc(avg_years))\n\n\n\nFor each country CNT find out which teachers report that they ‘Help students think critically’ TC199Q07HA. Hin: you’ll need to look at the levels of this question to find the correct filter:\n\n\n\nanswer\ncrit_thinking &lt;- PISA_2022_teacher %&gt;% \n  rename(crit_think = TC199Q07HA) %&gt;%\n  group_by(CNT) %&gt;%\n  mutate(teachers=n()) %&gt;%\n  group_by(CNT, crit_think) %&gt;%\n  summarise(n = n(),\n            per = n()/unique(teachers)) %&gt;%\n  arrange(desc(per)) %&gt;%\n  filter(crit_think == \"A lot\")\n\n# interestingly the highest performing countries also \n# have some of the lowest scores in helping children \n# think critically. To plot this:\n\nleft_join(crit_thinking,\n          PISA_2022 %&gt;% group_by(CNT) %&gt;% summarise(maths = mean(PV1MATH))) %&gt;%\n  ggplot(aes(x=per, y=maths)) + \n  geom_point() +\n  geom_smooth()\n\n\n\nExplore the data on use of technology in the classroom TC169____\n\n\n\nanswer\nPISA_2022_teacher %&gt;% select(CNT, TC001Q01NA, starts_with(\"TC169\"))\n\n\n\nSave the results of one of the above questions using write_csv().\n[EXTENSION] explore the data set and find out some more interesting facts to share with your group",
    "crumbs": [
      "Introduction to R",
      "Loading packages and exploring data"
    ]
  },
  {
    "objectID": "chapters/01-2-Intro_tidyverse.html#footnotes",
    "href": "chapters/01-2-Intro_tidyverse.html#footnotes",
    "title": "Loading packages and exploring data",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nEven in this cut down format the PISA data might take a few minutes to load. You can find the full dataset here, but be warned, it might crash you machine when trying to load it! Plug your laptop into a power supply, and having 16GB of RAM is highly recommended! You might also need to wrangle some of the fields to make them work for your purposes, you might enjoy the challenge!↩︎\nhttps://www.cdc.gov/obesity/basics/adult-defining.html↩︎",
    "crumbs": [
      "Introduction to R",
      "Loading packages and exploring data"
    ]
  },
  {
    "objectID": "chapters/01-1-Loading_R.html",
    "href": "chapters/01-1-Loading_R.html",
    "title": "Introduction to R",
    "section": "",
    "text": "This short course aims to take you through the process of writing your first programs in the R statistical programming language to analyse national and international educational datasets. To do this we will be using the R Studio integrated development environment (IDE), a desktop application to support you in writing R scripts. R Studio supports your programming by flagging up errors in your code as you write it, and helping you manage your analysis environment by giving you quick access to tables, objects and graphs as you develop them. In addition, we will be looking at data analysis using the tidyverse code packages. The tidyverse is a standardised collection of supporting code that helps you read data, tidy it into a usable format, analyse it and present your findings.\nThe R programming language offers similar functionality to an application based statistical tool such as SPSS, with more of a focus on you writing code to solve your problems, rather than using prebuilt tools. R is open source, meaning that it is free to use and that lots of people have written code in R that they have shared with others. R statistical libraries are some of the most comprehensive in existence. R is popular1 in academia and industry, being used for everything from sales modelling to cancer detection.\n# This example shows how R can pull data directly from the internet\n# tidy it and start making graphs. All within 9 lines of code\nlibrary(tidyverse)\n\neducation &lt;- read_csv(\n  \"https://barrolee.github.io/BarroLeeDataSet/BLData/BL_v3_MF.csv\")\n\neducation %&gt;%\n  filter(agefrom == 15, ageto == 24,\n         country %in% c(\"Germany\",\"France\",\"Italy\",\"United Kingdom\")) %&gt;%\n  ggplot(aes(x=year, y=yr_sch, colour=country)) +\n  geom_point() +\n  geom_line()\nWhilst it is possible to use R through menu systems and drop down tools, the focus of this course is for you to write your own R scripts. These are text files that will tell the computer how to go through the process of loading, cleaning, analysing and presenting data. The sequential and modular nature of these files makes it very easy to develop and test each stage separately, reuse code in the future, and share with others.\nThis booklet is written with the following sections to support you:\n# Code examples and questions appear like this\na &lt;- 1 + 3\nCourier font indicates keyboard presses, column names, column values and function names.\n&lt;folder&gt; Courier font within brackets describe values that can be passed to functions and that you need to define yourself. I.e. copying and pasting these code chunks verbatim won’t work!",
    "crumbs": [
      "Introduction to R",
      "Introduction to R"
    ]
  },
  {
    "objectID": "chapters/01-1-Loading_R.html#sec-installation",
    "href": "chapters/01-1-Loading_R.html#sec-installation",
    "title": "Introduction to R",
    "section": "\n1.1 Installation (on your own machine)",
    "text": "1.1 Installation (on your own machine)\n\n\nInstall R (default settings should be fine)\n\n\nWindows users visit: here\n\n\nMac users visit: here and make sure you get the correct version of R: for Apple silicon (M1-3) Macs (~November 2020 onwards), or older Intel Macs (~up to November 2020)\n\nLinux users visit: here\n\n\n\nInstall RStudio, visit here and it should present you with the version suitable for your operating system.\n\n(If the above doesn’t work follow the instructions here)",
    "crumbs": [
      "Introduction to R",
      "Introduction to R"
    ]
  },
  {
    "objectID": "chapters/01-1-Loading_R.html#sec-packages",
    "href": "chapters/01-1-Loading_R.html#sec-packages",
    "title": "Introduction to R",
    "section": "\n1.2 Setting up RStudio and the tidyverse",
    "text": "1.2 Setting up RStudio and the tidyverse\n\nOpen RStudio\n\nOn the bottom right-hand side, select Packages, then select Install, then type “tidyverse” into the Packages field of the new window:\n\n\nClick Install and you should see things happening in the console (bottom left). Wait for the console activity to finish (it’ll be downloading and checking packages). If it asks any questions, type N for no and press enter.\n\nAdd a new R Script using the  button\n\n\n\nIn the new R script, write the following:\n\n\n\nSelect all the lines and press Control or Command ⌘ and Enter on your keyboard at the same time. Alternatively, press the  button\n\n\n\nCheck that you have the following in the console window (depending on your screen size you might have fewer columns):\n\n\nInstall the arrow package, repeat step 2, above.\nDownload the PISA_student_2022_subset.parquet dataset from here and download it on your computer, make a note of the full folder location where you have saved this!\n\n\n\n\n\n\n\nNote\n\n\n\nIf you need help with finding the full folder location of your file, often a hurdle for Mac users, go to Chapter 10\n\n\n\nCopy the following code and replace &lt;folder&gt; with the full folder location of where your dataset was saved, make sure that you have .parquet on the end. And keep the (r\"[  ]\")! Make sure you run all the lines in the code below, including the library(arrow) and library(tidyverse) lines.\n\n\nexamples of what this should look like for PC and Mac# For Pete (PC) the address format was:\nPISA_2022 &lt;- read_parquet(r\"[C:\\Users\\Peter\\KCL\\MASTEMR\\PISA_student_2022_subset.parquet]\")\n\n# For Richard (Mac) the address format was:\nPISA_2022 &lt;- read_parquet(r\"[/Users/k1765032/Documents/Teaching/STEM MA/Quantitative module/Data sets/PISA_student_2022_subset.parquet]\")\n\n\n\nlibrary(arrow)\nlibrary(tidyverse)\n\nPISA_2022 &lt;- read_parquet(r\"[&lt;folder&gt;PISA_student_2022_subset.parquet]\")\n\nIf you can’t load the parquet file, you can load the data as an RDS file which takes longer, but should work if you are having problems with the arrow package. Download the data as an RDS file here\nThen use the code below to load the RDS file:\n\nlibrary(tidyverse)\n\nPISA_2022 &lt;- readRDS(file = \"[&lt;folder&gt;PISA_student_2022_subset_RDS.rds]\")\n\n\nUnderneath the code you have already written, copy the code below (you don’t have to write it yourself), and run it. Try and figure out what each line does and what it’s telling you.\n\n\nlibrary(tidyverse)\n\nPISA_2022 %&gt;%\n  mutate(maths_better = PV1MATH &gt; PV1READ) %&gt;%\n  select(CNT, ST004D01T, maths_better, PV1MATH, PV1READ) %&gt;% \n  filter(!is.na(ST004D01T), !is.na(maths_better)) %&gt;%\n  group_by(ST004D01T) %&gt;%\n  mutate(students_n = n()) %&gt;%\n  group_by(ST004D01T, maths_better) %&gt;%\n  summarise(n = n(),\n            per = n/unique(students_n))\n\n\nThat’s it, you should be set up!\nAny issues, please drop a message on the Teams group, or mail peter.kemp@kcl.ac.uk and richard.brock@kcl.ac.uk",
    "crumbs": [
      "Introduction to R",
      "Introduction to R"
    ]
  },
  {
    "objectID": "chapters/01-1-Loading_R.html#objects-and-instructions",
    "href": "chapters/01-1-Loading_R.html#objects-and-instructions",
    "title": "Introduction to R",
    "section": "\n3.1 Objects and instructions",
    "text": "3.1 Objects and instructions\nIn programming languages we can attach data to a name, this is called assigning a value to an object (you might also call them variables). To do this in R we use the &lt;- arrow command. For example, I want to put the word \"Pete\" into an object called myname (note that words and sentences such as \"Pete\" need speech marks):\n\nmyname &lt;- \"Pete\"\nprint(myname)\n\n[1] \"Pete\"\n\n\nWe can also perform quick calculations and assign them to objects:\n\nHoursInYear &lt;- 365 * 24\nprint(HoursInYear) \n\n[1] 8760\n\n\n\nType the two examples above into your RStudio script file and check that they work. Adapt them to say your full name and give the number of MinutesInADay\n\n\n\n\n\n\n\nTip\n\n\n\nRemember to select code and press control or command and Enter to run it\n\n\nObjects can form part of calculations, for example, the code below shows how we can use the number HoursInYear to (roughly!) calculate the number of HoursInWeek:\n\nHoursInYear &lt;- 365 * 24\n\nHoursInWeek &lt;- HoursInYear / 52\nprint(HoursInWeek)\n\n[1] 168.4615\n\n\nNotice from the above we can perform the main arithmetic commands using keyboard symbols: + (add); - (minus); * (multiply); / (divide); ^ (power)\nObjects can change values when you run code. For example in the code below:\n\na &lt;- 2000\nb &lt;- 5\n\na &lt;- b\n\na &lt;- a * b\nprint(a)\n\n[1] 25\n\n\nWhat’s going on here?\n\nline 1 sets a to equal 2000 (note: don’t use commas in writing numbers a &lt;- 2,000 would bring up an error),\nline 2 sets b to equal 5,\nline 4 overwrites the value of a with the value stored in b, making object a now equal to 5\nline six is now 5 * 5\n\n\n\n3.1.1 Questions\n\nwhat are the outputs of the following code snippets/what do they do? One of the examples might not output anything, why is that? Type the code into your script file to check your answers:\ncode example 1\n\nrabbits &lt;- 50\nfeet &lt;- 4\n\ntotalfeet &lt;- rabbits * feet\nprint(totalfeet)\n\n\nanswer200\n\n\ncode example 2\n\np &lt;- 3.14 - 0.14\nr &lt;- 5\n\nprint(p * r^2)\n\n\nanswer75\n\n\ncode example 3\n\ntax &lt;- 17.5\nprice &lt;- 4.50\nsales &lt;- 128\ntax &lt;- 20\n\nincome &lt;- (sales * price) * (1 + (tax/100))\n\n\nanswer# prints nothing! there isn't a print statement",
    "crumbs": [
      "Introduction to R",
      "Introduction to R"
    ]
  },
  {
    "objectID": "chapters/01-1-Loading_R.html#naming-objects",
    "href": "chapters/01-1-Loading_R.html#naming-objects",
    "title": "Introduction to R",
    "section": "\n3.2 Naming objects",
    "text": "3.2 Naming objects\nCorrectly naming objects is very important. You can give an object almost any name, but there are a few rules to follow:\n\nName them something sensible\nR is case sensitive, myName is not equal to (!=) myname\n\nDon’t use spaces in names\nDon’t start a name with a number\nKeep punctuation in object names to underscore (_ and full stop .) e.g. my_name, my.name.\nStick to a convention for all your objects, it’ll make your code easier to read, e.g.\n\n\nmyName, yourName, ourName (this is camelCase 2)\n\nmy_name, your_name, our_name (this is snake case)\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nThe actual name of an object has no effect on what it does (other than invalid names breaking your program!). For example age &lt;- \"Barry\" is perfectly valid to R, it’s just a real pain for a human to read.\n\n\n\n3.2.1 Questions\n\nWhich of these are valid R object names:\n\nmy_Number\nmy-Number\nmyNumber!\nfirst name\nFIRSTname\ni\n3names\nnames3\n\n\nanswers# my_Number  (VALID)\n# my-Number  (INVALID due to -)\n# myNumber!  (INVALID due to !)\n# first name (INVALID due to space)\n# FIRSTname  (VALID but we don't recommend so many caps)\n# i          (VALID)\n# 3names     (INVALID starts with a 3)\n# names3     (VALID)\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nFor more information on the R programming style guide, see this",
    "crumbs": [
      "Introduction to R",
      "Introduction to R"
    ]
  },
  {
    "objectID": "chapters/01-1-Loading_R.html#comments",
    "href": "chapters/01-1-Loading_R.html#comments",
    "title": "Introduction to R",
    "section": "\n3.3 Comments",
    "text": "3.3 Comments\nCode can often look confusing and it’s a good idea to add # comments to your code to make it more understandable for you and others. The computer ignores comments when running your code:\n\n# this calculates the average sales per shop\n\nincome1 &lt;- 132\nincome2 &lt;- 665\nincome3 &lt;- 233\nincome4 &lt;- 1200\n\nshops &lt;- 4 # everything after the hash is a comment\n\navgSales &lt;- sum(income1, income2, income3, income4) / shops  \n\n# sometimes you might want to comment out code that\n# is no longer needed, but might be useful later\n# standard_deviation &lt;- sd(c(income1, income2, income3, income4) )\n# the above code isn't run\n\nprint(avgSales) # but this code is\n\n[1] 557.5",
    "crumbs": [
      "Introduction to R",
      "Introduction to R"
    ]
  },
  {
    "objectID": "chapters/01-1-Loading_R.html#sec-datatypes",
    "href": "chapters/01-1-Loading_R.html#sec-datatypes",
    "title": "Introduction to R",
    "section": "\n3.4 Datatypes",
    "text": "3.4 Datatypes\nWe have already met two different datatypes, the character datatype for words and letters (e.g. \"Peter\") and the numeric datatype for numbers (e.g. 12). Datatypes tell R how to handle data in certain circumstances. Sometimes data will be of the wrong datatype and you will need to convert between datatypes.\n\nweeks &lt;- 4\ndays_in_week &lt;- \"7\"\n\n# we now attempt to multiply a number by a string\n# but it doesn't work!\ntotal_days &lt;- weeks * days_in_week \n\nError in weeks * days_in_week: non-numeric argument to binary operator\n\n\nWhilst R will understand what to do when we multiply numbers with numbers, it gets very confused and raises an error when we try to perform an arithmetic operation using words and numbers.\nTo perform the calculation we will need to convert the days_in_week from a string to a number, using the as.numeric(&lt;text&gt;) command:\n\nweeks &lt;- 4\ndays_in_week &lt;- \"7\"\n\n# we now attempt to multiply a number by a string\ntotal_days &lt;- weeks * as.numeric(days_in_week)\n\nThere is a logical datatype for boolean values of TRUE and FALSE. This will become a lot more useful later.\n\nlegs_snake &lt;- FALSE # you can specify logical values directly\ndogs_legs &lt;- 4\nlegs_dog &lt;- dogs_legs &gt; 0 # or as part of a calculation\n\n# Do dog's have legs?\nprint(legs_dog)\n\n[1] TRUE\n\n\nThere are actually three datatypes for numbers in R, numeric for most of your work, the rarer integer specifically for whole numbers and the even rarer complex for complex numbers. When you are looking at categorical data, factors are used on top of the underlying datatype to store the different values, for example you might have a field of character to store countries, factors would then list the different countries stored in this character field.\nTo change from one datatype to another we use the as.____ command: as.numeric(&lt;text&gt;), as.logical(&lt;data&gt;), as.character(&lt;numeric&gt;).\n\n3.4.1 Questions\n\n\nCan you spot the error(s) in this code and fix them so it outputs: “July is month 7”?\n\n\nmonth &lt;- \"July\"\norder &lt;- 7\n  \nprint(month)\nPrint(\"is\")\nprint(month)\nprint(\"order\")\n\n\nanswermonth &lt;- \"July\"\norder &lt;- 7\n  \nprint(month)    \nprint(\"is\")     #1 print needs a lowercase p\nprint(\"month\")  #2 month is a character not an object, use speech marks\nprint(order)    #3 order is an object, not a character, so drop the speech marks\n\n\n\nCan you spot the error(s) in this code and fix it?\n\n\na &lt;- 7\nb &lt;- \"8\"\nc &lt; - 3\n  \nprint(a + b + c)\n\n\nanswera &lt;- 7\nb &lt;- 8 #1 b is numeric so drop the speech marks\nc &lt;- 3 #2 the arrow needs to be together, remove the space\n  \nprint(a + b + c)\n\n\n\nCan you spot the error(s) in this code and fix it?\n\n\npass mark &lt;- 50 \nexam_grade &lt;- 50\n\n# did the student pass?\nprint(exam_grade &gt; pass_mark)\n\n\nanswerpass_mark &lt;- 50 #1 the variable name can't have any spaces\nexam_grade &lt;- 50\n\n# did the student pass?\nprint(exam_grade &gt;= pass_mark) # this needs to be &gt;= as they had a passing grade\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nIf you want to find out the datatype of an object you can use the structure str command to give you more information about the object. In this instance chr means that month is of character datatype and num means it is of the numeric datatype.\n\nmonth &lt;- \"July\"\nstr(month)\n\n chr \"July\"\n\nmonth &lt;- 7\nstr(month)\n\n num 7",
    "crumbs": [
      "Introduction to R",
      "Introduction to R"
    ]
  },
  {
    "objectID": "chapters/01-1-Loading_R.html#questions-3",
    "href": "chapters/01-1-Loading_R.html#questions-3",
    "title": "Introduction to R",
    "section": "\n4.1 Questions",
    "text": "4.1 Questions\n\n\nCan you spot the three problems with this code:\n\n\nnums &lt;- v(1,2,\"3\",4,7,2,2)\nsum(nums)\nmean(nums)\n# return a vector of all numbers greater than 2\nnums(nums &gt;= 2)\n\n\nanswernums &lt;- c(1,2,3,4,7,2,2) \n#1 a vector is declared using c(), not v()\n#2 3 should be numeric, so no need for speech marks\n# (though technically R would do this conversion for you!)\n\nsum(nums)\nmean(nums)\n# return a vector of all numbers greater than 2\nnums[nums &gt;= 2] #3 to pick items from another vector, use square brackets\n\n\n\nCreate a vector to store the number of glasses of water you have drunk for each day in the last 7 days. Work out:\n\nthe mean average number of glasses for the week,\nthe total number of glasses,\nthe number of days where you drank less than 2 glasses (feel free to replace water with your own tipple: wine, coffee, tea, coke, etc.)\n\n\n\n\nanswerglasses &lt;- c(6,1,3,2,3,0,3)\nmean(glasses)\nsum(glasses)\nsum(glasses &lt; 2)\n\n\n\nUsing the vectors below, create a program that will find out the average grade for females taking English:\n\n\nenglish_grade &lt;- c(8,5,3,2,3,6,9)\ngenders &lt;- c(\"F\", \"M\", \"M\", \"F\", \"M\", \"F\", \"M\")\n\n\nanswerenglish_grade &lt;- c(8,5,3,2,3,6,9)\ngenders &lt;- c(\"F\", \"M\", \"M\", \"F\", \"M\", \"F\", \"M\")\nmean(english_grade[genders == \"F\"])",
    "crumbs": [
      "Introduction to R",
      "Introduction to R"
    ]
  },
  {
    "objectID": "chapters/01-1-Loading_R.html#sec-load-run-pckges",
    "href": "chapters/01-1-Loading_R.html#sec-load-run-pckges",
    "title": "Introduction to R",
    "section": "\n6.1 Installing and loading packages",
    "text": "6.1 Installing and loading packages\nTo install a package you can use the package tab in the bottom right-hand panel of RStudio and follow the steps from Section 1.2. Alternatively you can install things by typing:\n\ninstall.packages(\"tidyverse\")\n\nNote that the instruction is to install packages, you can pass a vector of package names to install multiple packages at the same time:\n\ninstall.packages(c(\"tidyverse\",\"readxl\",\"haven\"))\n\nOnce a package is installed it doesn’t mean that you can use it, yet. You will need to load the package. To do this you need to use the library(&lt;package_name&gt;) command, for example:\n\nlibrary(tidyverse)\n\n\n\n\n\n\n\nImportant\n\n\n\nSome packages might use the same function names as other packages, for example select might do different things depending on which package you loaded last. As a rule of thumb, when you start RStudio afresh, make sure that you load the tidyverse package after you have loaded all your other packages. To read more about this problem see ?@sec-QANDA",
    "crumbs": [
      "Introduction to R",
      "Introduction to R"
    ]
  },
  {
    "objectID": "chapters/01-1-Loading_R.html#the-tidyverse",
    "href": "chapters/01-1-Loading_R.html#the-tidyverse",
    "title": "Introduction to R",
    "section": "\n6.2 The Tidyverse",
    "text": "6.2 The Tidyverse\nThis course focuses on using the tidyverse; a free collection of programming packages that will allow you to write code that imports data, tidys it, transforms it into useful datasets, visualises findings, creates statistical models and communicates findings to others data using a standardised set of commands.\n\n\nData science workflow - RStudio\n\nFor many people the tidyverse is the main reason that they use R. The tidyverse is used widely in government, academia, NGOs and industry, notable examples include the Financial Times and the BBC. Code in the tidyverse can be (relatively) easily understood by others and you, when you come back to a project after several months.\n\n\n\n\n\n\nNote\n\n\n\nTry this out\nThe code above transforms data and converts it into a graph. It doesn’t have any comments, but you should hopefully be able to understand what a lot of the code does by just reading it. Can you guess what each line does? Try running the code by selecting parts of it and pressing control | command ⌘ and Enter",
    "crumbs": [
      "Introduction to R",
      "Introduction to R"
    ]
  },
  {
    "objectID": "chapters/01-1-Loading_R.html#proper-addresses",
    "href": "chapters/01-1-Loading_R.html#proper-addresses",
    "title": "Introduction to R",
    "section": "\n11.1 Proper addresses",
    "text": "11.1 Proper addresses\nYou might have found that you get an error if you don’t convert your backslashes \\ into forwardslashes /. It’s common mistake and very annoying. In most programming languages a backslash signifies the start of a special command, for example \\n signifies a newline.\nWith R there are three ways to get around the problem of backslashes in file locations, for the location:\"C:\\myfolder\\\" we could:\n\nreplace them with forwardslashes (as shown above):\"C:/myfolder/\"\n\nreplace them with double backslashes (the special character specified by two backslashes is one backslash!):\"C:\\\\myfolder\\\\\"\n\nuse the inbuilt R command to deal with filenames: r\"[C:\\myfolder\\]\"",
    "crumbs": [
      "Introduction to R",
      "Introduction to R"
    ]
  },
  {
    "objectID": "chapters/01-1-Loading_R.html#footnotes",
    "href": "chapters/01-1-Loading_R.html#footnotes",
    "title": "Introduction to R",
    "section": "Footnotes",
    "text": "Footnotes\n\nAs of December 2022, Tiobe has R as the 11th most popular programming language. Many other, contradictory, ranking systems exist.↩︎\ncamelCase has a capital letter in the front or front and middle forming the camel’s hump(s), there are multiple naming conventions, it doesn’t matter which you pick, just stick to one of them.↩︎\nR was created to allow for vector programming, that is a programming language where you can apply operations to entire sets of values (vectors) at the same time, rather than having to cycle through them individually. Vector languages work in a way that is close to how mathematical notation works, making them well suited for performing mathematical functions.↩︎\nYou’ll sometimes see the words package and library used interchangeably, technically the library is the place where the packages are stored.↩︎",
    "crumbs": [
      "Introduction to R",
      "Introduction to R"
    ]
  },
  {
    "objectID": "chapters/03-1-Descriptive.html",
    "href": "chapters/03-1-Descriptive.html",
    "title": "Descriptive Statistics",
    "section": "",
    "text": "Getting set up\nEnsure you have the PISA 2022 data frame loaded. If you can see the PISA_2022 data frame in your environment window (at the top right of your screen), there is no need to reload.\n# Load the PISA data.\n\nlibrary(arrow)\nlibrary(tidyverse)\n\nPISA_2022 &lt;- read_parquet(r\"[&lt;folder&gt;PISA_2022_student_subset.parquet]\")",
    "crumbs": [
      "Introduction to Stats",
      "Descriptive Statistics"
    ]
  },
  {
    "objectID": "chapters/03-1-Descriptive.html#the-pisa-assessments",
    "href": "chapters/03-1-Descriptive.html#the-pisa-assessments",
    "title": "Descriptive Statistics",
    "section": "1.1 The PISA assessments",
    "text": "1.1 The PISA assessments\nThe first International Large-Scale Assessment (ILSA) comparing the learning outcomes of school students between countries was attempted in the 1960s. However, ILSAs only became established and regular in the late 1990s and 2000s.\nThe OECD’s Programme for International Student Assessment (PISA) has tested 15-year-old students in a range of “literacies” or “competencies” every three years since 2000. There is a rotating focus on reading, mathematics and science, with PISA 2021 focusing on mathematics but delayed by the global pandemic until 2022 and the results only published in December 2023. Until then, PISA 2018, with a focus on reading, was the most recently available cycle and PISA 2015 remains the most recent cycle focusing on science.\nIn addition to reading, mathematics and science, PISA has tested students on a range of “novel” competencies including problem-solving, global competence, financial literacy, and creative thinking. In addition to these tests, PISA also administers questionnaires to students, teachers and parents to identify “factors” which explain test score differences within and between countries.\nSince 2000, more than 90 “countries and economies” and around 3,000,000 students have participated in PISA. The growth in the number of countries participating in each cycle of PISA is reflected in the growth in the number of students taking the PISA tests and responding to the PISA questionnaires, as shown in Table 1.\nTable 1: Number of students participating in PISA by year\n\n\n\nYear\nNumber completing assessment\n\n\n\n\n2000\n265,000\n\n\n2003\n275,000\n\n\n2006\n400,000\n\n\n2009\n470,000\n\n\n2012\n510,000\n\n\n2015\n540,000\n\n\n2018\n600,000\n\n\n2022\n690,000\n\n\n\nThere is a degree of inherent error in all educational and psychological assessments - and indeed in all social or physical measurement. ILSAs such as PISA may be more prone to error because their comparisons across large and diverse populations make them particularly complex. However, it is particularly important to minimise the error in ILSAs because they influence education policy and practice across a large number of education systems, impacting a vast population of students beyond those sampled for the assessments.\nAccording to the OECD (2019), three sources of error are worth considering. First, sampling error, uncertainty in the degree to which results from the sample generalise to the wider population - in 2018, the OECD average sampling error was 0.4 of a PISA point score (the value was not reported for 2022). Second, measurement error, uncertainty in the extent to which test items measure proficiency. In 2018, the measurement error was around 0.8 of a point in mathematics and science and 0.5 of a score point in reading (the measurement error was not reported for 2022). Third, the link error is the uncertainty in comparison between scores in different years. For comparisons of science scores between 2018 and 2015, the link error is 1.5 points. For 2018-2022, the link errors are reading (1.47), mathematics (2.24) and science (1.61) (OECD 2022, 293)\nPISA uses a probabilistic, stratified clustered survey design (Jerrim et al. 2017). However, sampling issues including sample representativeness, non-response rates and population coverage have been identified (Zieger et al. 2022; Rutkowski and Rutkowski 2016; Gillis, Polesel, and Wu 2016; Hopmann, Brinek, and Retzl 2007). Furthermore, Anders et al. (2021) and Jerrim (2021) have shown that assumptions for imputing values (imputing means estimating any missing values based on existing data - for example by adding a mean or mode score for a missing test) for non-participating students used to construct the sample may have significant impacts on achievement scores.\nSince PISA 2015, the majority of participating countries have switched from paper-based assessment to computer-based assessment (Jerrim 2016). A randomised controlled trial conducted by the OECD prior to the switch indicated a difference in score between the two modes of delivery. The OECD introduced an adjustment to compensate for this difference, but it is not entirely removed by the adjustment Jerrim et al. (2018), with implications for any time series comparisons between PISA cycles. Nonetheless, Jerrim (2016) notes that “in terms of cross-country rankings, there remains a high degree of consistency… the vast majority of countries are simply ‘shifted’ by a uniform amount” (pp. 508-509).\nIn summary, comparisons within and between countries and comparisons over time using ILSAs need careful interpretations that bear in mind the specific design of each ILSA. In practice, this means considering a range of potential explanations for score differences. Does a difference in science ranking between two countries simply reflect sampling error? Does the same parental occupation or home possessions amount to the same economic, social and cultural status in different countries (e.g. the social status of a parent as a teacher or the economic status of the number of cars a family owns)? Does a difference in mathematical self-efficacy (i.e. student self-confidence in mathematics) between the USA and Japan reflect sociocultural differences in self-enhancement and modesty, respectively? How do score differences between boys and girls indicate gender inequalities in education that reflect wider society?\n\n\n\n\n\n\nTip\n\n\n\nFor useful critique and discussion of the construction of the measure of socio-economic status in PISA data see: Avvisati’s (2020) paper.",
    "crumbs": [
      "Introduction to Stats",
      "Descriptive Statistics"
    ]
  },
  {
    "objectID": "chapters/03-1-Descriptive.html#using-the-command-line-for-descriptive-statistics",
    "href": "chapters/03-1-Descriptive.html#using-the-command-line-for-descriptive-statistics",
    "title": "Descriptive Statistics",
    "section": "1.2 Using the command line for descriptive statistics",
    "text": "1.2 Using the command line for descriptive statistics\nFor further reading on descriptive statistics see chapter 5 of Navaro’s Learning Statistics with R.\n\n\n\n\n\n\nTip\n\n\n\nWe are going to focus on the following variables in the PISA_2022 data frame:\n\nCNT the country of the student.\nHOMEPOS is a self-reported measure of a student’s wealth, linked to the number of possessions students report having in their home (e.g. books, computers, cars, phones etc.). It is a numeric variable, with a mean of -0.447, minimum of -10.07 and a maximum of 15.24.\nESCS is the index of economic, social and cultural status. It might be thought of as a measure of economic and social status (with some cultural capital measures included). It is a numeric variable, with a mean of -0.310, minimum of -6.84 and a maximum of 7.38. It is constructed from three items: highest parental occupation (HISEI), highest level of parental education (PARED), and home possessions (HOMEPOS), including books in the home\nPV1MATH, PV1SCIE, PV1READ are the plausible value scores for achievement tests in mathematics, science and reading, respectively. The full achievement tests are long, so each student only completes a subset of items (which still takes 2 hours). Statistical models are then used to calculate an overall score, based on the students’ answers to the subset of questions, as if students had answered all the questions. Ten different approaches (ten different statistical models, that take different approaches to estimating the overalls score are used) to calculating a representative scores, plausible values are used, leading to ten different plausible values. In this course, will just use the first plausible value (PV1). This differs from the PISA recommendation for using the scores, but simplifies things for teaching. For more on plausible values see: What are plausible values?\nST004D01T is the gender variable and and can take the values: Male, Female or NA.\n\n\n\nThe simplest way to find information about a data frame is to use the console. You can type commands to find out about a data frame directly into the console. To preform an action on a particular column (also called a vector), we use the $ symbol. For example, to refer to country data (which is in the vector CNT) we would use PISA_2022$CNT\nIn the command line, if you want to find the mean of all the repsonses to the HOMEPOS (Home Possessions, a proxy for wealth) item you can type the following:\n\nmean(PISA_2022$HOMEPOS)\n\nNotice that you get this response: [1] NA. An NA in the data frame can occur for a number of reasons, for example it may indicate a response is missing or incomplete, hence the mean can’t be calculated. To tell R to ignore NAs, we add na.rm = TRUE to a function:\n\nmean(PISA_2022$HOMEPOS, na.rm = TRUE)\n\nYou can use the command line with a number of functions to find useful information about a data frame. R has a number of standard functions that might be useful for descriptive statistics. To find out details about data frames, you can use:\n\nnrow() finds the number of rows (e.g. nrow(PISA_2022))\nncol() finds the number of columns (e.g. ncol(PISA_2022))\nnames() finds the names of all the columns (e.g. names(PISA_2022))\n\nIf you are working on individual columns, e.g. max(PISA_2022$PV1SCIE), you can use:\n\nmean() - finds the arithmetic mean\nmedian() - finds the median value\nmin() - finds the minimum value\nmax() - finds the maximum value\nsd() - finds the standard deviation\nrange() - finds the range of values\nlength()- finds the number of items\nunique() - finds the unique items\n\n\n\n\n\n\n\nTip\n\n\n\nMaybe surprisingly, there is no function to calculate the mode in the tidyverse package. However, you can get one by loading the modeest package and using the most frequent value (mfv) function.\n\n# Install the modeest package to calculate a mode\n\nlibrary(modeest)\nlibrary(tidyverse)\n\n# The mode can be found with the most frequent value (mfv) function\n# We can look at about number of books in the home (ST255Q01JA)\n# Then use mfv to find the mode value (note the na.rm=TRUE to avoid NAs)\n\nmfv(PISA_2022$ST255Q01JA, na.rm = TRUE)\n\n[1] 26-100 books\n11 Levels: There are no books. 1-10 books 11-25 books ... No Response\n\n# In the whole dataframe, the mode number of books is 26-100 books\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nTo get a list of the item descriptors, you can use this code:\n\nlapply(PISA_2022, attr, \"label\")\n\n$CNT\n[1] \"Country code 3-character\"\n\n$CNTSCHID\n[1] \"Intl. School ID\"\n\n$CNTSTUID\n[1] \"Intl. Student ID\"\n\n$REGION\n[1] \"REGION\"\n\n$OECD\n[1] \"OECD country\"\n\n$LANGTEST_QQQ\n[1] \"Language of Questionnaire\"\n\n$ST003D02T\n[1] \"Student (Standardized) Birth - Month\"\n\n$ST003D03T\n[1] \"Student (Standardized) Birth -Year\"\n\n$ST004D01T\n[1] \"Student (Standardized) Gender\"\n\n$ST250Q01JA\n[1] \"Which of the following are in your [home]: A room of your own\"\n\n$ST250Q02JA\n[1] \"Which of the following are in your [home]: A computer (laptop, desktop, or tablet) that you can use for school work\"\n\n$ST250Q03JA\n[1] \"Which of the following are in your [home]: Educational Software or Apps\"\n\n$ST250Q05JA\n[1] \"Which of the following are in your [home]: Internet access (e.g. Wi-fi) (excluding through smartphones)\"\n\n$ST251Q01JA\n[1] \"How many of these items are there at your [home]: Cars, vans, or trucks\"\n\n$ST251Q06JA\n[1] \"How many of these items are there at your [home]: Musical instruments (e.g. guitar, piano, [country-specific example])\"\n\n$ST251Q07JA\n[1] \"How many of these items are there at your [home]: Works of art (e.g. paintings, sculptures, [country-specific example])\"\n\n$ST253Q01JA\n[1] \"How many [digital devices] with screens are there in your [home]?\"\n\n$ST254Q01JA\n[1] \"How many of the following [digital devices] are in your [home]: Televisions\"\n\n$ST254Q02JA\n[1] \"How many of the following [digital devices] are in your [home]: Desktop computers\"\n\n$ST254Q03JA\n[1] \"How many of the following [digital devices] are in your [home]: Laptop computers or notebooks\"\n\n$ST254Q04JA\n[1] \"How many of the following [digital devices] are in your [home]: Tablets (e.g. [iPad®], [BlackBerry® Playbook™])\"\n\n$ST254Q05JA\n[1] \"How many of the following [digital devices] are in your [home]: E-book readers (e.g. [Kindle™], [Kobo], [Bookeen])\"\n\n$ST254Q06JA\n[1] \"How many of the following [digital devices] are in your [home]: [Cell phones] with Internet access (i.e. smartphones)\"\n\n$ST255Q01JA\n[1] \"How many books are there in your [home]?\"\n\n$ST256Q02JA\n[1] \"How many of these books at [home]: Classical literature (e.g. [Shakespeare], [Example 2])\"\n\n$ST005Q01JA\n[1] \"What is the [highest level of schooling] completed by your mother?\"\n\n$ST007Q01JA\n[1] \"What is the [highest level of schooling] completed by your father?\"\n\n$ST019AQ01T\n[1] \"In what country were you and your parents born? You\"\n\n$ST019BQ01T\n[1] \"In what country were you and your parents born? Mother\"\n\n$ST019CQ01T\n[1] \"In what country were you and your parents born? Father\"\n\n$ST125Q01NA\n[1] \"How old were you when you started [ISCED 0]: Years\"\n\n$ST261Q01JA\n[1] \"Why miss school for 3+ months: I was bored.\"\n\n$ST261Q04JA\n[1] \"Why miss school for 3+ months: I could not reach school because of transportation problems.\"\n\n$ST062Q02TA\n[1] \"In the last two full weeks of school, how often: I [skipped] some classes\"\n\n$ST038Q08NA\n[1] \"In past 12 months, how often: Other students spread nasty rumours about me.\"\n\n$ST016Q01NA\n[1] \"Overall, how satisfied are you with your life as a whole these days?\"\n\n$ST337Q07JA\n[1] \"In your school, how often participate in: Science [club]\"\n\n$ST324Q11JA\n[1] \"Agree/disagree: School has been a waste of time.\"\n\n$ST355Q03JA\n[1] \"Confident can do in future: : Finding learning resources online on my own\"\n\n$FL150Q02TA\n[1] \"Have you learned to manage money in a course: At school as part of another subject or course\"\n\n [ reached getOption(\"max.print\") -- omitted 43 entries ]\n\n\nAlternatively, you can read a complete list of the items in PISA here: PISA 2022 student survey item descriptors\n\n\nA useful way to get a quick summary of what is in a data.frame is, the summary command. This command outputs the minimum, median, mean, maximum (and 1st and 3rd quartile values, i.e. the values at 25% and 75% of the range). For example, to get a sense of the science score variable (PV1SCIE) we can use:\n\nsummary(PISA_2022$PV1SCIE)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n    0.0   371.7   444.5   450.5   524.7   895.4",
    "crumbs": [
      "Introduction to Stats",
      "Descriptive Statistics"
    ]
  },
  {
    "objectID": "chapters/03-1-Descriptive.html#task-1---using-the-command-line",
    "href": "chapters/03-1-Descriptive.html#task-1---using-the-command-line",
    "title": "Descriptive Statistics",
    "section": "4.1 Task 1 - Using the command line",
    "text": "4.1 Task 1 - Using the command line\n\n\nUsing the command line, find out:\n\n\nThe number of students (i.e. the number of rows) in the PISA 2022 data frame\nThe number of items in our data frame (i.e. the number of columns)\nThe mean, maximum and minimum science score (don’t forget to use $)\nThe unique values of ST003D02T - what information do you think this column holds?\n\n\n\n\nAnswer\n# Using the command line\n# a) Find the number of students (i.e. the number of rows) in the PISA 2022 data frame\n\nnrow(PISA_2022)\n\n# b) The number of items in our data frame (i.e. the number of columns)\n\nncol(PISA_2022)\n\n# c) The mean, maximum and minimum science score (don't forget to use $)\n\nmean(PISA_2022$PV1SCIE)\nmax(PISA_2022$PV1SCIE)\nmin(PISA_2022$PV1SCIE)\n\n# d) The unique values of ST003D02T - what information do you think this column holds?\n\nunique(PISA_2022$ST003D02T)\n\n# This column contains students' birth months\n# You can find out the subtitle of columns using\n\nattributes(PISA_2022$ST003D02T)",
    "crumbs": [
      "Introduction to Stats",
      "Descriptive Statistics"
    ]
  },
  {
    "objectID": "chapters/03-1-Descriptive.html#task-2---using-the-summary-function",
    "href": "chapters/03-1-Descriptive.html#task-2---using-the-summary-function",
    "title": "Descriptive Statistics",
    "section": "4.2 Task 2 - Using the summary function",
    "text": "4.2 Task 2 - Using the summary function\n\n\nUsing summary find:\n\n\nThe maximum and minimum of the HOMEPOS (Wealth) variable\nThe mean reading score\nThe minimum science score in the data set\nConsider the distributions of the reading and science scores, and comment on any differences.\n\n\n\n\nAnswer\n# Using the command line\n\nsummary(PISA_2022$HOMEPOS)\n\nsummary(PISA_2022$PV1READ)\n\nsummary(PISA_2022$PV1SCIE)",
    "crumbs": [
      "Introduction to Stats",
      "Descriptive Statistics"
    ]
  },
  {
    "objectID": "chapters/03-1-Descriptive.html#task-3---creating-summary-tables",
    "href": "chapters/03-1-Descriptive.html#task-3---creating-summary-tables",
    "title": "Descriptive Statistics",
    "section": "4.3 Task 3 - Creating summary tables",
    "text": "4.3 Task 3 - Creating summary tables\n\n\n\n\n\n\nTip\n\n\n\nMake sure you have spelled the name of the variables PV1MATH, etc. correctly. They are case sensitive. You can use the function colnames(PISA_2022) to get a list of names and copy and paste them.\n\n\n\n\nFind the total number of students who responded in the United States, and their mean science, mathematics and reading scores. Compare that to the responses from the UK. Don’t forget to pipe (%&gt;%) each step!\nFilter the data frame for the UK and group_by gender (which is ST004D01T). Use summarise to find the maximum, minimum and mean scores for boys and girls in mathematics in the UK.\nFilter the data frame for the UK, the US, and group_by gender (which is ST004D01T) and country. Use summarise to compare mathematics and science achievement.\n\n\n\n\nAnswer\n# Summarising responses in the US and UK and finding means\n\nPISA_2022 %&gt;% \n filter(CNT == \"United Kingdom\" | CNT == \"United States\")%&gt;%\n  group_by(CNT)%&gt;%\n  summarise(MeanSci = mean(PV1SCIE), \n            MeanMath = mean(PV1MATH),\n            MeanRead = mean(PV1READ),\n            Total = n())\n\n# Comparing male and female mathematics performance in the UK\n\nPISA_2022 %&gt;% \n filter(CNT == \"United Kingdom\")%&gt;%\n  group_by(ST004D01T)%&gt;%\n  summarise(MeanUKMath = mean(PV1MATH),\n            MaxUKMath = max(PV1MATH),\n            MinUKMath = min(PV1MATH))\n\n# Comparing male and female mathematics performance in the UK and US\n\nPISA_2022 %&gt;% \n  filter(CNT == \"United Kingdom\" | CNT== \"United States\" )%&gt;%\n  group_by(ST004D01T, CNT)%&gt;%\n  summarise(MeanMath = mean(PV1MATH),\n            MaxMath = max(PV1MATH),\n            MinMath = min(PV1MATH))\n\n\n\n\n\n\n\n\nTip\n\n\n\nDon’t forget to use the pipe operator %&gt;% between each function!\n\n\n\nWB171Q01HA asks participants to think of the last time you had a break between classes at school: How did you feel: Happy. For students in France, find out the percentage of students who responded with the different options: Not at all A little Quite a bit Extremely Valid Skip Not Applicable Invalid No Response Missing. (Hint: don’t forget to droplevels()).\n\n\n\nAnswer\n# Finding the percentage of students who feel happy between lessons in France\n\nWellData&lt;-PISA_2022%&gt;%\n  select(CNT, WB171Q01HA)%&gt;%\n  filter(CNT == \"France\")%&gt;%\n  droplevels()\n\nWellData&lt;-as.data.frame(table(WellData))\nTotal = sum(WellData$Freq)\nWellData&lt;-WellData%&gt;%\n  mutate(WellData=round((Freq*100 / Total),1))\n\nWellData\n\n\n\nST251Q06JA asks students if they have a musical instrument in their home. What percentage of students in the UK have no instruments in their home? What is the percentage in Korea?\n\n\n\nAnswer\n# Finding the percentage of students with no musical instruments in the UK and Korea\n# Select the relevant variables, filter for the countries and group - dropping levels to cut unnecessary countries\nMusicData &lt;- PISA_2022%&gt;%\n  select(CNT, ST251Q06JA)%&gt;%\n  filter(CNT == \"United Kingdom\"|CNT == \"Korea\")%&gt;%\n  group_by(ST251Q06JA, CNT)%&gt;%\n  droplevels()\n\n# Convert to a data frame\n\nMusicData&lt;-as.data.frame(table(MusicData))\n\n# Find the total number of students to calculate percentages\nTotal = sum(MusicData$Freq)\n\n# Mutate to add a column with the percentage calculation\nMusicData&lt;-MusicData%&gt;%\n  mutate(PercComp = round((Freq*100 / Total), 1))\n\nMusicData\n\n\n\n\n\n\n\n\nTip\n\n\n\nDon’t forget to use the pipe operator %&gt;% between each function!",
    "crumbs": [
      "Introduction to Stats",
      "Descriptive Statistics"
    ]
  },
  {
    "objectID": "chapters/03-1-Descriptive.html#categorising-data",
    "href": "chapters/03-1-Descriptive.html#categorising-data",
    "title": "Descriptive Statistics",
    "section": "4.4 Categorising data",
    "text": "4.4 Categorising data\nA useful analytical choice is to categorise some a numerical variable into ordinal classes. For example, rather than treating HOMEPOS as a continuous scale, you might want to split into high and low wealth groups (for example, those above and below the mean value).\nTo do this, first calculate the mean mean(HOMEPOS). Then we add a new vector, which we will call wealthclass using the mutate function. We set the value of wealthclass using ifelse. If HOMEPOS is more than the mean score, we set wealthclass to High, and if it is anything else, we set it to Low. We do that using wealthclass = ifelse(HOMEPOS &gt; MeanUKwealth, \"High\", \"Low\"). Note, in ifelse, the first value is returned if the identity is true (i.e. if HOMEPOS &gt; MeanUKwealth wealthclass is set to High). If the value if not true, the second value is set (e.g. if HOMEPOS is not &gt; MeanUKwealth then wealthclass is set to LOW).\nFor example, create a data frame of UK participants HOMEPOS sorted into HIGH and LOW categories.\n\n# Create a data frame of UK responses\nUKPISA2022 &lt;- PISA_2022 %&gt;%\n  select(CNT, HOMEPOS) %&gt;%\n  filter(CNT == \"United Kingdom\") %&gt;%\n4  mutate(wealthclass =  ifelse(HOMEPOS &gt; mean(HOMEPOS, na.rm=TRUE),\n                               \"High\", \n                               \"Low\")) \nUKPISA2022\n\n\n4\n\nline 4 - mutate to create a new column wealthclass - if HOMEPOS is more than mean(HOMEPOS), set the column to “High” otherwise set it to “Low”\n\n\n\n\n# A tibble: 12,972 × 3\n   CNT            HOMEPOS wealthclass\n   &lt;fct&gt;            &lt;dbl&gt; &lt;chr&gt;      \n 1 United Kingdom  -1.09  Low        \n 2 United Kingdom  -0.418 Low        \n 3 United Kingdom   1.13  High       \n 4 United Kingdom  -0.829 Low        \n 5 United Kingdom  -0.274 Low        \n 6 United Kingdom  NA     &lt;NA&gt;       \n 7 United Kingdom  -0.606 Low        \n 8 United Kingdom  NA     &lt;NA&gt;       \n 9 United Kingdom   0.425 High       \n10 United Kingdom   0.998 High       \n# ℹ 12,962 more rows",
    "crumbs": [
      "Introduction to Stats",
      "Descriptive Statistics"
    ]
  },
  {
    "objectID": "chapters/03-1-Descriptive.html#seminar-activities-1",
    "href": "chapters/03-1-Descriptive.html#seminar-activities-1",
    "title": "Descriptive Statistics",
    "section": "4.5 Seminar activities",
    "text": "4.5 Seminar activities\n\n4.5.1 Task 1 Create a ranked list\n\nCreate a ranked list of countries by their mean science scores (PV1SCIE). What are the top five countries for science? Do the same for wealth (HOMEPOS). What patterns do you notice? Why might a researcher be critical of such rankings [Extension: Include the standard deviation of each country (hint: use the sd function) - can you detect any patterns?]\n\n\n\n\n\n\n\nTip\n\n\n\nNote that the PISA 2022 links wealth to HOMEPOS (a self reported measure of possessions in the home). You might want to consider the implications of that definition for interpreting the data\n\n\n\n\nShow the answer\n# Create a ranked data data frame for science\n\nPISA2022SciRank &lt;- PISA_2022 %&gt;%\n  select(CNT, PV1SCIE) %&gt;% # Select variables of interest\n  group_by(CNT) %&gt;% # group by country\n  summarise(meansci = mean(PV1SCIE)) %&gt;% \n     # summarise  country data to find the mean Sci score\n  arrange(desc(meansci)) # arrange in descending order based on the meansci score\n\nprint(PISA2022SciRank)\n\n\n# A tibble: 80 × 2\n   CNT               meansci\n   &lt;fct&gt;               &lt;dbl&gt;\n 1 Singapore            561.\n 2 Japan                546.\n 3 Macao (China)        543.\n 4 Korea                531.\n 5 Estonia              527.\n 6 Chinese Taipei       527.\n 7 Hong Kong (China)    525.\n 8 Czech Republic       511.\n 9 Australia            508.\n10 Poland               505.\n# ℹ 70 more rows\n\n\nShow the answer\n# And repeat the ranking for wealth\n\nPISA2022WealthRank &lt;- PISA_2022 %&gt;%\n  select(CNT, HOMEPOS) %&gt;% # Select variables of interest\n  group_by(CNT) %&gt;% # group by country\n  summarise(meanwel = mean(HOMEPOS, na.rm=TRUE)) %&gt;% \n     # summarise  country data to find the mean Sci score\n  arrange(desc(meanwel)) # arrange in descending order based on the meansci score\n\nprint(PISA2022WealthRank)\n\n\n# A tibble: 80 × 2\n   CNT         meanwel\n   &lt;fct&gt;         &lt;dbl&gt;\n 1 Norway        0.547\n 2 Australia     0.483\n 3 Korea         0.371\n 4 New Zealand   0.367\n 5 Canada        0.348\n 6 Iceland       0.346\n 7 Sweden        0.327\n 8 Ireland       0.318\n 9 Malta         0.308\n10 Austria       0.280\n# ℹ 70 more rows\n\n\nShow the answer\n# With standard deviations\n\nPISA2022SciRank &lt;- PISA_2022 %&gt;%\n  select(CNT, PV1SCIE) %&gt;% # Select variables of interest\n  group_by(CNT) %&gt;% # group by country\n  summarise(meansci = mean(PV1SCIE), \n            sdsci = sd(PV1SCIE)) %&gt;% \n  # summarise  country data to find the mean Sci score\n  arrange(desc(meansci)) # arrange in descending order based on the meansci score\n\nprint(PISA2022SciRank)\n\n\n# A tibble: 80 × 3\n   CNT               meansci sdsci\n   &lt;fct&gt;               &lt;dbl&gt; &lt;dbl&gt;\n 1 Singapore            561.  99.6\n 2 Japan                546.  92.7\n 3 Macao (China)        543.  86.6\n 4 Korea                531. 104. \n 5 Estonia              527.  87.7\n 6 Chinese Taipei       527. 102. \n 7 Hong Kong (China)    525.  91.1\n 8 Czech Republic       511. 103. \n 9 Australia            508. 107. \n10 Poland               505.  94.2\n# ℹ 70 more rows\n\n\nShow the answer\nPISA2022WealthRank &lt;- PISA_2022%&gt;%\n  select(CNT, HOMEPOS)%&gt;% # Select variables of interest\n  group_by(CNT) %&gt;% # group by country\n  summarise(meanwel = mean(HOMEPOS, na.rm=TRUE),\n            sdwel = sd(HOMEPOS, na.rm=TRUE)) %&gt;% \n  # summarise  country data to find  mean wealth score\n  arrange(desc(meanwel)) \n  # arrange in descending order based on the meanwel score\nprint(PISA2022WealthRank)\n\n\n# A tibble: 80 × 3\n   CNT         meanwel sdwel\n   &lt;fct&gt;         &lt;dbl&gt; &lt;dbl&gt;\n 1 Norway        0.547 0.970\n 2 Australia     0.483 0.861\n 3 Korea         0.371 1.01 \n 4 New Zealand   0.367 0.862\n 5 Canada        0.348 0.867\n 6 Iceland       0.346 0.805\n 7 Sweden        0.327 0.878\n 8 Ireland       0.318 0.818\n 9 Malta         0.308 0.857\n10 Austria       0.280 0.938\n# ℹ 70 more rows\n\n\n\n\n4.5.2 Task 2 Categorise HOMEPOS scores\n\nCategorising Variables\nSplit the HOMEPOS variable for the UK and Germany into the following groups:\n\n\n\nHOMEPOS\nName of category\n\n\n\n\n&gt;1\nVery High\n\n\n0&gt;HOMEPOS&lt;1\nHigh\n\n\n0&lt;\nLow\n\n\n\nPlot bar graphs of participants in these categories for both countries.\n• What differences can you observe between the countries?\nHint: You can use mutate with if_else to do the categorisation. For more than two categories, you can use nested ifelses. In the example below, if the math score is more than 400, you go to the second ifelse to check if it is over 500. If both ifelses (over 400 and over 500) are met, the score is categorised as “Very High”. If the score is between 400 and 500, the first ifelse is met, but not the second, so the else condition of the second is met and the score set to “High”. If neither condition is met, the MATHSCORECAT is set to “Low”.\n\n\n\nShow the answer\n# Create a data frame for the UK and Germany\n# Mutate the WTHCTG (wealth category) column by the boundaries of wealth categories\nWealth &lt;- PISA_2022 %&gt;%\n  select(CNT, HOMEPOS) %&gt;%\n  filter(CNT == \"United Kingdom\" | CNT == \"Germany\") %&gt;%\n  mutate(WTHCTG = ifelse(HOMEPOS &gt; 0, \n                       ifelse(HOMEPOS &gt; 1,\n                             \"Very high\",\n                             \"High\"), \n                       \"Low\"))%&gt;%\n  group_by(CNT) %&gt;%\n  droplevels()\n\nggplot(data = Wealth, \n       aes(x = WTHCTG, fill = WTHCTG))+\n  geom_bar()+\n  facet_wrap(.~CNT)+\n  xlab(\"Wealth grouping\")",
    "crumbs": [
      "Introduction to Stats",
      "Descriptive Statistics"
    ]
  },
  {
    "objectID": "chapters/A5-Self_Study_Tasks.html",
    "href": "chapters/A5-Self_Study_Tasks.html",
    "title": "Self Study Tasks",
    "section": "",
    "text": "The pages below set out a series of graded challenges that you can use to test your R and statistical skills. Sample code that solves each problem is included so you can compare your solution with ours. Don’t worry if you solve something in a different way, there will be multiple solutions to the same task. The tasks are all set on the PISA_2022 data set: PISA_2022\nTo load the data, use the code below:",
    "crumbs": [
      "Appendices",
      "Self Study Tasks"
    ]
  },
  {
    "objectID": "chapters/A5-Self_Study_Tasks.html#task-1-practice-creating-a-summary-table-1",
    "href": "chapters/A5-Self_Study_Tasks.html#task-1-practice-creating-a-summary-table-1",
    "title": "Self Study Tasks",
    "section": "\n0.1 Task 1 Practice creating a summary table #1",
    "text": "0.1 Task 1 Practice creating a summary table #1\n\nCreate a table that summarises the mean PISA science scores by country. You will need to use the group_by, summarise and mean functions.\n\nShow the codePISAsummary&lt;-PISA_2022%&gt;%  # Pipe the overall frame to a summary data.frame\n  select(CNT, PV1SCIE)%&gt;%  # Select the two required columns\n  group_by(CNT) %&gt;%        # Group the entries by country\n  summarise(meansci = mean(PV1SCIE)) # calculate means for each country\n\nprint(PISAsummary)\n\n# A tibble: 80 × 2\n   CNT                  meansci\n   &lt;fct&gt;                  &lt;dbl&gt;\n 1 Albania                 376.\n 2 United Arab Emirates    436.\n 3 Argentina               415.\n 4 Australia               508.\n 5 Austria                 494.\n 6 Belgium                 495.\n 7 Bulgaria                422.\n 8 Brazil                  406.\n 9 Brunei Darussalam       445.\n10 Canada                  499.\n# ℹ 70 more rows\n\n\nExtension: use the signif function to give the responses to three significant figures",
    "crumbs": [
      "Appendices",
      "Self Study Tasks"
    ]
  },
  {
    "objectID": "chapters/A5-Self_Study_Tasks.html#task-2-practice-creating-a-summary-table-including-percentages-2",
    "href": "chapters/A5-Self_Study_Tasks.html#task-2-practice-creating-a-summary-table-including-percentages-2",
    "title": "Self Study Tasks",
    "section": "\n0.2 Task 2 Practice creating a summary table (including percentages) #2",
    "text": "0.2 Task 2 Practice creating a summary table (including percentages) #2\n\nUse the table function to create a summary of numbers of speakers of different languages (LANGN) recorded in the data frame for the UK. Use the mutate function to turn these into percentages (you will need to calculate a total)\n\nShow the codeUKPISA&lt;-PISA_2022%&gt;%\n  select(CNT,LANGN)%&gt;%               # Select the country school type \n  filter(CNT == \"United Kingdom\")%&gt;%  # filter for the UK\n  select(LANGN) %&gt;%                  # Just select the language (removing country)\n  droplevels()                                   \n\nUKPISA&lt;-xtabs(data=UKPISA, ~ LANGN)  # Create a summary of counts\n                                    # To manipulate the table it is\nUKPISA&lt;-as.data.frame(UKPISA)       # easier to convert it to a \n                                    # a data.frame\n\nUKPISA&lt;-mutate(UKPISA, per = Freq / sum(Freq)*100)\nUKPISA  \n\n                            LANGN Freq         per\n1                           Scots  387  2.98334875\n2                         English 9710 74.85353068\n3                           Welsh  137  1.05612088\n4                 Scottish Gaelic    7  0.05396238\n5                           Irish   28  0.21584952\n6  Other European languages (QSC)  154  1.18717237\n7                    Ulster Scots   41  0.31606537\n8   A non-European Union language  128  0.98674067\n9          Another language (QUK)  809  6.23650940\n10                        Missing 1571 12.11069997\n\nShow the code# If you want to sort the data (arrange descending by the percentage vector)\nUKPISA&lt;-UKPISA%&gt;%\n  arrange(desc(per))\nUKPISA\n\n                            LANGN Freq         per\n1                         English 9710 74.85353068\n2                         Missing 1571 12.11069997\n3          Another language (QUK)  809  6.23650940\n4                           Scots  387  2.98334875\n5  Other European languages (QSC)  154  1.18717237\n6                           Welsh  137  1.05612088\n7   A non-European Union language  128  0.98674067\n8                    Ulster Scots   41  0.31606537\n9                           Irish   28  0.21584952\n10                Scottish Gaelic    7  0.05396238",
    "crumbs": [
      "Appendices",
      "Self Study Tasks"
    ]
  },
  {
    "objectID": "chapters/A5-Self_Study_Tasks.html#task-3-practice-pivoting-a-table",
    "href": "chapters/A5-Self_Study_Tasks.html#task-3-practice-pivoting-a-table",
    "title": "Self Study Tasks",
    "section": "\n0.3 Task 3 Practice pivoting a table",
    "text": "0.3 Task 3 Practice pivoting a table\n\nConvert a table of UK Science, Maths and Reading scores, extracted from the main data set, into the long format R prefers. In the long format, each score becomes a single so each student will have three entries.\n\nShow the code# Create a data frame in wide format, with three columns for each student's scores (math, reading and science)\nUKScores&lt;-PISA_2022%&gt;%\n  select(CNT,PV1MATH, PV1READ, PV1SCIE)%&gt;%\n  filter(CNT == \"United Kingdom\")%&gt;%\n  select(PV1MATH, PV1READ, PV1SCIE)\n# Use pivot longer to turn the three columns into one. First, pass pivotlonger the dataframe to be converted, then the three columns\n# to convert into one, the name of the new longer column and the\n# name of the new scores column\n\nUKScores&lt;-pivot_longer(UKScores, cols = c('PV1MATH', 'PV1READ', 'PV1SCIE'),\n                       names_to = 'Subject', values_to = 'Score' )",
    "crumbs": [
      "Appendices",
      "Self Study Tasks"
    ]
  },
  {
    "objectID": "chapters/A5-Self_Study_Tasks.html#task-4-graphing-practice-1-a-bar-chart",
    "href": "chapters/A5-Self_Study_Tasks.html#task-4-graphing-practice-1-a-bar-chart",
    "title": "Self Study Tasks",
    "section": "\n0.4 Task 4 Graphing Practice #1 A Bar Chart",
    "text": "0.4 Task 4 Graphing Practice #1 A Bar Chart\n\nDraw a bar chart of the mean mathematics scores for Germany, the UK, the US and China\n\nShow the codePlotdata&lt;-PISA_2022%&gt;%\n  select(CNT, PV1MATH)%&gt;%\n  filter(CNT == \"United Kingdom\"| CNT == \"United States\"|\n           CNT == \"Germany\"| CNT == \"B-S-J-Z (China)\")%&gt;%\n  group_by(CNT)%&gt;%\n  summarise(mean = mean(PV1MATH))\n\nggplot(Plotdata,               # Pass the data to be plotted to ggplot\n       aes(x = CNT, y = mean))+    # set the x and y varibale\n  geom_col(fill = \"red\")         # plot a column graph and fill in red",
    "crumbs": [
      "Appendices",
      "Self Study Tasks"
    ]
  },
  {
    "objectID": "chapters/A5-Self_Study_Tasks.html#task-5-graphing-practice-2-a-bar-chart-with-two-series",
    "href": "chapters/A5-Self_Study_Tasks.html#task-5-graphing-practice-2-a-bar-chart-with-two-series",
    "title": "Self Study Tasks",
    "section": "\n0.5 Task 5 Graphing Practice #2 A Bar Chart with two series",
    "text": "0.5 Task 5 Graphing Practice #2 A Bar Chart with two series\n\nDraw a bar chart of the mean mathematics scores for Germany, the UK, the US and Korea for boys and girls\n\nShow the codePlotdata&lt;-PISA_2022%&gt;%\n  select(CNT, PV1MATH, ST004D01T)%&gt;%\n  filter(CNT == \"United Kingdom\"|CNT==\"United States\"|\n           CNT == \"Germany\"|CNT == \"Korea\")%&gt;%\n  group_by(CNT, ST004D01T)%&gt;%\n  summarise(mean = mean(PV1MATH))\n\nggplot(Plotdata,\n       aes(x = CNT, y=mean, fill = ST004D01T))+ # Setting the fill to the gender\n                                            # variable gives two series\n  geom_col(position = position_dodge())     # position_dodge here means the\n\n\n\n\n\n\nShow the code                                            # means the bars are plotted                                                # side by side",
    "crumbs": [
      "Appendices",
      "Self Study Tasks"
    ]
  },
  {
    "objectID": "chapters/A5-Self_Study_Tasks.html#task-6-graphing-practice-3-a-scatter-plot",
    "href": "chapters/A5-Self_Study_Tasks.html#task-6-graphing-practice-3-a-scatter-plot",
    "title": "Self Study Tasks",
    "section": "\n0.6 Task 6 Graphing Practice #3 A scatter plot",
    "text": "0.6 Task 6 Graphing Practice #3 A scatter plot\n\nPlot a graph of science scores against mathematics scores for students in the UK\n\nShow the codePlotdata&lt;-PISA_2022%&gt;%              # Create a new data frame to be plotted\n  select(CNT, PV1MATH, PV1SCIE)%&gt;%  # Choose the country, and scores vectors\n  filter(CNT == \"United Kingdom\")    # Filter for only Uk results\n\nggplot(Plotdata,                  # Pass the data to be plotted to ggplot\n       aes(x = PV1MATH, y = PV1SCIE))+ # Define the x and y variable\n      geom_point(size = 0.1, alpha = 0.2, colour=\"red\")+ \n                                  # Use geom-point to create a scatter                                      # graph and set the size of the point \n                                    # alpha (i.e transparency)\n      labs(x = \"Math Score\", y = \"Science score\") # Add clearer labels",
    "crumbs": [
      "Appendices",
      "Self Study Tasks"
    ]
  },
  {
    "objectID": "chapters/A5-Self_Study_Tasks.html#task-7-graphing-practice-4-a-scatter-plot-with-multiple-series",
    "href": "chapters/A5-Self_Study_Tasks.html#task-7-graphing-practice-4-a-scatter-plot-with-multiple-series",
    "title": "Self Study Tasks",
    "section": "\n0.7 Task 7 Graphing Practice #4 A scatter plot with multiple series",
    "text": "0.7 Task 7 Graphing Practice #4 A scatter plot with multiple series\n\nPlot a graph of science scores against mathematics scores for students in the UK, with data split into two series for boys and girls\n\nShow the codePlotdata&lt;-PISA_2022%&gt;%              # Create a new dataframe to be plotted\n  select(CNT, PV1MATH, PV1SCIE, ST004D01T)%&gt;%  \n  filter(CNT == \"United Kingdom\")    # Filter for only Uk results\n\nggplot(Plotdata,                  \n       aes(x = PV1MATH, y = PV1SCIE, colour = ST004D01T))+ \n      geom_point(size = 0.1, alpha = 0.2)+ \n                          # As above, but set colour by the gender varibale\n      labs(x = \"Math Score\", y = \"Science score\")",
    "crumbs": [
      "Appendices",
      "Self Study Tasks"
    ]
  },
  {
    "objectID": "chapters/A5-Self_Study_Tasks.html#task-8-graphing-practice-4-a-scatter-plot-with-varying-size-points",
    "href": "chapters/A5-Self_Study_Tasks.html#task-8-graphing-practice-4-a-scatter-plot-with-varying-size-points",
    "title": "Self Study Tasks",
    "section": "\n0.8 Task 8 Graphing Practice #4 A scatter plot with varying size points",
    "text": "0.8 Task 8 Graphing Practice #4 A scatter plot with varying size points\n\nPlot a graph of mean science scores against mean mathematics scores for all the countries in the data set. Vary the point size by the number of students per country.\n\nShow the codePlotdata&lt;-PISA_2022%&gt;%\n  select(CNT, PV1MATH, PV1SCIE) %&gt;%\n  group_by(CNT) %&gt;%\n  summarise(meansci = mean(PV1SCIE), meanmath=mean(PV1MATH), total=n())\n\n  # Summarise finds mean scores by countries and n() is used to sum\n  # the number of students in each country\n\nggplot(Plotdata,\n       aes(x = meansci, y = meanmath, size = total, colour = \"red\"))+\n  # The size aesthetic is set to the total entries value computed\n  # for the data set\n  geom_point()+\n  labs(x = \"Mean science score\", y = \"Mean math score\")",
    "crumbs": [
      "Appendices",
      "Self Study Tasks"
    ]
  },
  {
    "objectID": "chapters/A5-Self_Study_Tasks.html#task-9-graphing-practice-5-a-mosaic-plot",
    "href": "chapters/A5-Self_Study_Tasks.html#task-9-graphing-practice-5-a-mosaic-plot",
    "title": "Self Study Tasks",
    "section": "\n0.9 Task 9 Graphing Practice #5 A mosaic plot",
    "text": "0.9 Task 9 Graphing Practice #5 A mosaic plot\n\nPlot a mosaic plot of the number of students who speak (use LANGN) French and Spanish in the whole data set\n\nShow the codeLang&lt;-PISA_2022 %&gt;%\n  select(ST004D01T, LANGN) %&gt;%\n  filter(LANGN == \"French\" | LANGN == \"Spanish\") %&gt;%\n  na.omit() %&gt;%\n  droplevels()\n\nlibrary(ggmosaic)\nggplot(Lang)+\n  geom_mosaic(aes(x = product(ST004D01T, LANGN), fill = LANGN))",
    "crumbs": [
      "Appendices",
      "Self Study Tasks"
    ]
  },
  {
    "objectID": "chapters/A5-Self_Study_Tasks.html#task-10-t-test-practice-1",
    "href": "chapters/A5-Self_Study_Tasks.html#task-10-t-test-practice-1",
    "title": "Self Study Tasks",
    "section": "\n0.10 Task 10 T-test practice #1",
    "text": "0.10 Task 10 T-test practice #1\n\nUsing the PISA 2022 data set, determine if there are statistically significant differences between the science, reading and mathematics scores of the UK and the US.\n\nShow the code# Create data frames with the score results for UK and US\nUKscores&lt;-PISA_2022%&gt;%\n  select(CNT,PV1MATH,PV1READ, PV1SCIE)%&gt;%\n  filter(CNT == \"United Kingdom\")\n\nUSscores&lt;-PISA_2022%&gt;%\n  select(CNT,PV1MATH,PV1READ, PV1SCIE)%&gt;%\n  filter(CNT == \"United States\")\n\n# Perform the t-test with maths results\n\nt.test(UKscores$PV1MATH, USscores$PV1MATH)\n\n\n    Welch Two Sample t-test\n\ndata:  UKscores$PV1MATH and USscores$PV1MATH\nt = 12.614, df = 7958.4, p-value &lt; 2.2e-16\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n 17.45734 23.88158\nsample estimates:\nmean of x mean of y \n 482.5427  461.8733 \n\nShow the code# p-value is &lt; 2.2e-16 so significant differences exist for maths\n\nt.test(UKscores$PV1READ, USscores$PV1READ)\n\n\n    Welch Two Sample t-test\n\ndata:  UKscores$PV1READ and USscores$PV1READ\nt = -6.4317, df = 7555.2, p-value = 1.339e-10\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -15.887576  -8.465219\nsample estimates:\nmean of x mean of y \n 490.7616  502.9380 \n\nShow the code# p-value = 1.339e-10 - statistically significant differences exist for reading between Uk and US\n\nt.test(UKscores$PV1SCIE, USscores$PV1SCIE)\n\n\n    Welch Two Sample t-test\n\ndata:  UKscores$PV1SCIE and USscores$PV1SCIE\nt = -3.2425, df = 7545.7, p-value = 0.00119\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -9.604044 -2.366899\nsample estimates:\nmean of x mean of y \n 492.2651  498.2506 \n\nShow the code# p-value = 0.00119  significant differences exist for science between the UK and US",
    "crumbs": [
      "Appendices",
      "Self Study Tasks"
    ]
  },
  {
    "objectID": "chapters/A5-Self_Study_Tasks.html#task-11-t-test-practice-2",
    "href": "chapters/A5-Self_Study_Tasks.html#task-11-t-test-practice-2",
    "title": "Self Study Tasks",
    "section": "\n0.11 Task 11 T-test practice #2",
    "text": "0.11 Task 11 T-test practice #2\n\nDivide the UK population into two groups, those that have internet access at home (ST250Q05JA) and those who do not. Are there statistically significant differences in the means of their reading, science and mathematics scores?\n\nShow the code# Create data frames with the score results for UK in two\n# groups, has internet and no internet, based on ST011Q06TA\n\nUKHasIntscores&lt;-PISA_2022%&gt;%\n  select(CNT,PV1MATH,PV1READ, PV1SCIE, ST250Q05JA)%&gt;%\n  filter(CNT==\"United Kingdom\" & ST250Q05JA == \"Yes\")\n\nUKNoIntscores&lt;-PISA_2022%&gt;%\n  select(CNT,PV1MATH,PV1READ, PV1SCIE, ST250Q05JA)%&gt;%\n  filter(CNT==\"United Kingdom\" & ST250Q05JA == \"No\")\n\n# Perform the t-test with maths results\nt.test(UKHasIntscores$PV1MATH, UKNoIntscores$PV1MATH)\n\n\n    Welch Two Sample t-test\n\ndata:  UKHasIntscores$PV1MATH and UKNoIntscores$PV1MATH\nt = 10.177, df = 86.803, p-value &lt; 2.2e-16\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n  72.1637 107.1935\nsample estimates:\nmean of x mean of y \n 485.8926  396.2140 \n\nShow the code# p-value is &lt; 2.2e-16 so no significant differences for maths scores from\n\n# those with and without internet\n\nt.test(UKHasIntscores$PV1READ, UKNoIntscores$PV1READ)\n\n\n    Welch Two Sample t-test\n\ndata:  UKHasIntscores$PV1READ and UKNoIntscores$PV1READ\nt = 10.117, df = 86.294, p-value = 2.547e-16\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n  92.92909 138.37826\nsample estimates:\nmean of x mean of y \n 495.4067  379.7530 \n\nShow the code# p-value = 2.547e-16 so no signficant differences for reading scores from\n\n# those with and without internet\n\nt.test(UKHasIntscores$PV1SCIE, UKNoIntscores$PV1SCIE)\n\n\n    Welch Two Sample t-test\n\ndata:  UKHasIntscores$PV1SCIE and UKNoIntscores$PV1SCIE\nt = 9.3975, df = 86.657, p-value = 7.135e-15\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n  73.60024 113.08755\nsample estimates:\nmean of x mean of y \n 495.8116  402.4677 \n\nShow the code# p-value = 7.135e-15 so no signficant differences for science scores from\n# those with and without internet",
    "crumbs": [
      "Appendices",
      "Self Study Tasks"
    ]
  },
  {
    "objectID": "chapters/A5-Self_Study_Tasks.html#task-12-t-test-practice-3",
    "href": "chapters/A5-Self_Study_Tasks.html#task-12-t-test-practice-3",
    "title": "Self Study Tasks",
    "section": "\n0.12 Task 12 T-test practice #3",
    "text": "0.12 Task 12 T-test practice #3\n\nUsing the PISA 2022 data set, are the mean mathematics scores of US boys and girls different to a statistically significant degree?\n\nShow the code# Create a data frame of US boys math scores\n\nUSboys &lt;- PISA_2022 %&gt;%\n  select(CNT, PV1MATH, ST004D01T)%&gt;%\n  filter(CNT == \"United States\")\n\n# Create a dataframe of US girls math scores\n\nUSgirls &lt;- PISA_2022 %&gt;%\n  select(CNT, PV1MATH, ST004D01T) %&gt;%\n  filter(CNT == \"United States\")\n\n# Perform the t-test, using $PVMATH to indicate which column of the data frame to use\n\nt.test(USboys$PV1MATH, USgirls$PV1MATH)\n\n\n    Welch Two Sample t-test\n\ndata:  USboys$PV1MATH and USgirls$PV1MATH\nt = 0, df = 9102, p-value = 1\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -3.90872  3.90872\nsample estimates:\nmean of x mean of y \n 461.8733  461.8733 \n\nShow the code# The p-value is 1 which is over 0.05 suggesting we accept the null hypothesis, there are no  statistically significant difference in US girls and boys math scores",
    "crumbs": [
      "Appendices",
      "Self Study Tasks"
    ]
  },
  {
    "objectID": "chapters/A5-Self_Study_Tasks.html#task-13-t-test-practice-3",
    "href": "chapters/A5-Self_Study_Tasks.html#task-13-t-test-practice-3",
    "title": "Self Study Tasks",
    "section": "\n0.13 Task 13 T-test practice #3",
    "text": "0.13 Task 13 T-test practice #3\n\nAre the mean science scores of all students in the US and the UK different to a statistically significant degree?\n\nShow the code# Create a data frame of US science scores\n\nUSSci&lt;-PISA_2022 %&gt;%\n  select(CNT, PV1SCIE)%&gt;%\n  filter(CNT == \"United States\")\n\n# Create a data frame of UK science scores\n\nUKSci&lt;-PISA_2022 %&gt;%\n  select(CNT, PV1SCIE)%&gt;%\n  filter(CNT == \"United Kingdom\")\n\n# Perform the t-test, using $PV1SCIE to indicate which column of the dataframe to use\n\nt.test(USSci$PV1SCIE, UKSci$PV1SCIE)\n\n\n    Welch Two Sample t-test\n\ndata:  USSci$PV1SCIE and UKSci$PV1SCIE\nt = 3.2425, df = 7545.7, p-value = 0.00119\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n 2.366899 9.604044\nsample estimates:\nmean of x mean of y \n 498.2506  492.2651 \n\nShow the code# The p-value is 0.00119, less than 0.05, so we reject the null hypothesis, there are statistically significant differences between US and UK science scores",
    "crumbs": [
      "Appendices",
      "Self Study Tasks"
    ]
  },
  {
    "objectID": "chapters/A5-Self_Study_Tasks.html#task-14-kruskal-wallis-practice-1",
    "href": "chapters/A5-Self_Study_Tasks.html#task-14-kruskal-wallis-practice-1",
    "title": "Self Study Tasks",
    "section": "\n0.14 Task 14 Kruskal Wallis practice #1",
    "text": "0.14 Task 14 Kruskal Wallis practice #1\n\nAre there statistically significant differences in the proportion of boys and girls who Working in household/take care of family members before or after school (WORKHOME) for the whole dataset? Note the responses are:\n\nNo work in household or care of family members\n1 time of working in household or caring for family members per week\n2 times of working in household or caring for family members per week\n3 times of working in household or caring for family members per week\n4 times of working in household or caring for family members per week\n5 times of working in household or caring for family members per week\n6 times of working in household or caring for family members per week\n7 times of working in household or caring for family members per week\n8 times of working in household or caring for family members per week\n9 times of working in household or caring for family members per week\n10 or more times of working in household or caring for family members per week\n\n\nShow the code# Create a data frame of including gender and working or caring\n\nworkcare &lt;- PISA_2022 %&gt;%\n  select(WORKHOME, ST004D01T) %&gt;%\n  filter(!is.na(WORKHOME))\n\n# As the data are ordinal, use a kurskal wallis test\n\nkruskal.test(data=workcare, WORKHOME ~ ST004D01T )\n\n# p-value &lt; 2.2e-16 so there are statistically significant differences between genders\n\n# plot the results\n\nworkcare&lt;-workcare %&gt;%\n  droplevels()%&gt;%\n  na.omit()\n\nggplot(data = workcare)+\n   geom_mosaic(aes(x=product(WORKHOME, ST004D01T), fill=WORKHOME))+\n  scale_y_discrete(label=abbreviate)",
    "crumbs": [
      "Appendices",
      "Self Study Tasks"
    ]
  },
  {
    "objectID": "chapters/A5-Self_Study_Tasks.html#task-15-chi-square-practice-1",
    "href": "chapters/A5-Self_Study_Tasks.html#task-15-chi-square-practice-1",
    "title": "Self Study Tasks",
    "section": "\n0.15 Task 15 Chi-square practice #1",
    "text": "0.15 Task 15 Chi-square practice #1\n\nAre there statistically significant differences, in the US, in the languages spoken (LANGN) by boys and girls?\n\nShow the code# Create a data frame of languages spoken in the US, including gender\n\nUSLang &lt;- PISA_2022 %&gt;%\n  filter(CNT == \"United States\") %&gt;%\n  select(LANGN, ST004D01T) %&gt;%\n  na.omit() %&gt;%\n  droplevels()\n\n# Create a contingency table\n\nContab &lt;- xtabs(data=USLang, ~ LANGN + ST004D01T)\n\n# Run the chi.sq test\n\nchisq.test(Contab)\n\n\n    Pearson's Chi-squared test\n\ndata:  Contab\nX-squared = 7.9695, df = 3, p-value = 0.04665\n\nShow the code# The output p-value is 0.04665 which is less than 0.05. So reject the null hypothesis. There is a difference in language by gender",
    "crumbs": [
      "Appendices",
      "Self Study Tasks"
    ]
  },
  {
    "objectID": "chapters/A5-Self_Study_Tasks.html#task-16-chi-square-practice-3",
    "href": "chapters/A5-Self_Study_Tasks.html#task-16-chi-square-practice-3",
    "title": "Self Study Tasks",
    "section": "\n0.16 Task 16 Chi-square practice #3",
    "text": "0.16 Task 16 Chi-square practice #3\n\nAre there statistically significant differences in numbers of students missing school for more than 3 months because they were bored (ST261Q01JA) between the UK and US\n\nShow the code# ST261Q01JA - Why miss school for 3+ months: I was bored.\n# Create a data frame for the two countries\n\nBored &lt;- PISA_2022 %&gt;%\n  select(CNT, ST261Q01JA) %&gt;%\n  filter(CNT == \"United Kingdom\" | CNT == \"United States\") %&gt;%\n  droplevels() %&gt;%\n  na.omit()\n\n# Create a contingency table\n\nContab &lt;- xtabs(data=Bored, ~ CNT + ST261Q01JA)\n\n# Do the chi squared test\n\nchisq.test(Contab)\n\n\n    Pearson's Chi-squared test with Yates' continuity correction\n\ndata:  Contab\nX-squared = 26.573, df = 1, p-value = 2.537e-07\n\nShow the code# p-value is less than 0.05 (2.537e-07), so reject the null hypotheses - there are statistically significant differences in boredom in the UK and the US",
    "crumbs": [
      "Appendices",
      "Self Study Tasks"
    ]
  },
  {
    "objectID": "chapters/A5-Self_Study_Tasks.html#task-18-anova-practice-1",
    "href": "chapters/A5-Self_Study_Tasks.html#task-18-anova-practice-1",
    "title": "Self Study Tasks",
    "section": "\n0.17 Task 18 Anova practice #1",
    "text": "0.17 Task 18 Anova practice #1\n\nAre there statistically significant differences in mathematics scores of students in France, Germany, Spain, the UK and Italy? Find between which pairs of countries there are statistically significant differences in mathematics scores.\n\nShow the code# Create a data frame of the required countries\n\nEuroPISA &lt;- PISA_2022 %&gt;%\n  select(CNT, PV1MATH)%&gt;%\n  filter(CNT %in% c(\"Spain\", \"France\", \"United Kingdom\", \"Italy\", \"Germany\"))\n\n# Perform the anova\n\nresaov &lt;- aov(data = EuroPISA, PV1MATH ~ CNT)\nsummary(resaov)\n\n               Df    Sum Sq Mean Sq F value Pr(&gt;F)    \nCNT             4   1236408  309102      39 &lt;2e-16 ***\nResiduals   67205 532663398    7926                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nShow the code# Yes, statistically significant differences exist between the countries Pr(&gt;F) &lt;2e-16 ***\n# Perform a Tukey HSD test\n\nTukeyHSD(resaov)\n\n  Tukey multiple comparisons of means\n    95% family-wise confidence level\n\nFit: aov(formula = PV1MATH ~ CNT, data = EuroPISA)\n\n$CNT\n                             diff         lwr       upr     p adj\nSpain-Germany            3.140287  -0.2593483  6.539922 0.0862603\nFrance-Germany          -9.679799 -13.9639526 -5.395645 0.0000000\nUnited Kingdom-Germany   4.767983   1.0011433  8.534822 0.0050336\nItaly-Germany           -2.548557  -6.4513428  1.354228 0.3845106\nFrance-Spain           -12.820085 -16.0798407 -9.560330 0.0000000\nUnited Kingdom-Spain     1.627696  -0.9141750  4.169566 0.4051954\nItaly-Spain             -5.688844  -8.4281440 -2.949544 0.0000001\nUnited Kingdom-France   14.447781  10.8066875 18.088875 0.0000000\nItaly-France             7.131241   3.3496782 10.912805 0.0000027\nItaly-United Kingdom    -7.316540 -10.5001420 -4.132937 0.0000000\n\nShow the code# Significant differences p&lt;0.05 exist for all countries except: Spain-Germany; Italy-Germany, UK-Spain.",
    "crumbs": [
      "Appendices",
      "Self Study Tasks"
    ]
  },
  {
    "objectID": "chapters/A5-Self_Study_Tasks.html#task-19-anova-practice-2",
    "href": "chapters/A5-Self_Study_Tasks.html#task-19-anova-practice-2",
    "title": "Self Study Tasks",
    "section": "\n0.18 Task 19 Anova practice #2",
    "text": "0.18 Task 19 Anova practice #2\n\nFor the UK PISA 2022 data set, which variable out of HOMEPOS, ST004D01T, OCOD1 (Mother’s occupation), OCOD2 (Father’s occupation), ST250Q05JA (having a link to the internet), and highest level of parental education (HISCED) accounts for the most variation in science score? What percentage of variance is explained by each variable?\n! This is a big calculation so will take some time to compute !\n\nShow the code# Create a data frame for the UK\nUKPISA_2022 &lt;- PISA_2022 %&gt;%\n  filter(CNT == \"United Kingdom\")\n\n# Perform the anova calculation with science score as the dependent variable\n\nresaov &lt;- aov(data=UKPISA_2022, \n              PV1SCIE ~ HOMEPOS + ST004D01T + OCOD1 + OCOD2 + ST250Q05JA + HISCED)\n\n# Print the output\nsummary(resaov)\n\n              Df   Sum Sq  Mean Sq  F value   Pr(&gt;F)    \nHOMEPOS        1 13423366 13423366 1571.542  &lt; 2e-16 ***\nST004D01T      1   224779   224779   26.316 2.95e-07 ***\nOCOD1        406  7197744    17728    2.076  &lt; 2e-16 ***\nOCOD2        483  6944691    14378    1.683  &lt; 2e-16 ***\nST250Q05JA     1   110018   110018   12.880 0.000334 ***\nHISCED         9  1636209   181801   21.284  &lt; 2e-16 ***\n [ reached getOption(\"max.print\") -- omitted 1 row ]\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n2418 observations deleted due to missingness\n\nShow the code# Calculate the value of eta and multiple by a 100 to get the % of variance explained\neta &lt;- etaSquared(resaov)\neta &lt;- 100*eta\neta &lt;- as.data.frame(eta)\neta\n\n               eta.sq eta.sq.part\nHOMEPOS    3.99268041   5.1441641\nST004D01T  0.32032198   0.4331991\nOCOD1      4.63295284   5.9202525\nOCOD2      6.12139253   7.6762624\nST250Q05JA 0.08516107   0.1155381\nHISCED     1.46116663   1.9460370\n\nShow the code# The variable that explains most variation in science scores is father's occupation OCOD2 (7.7%), then home possession OCOD1 (5.9%), then wealth HOMEPOS (5.1%)",
    "crumbs": [
      "Appendices",
      "Self Study Tasks"
    ]
  },
  {
    "objectID": "chapters/A6-selecting_statistical_tools.html",
    "href": "chapters/A6-selecting_statistical_tools.html",
    "title": "Selecting statistical tools",
    "section": "",
    "text": "Look over the test selection flow chart:\n\n\nShow the code\nlibrary(DiagrammeR)\ngrViz(\"\n      digraph Random{\n      graph [layout = dot,\n      overlap =T,\n      bgcolor='white',\n      splines=line]#controls l type setup\n      node [shape = box,style='filled',\n      fillcolor='skyblue',\n      fontSize=30,fontcolor='darkgrey',\n      fontname= 'Arial']\n     a [label = 'What do you want to do?']\n     b [label = 'Test a hypothesis - on what kind of data?']\n     c [label = 'Examine a relationship']\n     d [label = 'Continuous'];\n     e [label = 'Normally Distribured/Parametric'];\n     f [label = '1 Group'];\n     g [label = 'One sample t-test', fillcolor='lightyellow'];\n     h [label = 'Do a test of normality'];\n     i [label = 'qqplot', fillcolor='lightyellow'];\n     j [label = 'Tests on skewed distributions', fillcolor='lightyellow'];\n     k [label = 'Discrete / Categorical'];\n     l [label = '2 Groups'];\n     m [label = 'Unpaired groups'];\n     n [label = 'Expected counts more than 5\\nin more than 75 per cent of cells'];\n     o [label = 'Chi-squared', fillcolor='lightyellow'];\n     p [label = 'Expected counts more than 5\\n in less than 75 per cent of cells'];\n     q [label = 'Fisher exact test', fillcolor='lightyellow'];\n     r [label = 'Continuous variables'];\n     s [label = 'Linear Regression', fillcolor='lightyellow'];\n     t [label = '2 groups']\n     u [label = 'Paired groups']\n     v [label = 'Unpaired groups']\n     w [label = 'Paired t-test', fillcolor='lightyellow']\n     x [label = 'Unpaired t-test', fillcolor='lightyellow']\n     y [label = '3 groups or more']\n     z [label = 'anova', fillcolor='lightyellow']\n     aa [label = 'Not normally distributed'] \n     a -&gt; b\n     a -&gt; c\n     b -&gt; d\n     d -&gt; h\n     h -&gt; i\n     i -&gt; aa\n     aa -&gt; j\n     i -&gt; e\n     e -&gt; f\n     f -&gt; g\n     b -&gt; k\n     k -&gt; l\n     l -&gt; m\n     m -&gt; n\n     n -&gt; o\n     m -&gt; p\n     p -&gt; q\n     c -&gt; r\n     r -&gt; s\n     e -&gt; t\n     t -&gt; u\n     t -&gt; v\n     u -&gt; w\n     v -&gt; x\n     e -&gt; y\n     y -&gt; z\n      }\")\n\n\n\n\n\n\n\n\n\nWe will continue to use the PISA_2022 dataset, make sure it is loaded.\n\n# Load PISA data\n\nlibrary(arrow)\nlibrary(tidyverse)\n\nPISA_2022 &lt;- read_parquet(r\"[&lt;folder&gt;PISA_2022_student.parquet]\")",
    "crumbs": [
      "Appendices",
      "Selecting statistical tools"
    ]
  },
  {
    "objectID": "chapters/A6-selecting_statistical_tools.html#pre-session-reading",
    "href": "chapters/A6-selecting_statistical_tools.html#pre-session-reading",
    "title": "Selecting statistical tools",
    "section": "",
    "text": "Look over the test selection flow chart:\n\n\nShow the code\nlibrary(DiagrammeR)\ngrViz(\"\n      digraph Random{\n      graph [layout = dot,\n      overlap =T,\n      bgcolor='white',\n      splines=line]#controls l type setup\n      node [shape = box,style='filled',\n      fillcolor='skyblue',\n      fontSize=30,fontcolor='darkgrey',\n      fontname= 'Arial']\n     a [label = 'What do you want to do?']\n     b [label = 'Test a hypothesis - on what kind of data?']\n     c [label = 'Examine a relationship']\n     d [label = 'Continuous'];\n     e [label = 'Normally Distribured/Parametric'];\n     f [label = '1 Group'];\n     g [label = 'One sample t-test', fillcolor='lightyellow'];\n     h [label = 'Do a test of normality'];\n     i [label = 'qqplot', fillcolor='lightyellow'];\n     j [label = 'Tests on skewed distributions', fillcolor='lightyellow'];\n     k [label = 'Discrete / Categorical'];\n     l [label = '2 Groups'];\n     m [label = 'Unpaired groups'];\n     n [label = 'Expected counts more than 5\\nin more than 75 per cent of cells'];\n     o [label = 'Chi-squared', fillcolor='lightyellow'];\n     p [label = 'Expected counts more than 5\\n in less than 75 per cent of cells'];\n     q [label = 'Fisher exact test', fillcolor='lightyellow'];\n     r [label = 'Continuous variables'];\n     s [label = 'Linear Regression', fillcolor='lightyellow'];\n     t [label = '2 groups']\n     u [label = 'Paired groups']\n     v [label = 'Unpaired groups']\n     w [label = 'Paired t-test', fillcolor='lightyellow']\n     x [label = 'Unpaired t-test', fillcolor='lightyellow']\n     y [label = '3 groups or more']\n     z [label = 'anova', fillcolor='lightyellow']\n     aa [label = 'Not normally distributed'] \n     a -&gt; b\n     a -&gt; c\n     b -&gt; d\n     d -&gt; h\n     h -&gt; i\n     i -&gt; aa\n     aa -&gt; j\n     i -&gt; e\n     e -&gt; f\n     f -&gt; g\n     b -&gt; k\n     k -&gt; l\n     l -&gt; m\n     m -&gt; n\n     n -&gt; o\n     m -&gt; p\n     p -&gt; q\n     c -&gt; r\n     r -&gt; s\n     e -&gt; t\n     t -&gt; u\n     t -&gt; v\n     u -&gt; w\n     v -&gt; x\n     e -&gt; y\n     y -&gt; z\n      }\")",
    "crumbs": [
      "Appendices",
      "Selecting statistical tools"
    ]
  },
  {
    "objectID": "chapters/A6-selecting_statistical_tools.html#pre-session-task---loading-the-data",
    "href": "chapters/A6-selecting_statistical_tools.html#pre-session-task---loading-the-data",
    "title": "Selecting statistical tools",
    "section": "",
    "text": "We will continue to use the PISA_2022 dataset, make sure it is loaded.\n\n# Load PISA data\n\nlibrary(arrow)\nlibrary(tidyverse)\n\nPISA_2022 &lt;- read_parquet(r\"[&lt;folder&gt;PISA_2022_student.parquet]\")",
    "crumbs": [
      "Appendices",
      "Selecting statistical tools"
    ]
  },
  {
    "objectID": "chapters/A6-selecting_statistical_tools.html#task-1-plot-a-graph-of-mean-science-scores-by-country",
    "href": "chapters/A6-selecting_statistical_tools.html#task-1-plot-a-graph-of-mean-science-scores-by-country",
    "title": "Selecting statistical tools",
    "section": "2.1 Task 1 Plot a graph of mean science scores by country",
    "text": "2.1 Task 1 Plot a graph of mean science scores by country\nImagine we wish to compare the mean scores of students on the science element of PISA by plotting a bar graph. First you need to use the sumarise function to calculate means by countries. Then use ggplot with geom_col to create the graph. Extension task: add error bars for the standard deviations of science scores.\n\n\nShow the code\n# Task 1: Plot a graph of mean science scores by country\n# Create a variable avgscience - for every country (Group_by(CNT)) calculate the mean\n# science score (PV1SCIE) and ignore NA (na.rm=TRUE)\n\navgscience &lt;- PISA_2022 %&gt;%\n  group_by(CNT) %&gt;%\n  summarise(mean_sci = mean(PV1SCIE, na.rm = TRUE)) %&gt;%\n  arrange(desc(mean_sci))\n\n\n# Plot the data  x=CNT (reorder to ascending order), mean science score on the y\n# Change the fill colour to red, rotate the text, locate the text and reduce the font size\nggplot(data = avgscience,\n       aes(x = reorder(CNT, - mean_sci), y = mean_sci)) +\ngeom_col(fill = \"red\") +\ntheme(axis.text.x = element_text(angle = 90, hjust = 0.95,\n                                 vjust = 0.2, \n                                 size = 5))+\n  labs(x = \"Country\", y = \"Mean Science Score\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow the code\n# Extension version: added summarise to find standard deviation \n\navgscience &lt;- PISA_2022 %&gt;% \n  group_by(CNT) %&gt;%\n  summarise(mean_sci = mean(PV1SCIE, na.rm = TRUE),\n            sd_sci = sd(PV1SCIE, na.rm = TRUE)) %&gt;%\n  arrange(desc(mean_sci))\n\n# Extension version: geom_errorbar added with aes y=mean_sci (the centre of the bar) and then the maximum and minimum set to the mean plus or minus the standard deviation (ymin=mean_sci-sd_sci, ymax=mean_sci+sd_sci) \n\nggplot(data = avgscience, \n       aes(x = reorder(CNT, -mean_sci), y = mean_sci)) +\ngeom_col(fill = \"red\") +\ntheme(axis.text.x = element_text(angle = 90, hjust = 0.95, vjust = 0.2, \n                                 size = 5))+\n  labs(x=\"Country\", y = \"Mean Science Score\")+\n  geom_errorbar(aes(y = mean_sci, ymin = mean_sci - sd_sci,\n                    ymax = mean_sci + sd_sci),\n                width = 0.5, colour='black', size = 0.5)",
    "crumbs": [
      "Appendices",
      "Selecting statistical tools"
    ]
  },
  {
    "objectID": "chapters/A6-selecting_statistical_tools.html#task-2-are-there-differences-in-science-scores-by-gender-for-the-total-data-set",
    "href": "chapters/A6-selecting_statistical_tools.html#task-2-are-there-differences-in-science-scores-by-gender-for-the-total-data-set",
    "title": "Selecting statistical tools",
    "section": "2.2 Task 2 Are there differences in science scores by gender for the total data set?",
    "text": "2.2 Task 2 Are there differences in science scores by gender for the total data set?\nConsider the kinds of variables that represent the science score. What is an appropriate test to determine differences in the means between the two groups? Create two vectors, for boys and girls, that you can feed into the t.test function.\n\n\nShow the code\n# Task 2: Are there differences in Science scores by gender for the total data set? (Yes)\n# A comparison of means of two continuous variables, use a t-test.\n\n1MaleSci &lt;- PISA_2022 %&gt;%\n2  select(ST004D01T, PV1SCIE) %&gt;%\n3  filter(ST004D01T == \"Male\")\n\n# Choose the  gender (ST004D01T) and science score columns (PV1SCIE) from  2022 data, filter for females \n# Put that data into FemaleSci\n\n4FemaleSci &lt;- PISA_2022 %&gt;%\n  select(CNT, ST004D01T, PV1SCIE) %&gt;% \n  filter(ST004D01T == \"Female\")\n\n#Do a t-test comparing MaleSci and FemaleSci\nt.test(MaleSci$PV1SCIE, FemaleSci$PV1SCIE)\n# p-value is &lt; 2.2e-16 which is less than 0.05 so statistically significant differences exist\n\n\n\n1\n\nline 1 - Pipe the data into a new data frame MaleSci\n\n2\n\nline 2 - Choose the gender (ST004D01T) and science score columns (PV1SCIE) from 2022 data\n\n3\n\nline 3 - filter for males\n\n4\n\nline 4 - repeat for females, creating a data frame FemaleSci\n\n\n\n\n\n    Welch Two Sample t-test\n\ndata:  MaleSci$PV1SCIE and FemaleSci$PV1SCIE\nt = -9.3337, df = 610738, p-value &lt; 2.2e-16\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -3.033446 -1.980566\nsample estimates:\nmean of x mean of y \n 449.2026  451.7096",
    "crumbs": [
      "Appendices",
      "Selecting statistical tools"
    ]
  },
  {
    "objectID": "chapters/A6-selecting_statistical_tools.html#task-3-are-there-differences-in-science-scores-by-gender-for-uk-students",
    "href": "chapters/A6-selecting_statistical_tools.html#task-3-are-there-differences-in-science-scores-by-gender-for-uk-students",
    "title": "Selecting statistical tools",
    "section": "2.3 Task 3 Are there differences in science scores by gender for UK students?",
    "text": "2.3 Task 3 Are there differences in science scores by gender for UK students?\nAs above, but include a filter by country.\n\n\nShow the code\n# Task 3: Are there differences in Science scores by gender for UK students? (No)\n# A comparison of means of two continuous variables, use a t-test.\n# Choose the country (CNT), gender (ST004D01T) and science score columns (PV1SCIE) from  2022 data, filter for males and the UK\n# Put that data into UKMaleSci\n\nUKMaleSci &lt;- PISA_2022 %&gt;% \n  select(CNT, ST004D01T, PV1SCIE) %&gt;% \n  filter(ST004D01T == \"Male\")  %&gt;% \n  filter(CNT == \"United Kingdom\")\n\n# Choose the country (CNT), gender (ST004D01T) and science score columns (PV1SCIE) from  data, filter for females and the UK\n# Put that data into UKFemaleSci\nUKFemaleSci &lt;- PISA_2022 %&gt;% \n  select(CNT, ST004D01T, PV1SCIE) %&gt;% \n  filter(ST004D01T == \"Female\") %&gt;% \n  filter(CNT == \"United Kingdom\")\n\n# Do a t-test comparing UKMaleSci and UKFemaleSci\nt.test(UKMaleSci$PV1SCIE, UKFemaleSci$PV1SCIE)\n\n\n\n    Welch Two Sample t-test\n\ndata:  UKMaleSci$PV1SCIE and UKFemaleSci$PV1SCIE\nt = 3.9298, df = 12964, p-value = 8.547e-05\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n  3.529142 10.553500\nsample estimates:\nmean of x mean of y \n 495.7375  488.6962 \n\n\nShow the code\n# the p-value is 0.1267 over, 0.05, so statistically significant differences between males and females",
    "crumbs": [
      "Appendices",
      "Selecting statistical tools"
    ]
  },
  {
    "objectID": "chapters/A6-selecting_statistical_tools.html#task-4-for-the-whole-data-set-is-there-a-correlation-between-students-science-score-and-reading-scores",
    "href": "chapters/A6-selecting_statistical_tools.html#task-4-for-the-whole-data-set-is-there-a-correlation-between-students-science-score-and-reading-scores",
    "title": "Selecting statistical tools",
    "section": "2.4 Task 4 For the whole data set, is there a correlation between students’ science score and reading scores?",
    "text": "2.4 Task 4 For the whole data set, is there a correlation between students’ science score and reading scores?\nReflect on the appropriate test to show correlation between two scores. This test can be carried out quite simply using a couple of lines of code. Extensions: a) perform the same analysis, but consider the impact of gender; b) Find the correlations between reading and science core by country, and rank from most highly correlated to least.\n\n\nShow the code\n# Task 4: For the whole data set, is there a correlation between students’ science score reading score? (Yes, significant 0.77)\n\n# Do the regression test between science score (PV1SCIE) and reading score (PV1READ) on the PISA_2022 data\n1lmSciRead &lt;- lm(PV1SCIE ~ PV1READ, data = PISA_2022)\nsummary(lmSciRead)\n\n# Extension 1: Add Gender:\n3lmSciRead &lt;- lm(PV1SCIE ~ PV1READ + ST004D01T, data = PISA_2022)\nsummary(lmSciRead)\n\n# Extension 2: Rank by correlation\nCNTPISA &lt;- PISA_2022 %&gt;%\n5  select(CNT, PV1SCIE, PV1READ) %&gt;%\n6  group_by(CNT)%&gt;%\n7  summarise(MeanSci = mean(PV1SCIE),\n            MeanRead = mean(PV1READ),\n            Cor=cor(PV1SCIE, PV1READ)) %&gt;%\n  arrange(desc(Cor))\n\n\n\n1\n\nline 1 - Run a linear model, predicting PV1SCIE with PV1READ, based on PISA_2022 data, then summarise\n\n3\n\nline 5 - create a new data frame CNTPISA, and PISA_2022 into it selecting country, science and reading score\n\n5\n\nline 7 - summarise to find mean science scores, in the column MeanSci, and mean reading scores in MeanRead\n\n6\n\nline 9 - For each country, find the correlation between science and reading scores, put in the column Cor\n\n7\n\nline 10 - sort the data frame in descending order of the column Cor the correlation scores\n\n\n\n\n\nCall:\nlm(formula = PV1SCIE ~ PV1READ, data = PISA_2022)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-348.75  -38.22   -1.08   37.50  384.95 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 97.890279   0.303098     323   &lt;2e-16 ***\nPV1READ      0.804547   0.000671    1199   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 57.57 on 613742 degrees of freedom\nMultiple R-squared:  0.7008,    Adjusted R-squared:  0.7008 \nF-statistic: 1.438e+06 on 1 and 613742 DF,  p-value: &lt; 2.2e-16\n\n\nCall:\nlm(formula = PV1SCIE ~ PV1READ + ST004D01T, data = PISA_2022)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-358.01  -37.74   -0.83   37.13  376.71 \n\nCoefficients:\n               Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   8.486e+01  3.180e-01   266.9   &lt;2e-16 ***\nPV1READ       8.139e-01  6.674e-04  1219.4   &lt;2e-16 ***\nST004D01TMale 1.785e+01  1.462e-01   122.1   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 56.88 on 613662 degrees of freedom\n  (79 observations deleted due to missingness)\nMultiple R-squared:  0.7079,    Adjusted R-squared:  0.7079 \nF-statistic: 7.436e+05 on 2 and 613662 DF,  p-value: &lt; 2.2e-16",
    "crumbs": [
      "Appendices",
      "Selecting statistical tools"
    ]
  },
  {
    "objectID": "chapters/A6-selecting_statistical_tools.html#task-5-plot-a-representation-of-uk-students-science-score-against-reading-score-with-a-linear-best-fit-line.",
    "href": "chapters/A6-selecting_statistical_tools.html#task-5-plot-a-representation-of-uk-students-science-score-against-reading-score-with-a-linear-best-fit-line.",
    "title": "Selecting statistical tools",
    "section": "2.5 Task 5 Plot a representation of UK students’ science score against reading score, with a linear best fit line.",
    "text": "2.5 Task 5 Plot a representation of UK students’ science score against reading score, with a linear best fit line.\nIt will help here to create a data.frame that contains a filtered version of the whole dataset you can pass to ggplot.\n\n\nShow the code\n# Task 5: Plot a representation of UK students’ science score against reading score.\n \n# Choose the three variables of interest, science score (PV1SCIE), reading score (PV1READ) and country (CNT)\n# and filter for the UK. Put the values into regplotdata\n1regplotdata &lt;- PISA_2022 %&gt;%\n2  select(PV1SCIE, PV1READ, CNT) %&gt;%\n3  filter(CNT == \"United Kingdom\")\n\n# Plot the data in regplotdata, set the science score on the x-xis and reading on y-axis, set the size, colour and alpha (transparency)\n# of points and add a linear ('lm') black line\n\nggplot(data = regplotdata, \n5       aes(x = PV1SCIE, y = PV1READ)) +\n6    geom_point(size = 0.5, colour = \"red\", alpha = 0.3) +\n7    geom_smooth(method = \"lm\", colour=\"black\")+\n    labs(x = \"Science Score\", y = \"Reading score\")\n\n\n\n1\n\nline 1 - Create a new data frame for plotting regplotdata\n\n2\n\nline 2 - Select the variables we need: PV1SCIE, PV1READ and CNT.\n\n3\n\nline 3 - filter for UK results\n\n5\n\nline 6 - set the x-axis as science scores, and y axis as reading scores\n\n6\n\nline 7 - use geom_point to plot a scatter graph, set the point colour to red, and transparency (alpha) to 0.3\n\n7\n\nline 8 - add labels",
    "crumbs": [
      "Appendices",
      "Selecting statistical tools"
    ]
  },
  {
    "objectID": "chapters/A6-selecting_statistical_tools.html#task-6-do-girls-and-boys-in-the-uk-have-different-preferences-for-maths",
    "href": "chapters/A6-selecting_statistical_tools.html#task-6-do-girls-and-boys-in-the-uk-have-different-preferences-for-maths",
    "title": "Selecting statistical tools",
    "section": "2.6 Task 6 Do girls and boys in the UK have different preferences for maths?",
    "text": "2.6 Task 6 Do girls and boys in the UK have different preferences for maths?\nThe PISA 2022 data set includes the variable MATHPREF (Preference of Math over other core subjects). Determine if the data for girls and boys are homogenous (i.e. if the null hypothesis that girls and boys have similar preferences for maths). Note the possible responses are: 0 No preference for mathematics over other subjects and 1 Preference for mathematics over other subjects\n\n\nShow the code\n# Task 6: Is there a relationship between UK boys' and girls' mathematics preferences\n  \n1chi_data &lt;- PISA_2022 %&gt;%\n2  select(CNT, ST004D01T, MATHPREF) %&gt;%\n3  filter(CNT == \"United Kingdom\")  %&gt;%\n4  droplevels() %&gt;%\n5  na.omit()\n\n# We wish to compare two categorical variables, gender (Male/Female) and preference for maths (0 = No Preference for maths/ 1= Preference for maths)\n# Create a frequency table\n\n6Mathpreftable &lt;- xtabs(data = chi_data, ~ ST004D01T + MATHPREF)\n\n# Perform the chisq.test on the data\n\n7chisq.test(Mathpreftable)\n\n# p-value= 4.554e-08 - reject the null hypothesis - boys and girls have different preferences for mathematics\n\n\n\n1\n\nline 1 - Pipe PISA_2022 to a new data frame to test: chi_data\n\n2\n\nline 2 - Select the variables we need: gender (ST004D01T), country (CNT), and math preference (MATHPEF).\n\n3\n\nline 3 - filter for UK results\n\n4\n\nline 4 - drop unneeded levels for other countries\n\n5\n\nline 5 - drop NAs\n\n6\n\nline 6 - create a contingency table of gender (ST004D01T) by maths preference (MATHPREF)\n\n7\n\nline 7 - perform the chi-square test\n\n\n\n\n\n    Pearson's Chi-squared test with Yates' continuity correction\n\ndata:  Mathpreftable\nX-squared = 29.898, df = 1, p-value = 4.554e-08",
    "crumbs": [
      "Appendices",
      "Selecting statistical tools"
    ]
  },
  {
    "objectID": "chapters/A6-selecting_statistical_tools.html#task-7-does-mathematics-preferences-explain-variation-in-mathematics-score-for-uk-students",
    "href": "chapters/A6-selecting_statistical_tools.html#task-7-does-mathematics-preferences-explain-variation-in-mathematics-score-for-uk-students",
    "title": "Selecting statistical tools",
    "section": "2.7 Task 7 Does mathematics preferences explain variation in mathematics score for UK students?",
    "text": "2.7 Task 7 Does mathematics preferences explain variation in mathematics score for UK students?\nArguments have been made the students who know more science, might engage in more environmental activism. Determine what percentage of variation in UK mathematics scores is explained by a) the variable MATHPREF (Preference of Math over other core subjectsn); b) MATHEASE (Perception of Mathematics as easier than other subjects); and c) MATHMOT (Motivation to do well in mathematics ).\n\n\nShow the code\n# Task 7: How much variability in mathematics score is explained by attitude to maths variables for UK respondents\n\nUK_data &lt;- PISA_2022 %&gt;%\n1  select(CNT, PV1MATH, MATHPREF, MATHMOT, MATHEASE) %&gt;%\n2  filter(CNT == \"United Kingdom\")  %&gt;%\n3  na.omit()\n\n# Perform the anova test\n4resaov &lt;- aov(data = UK_data,\n5              PV1MATH ~ MATHPREF + MATHMOT + MATHEASE)\n6summary(resaov)\n#&gt; Significant differences exist for MATHPREF and MATHEASE, but not for MATHMOT (Motivation to do well in mathematics)\n\n# Determine the % of variation explained\n7library(lsr)\n8eta &lt;- etaSquared(resaov)\n9eta &lt;- 100*eta\n10eta\n# MATHPREF explains only 0.54% of the variance, and MATHEASE, 0.26% (MATHMOT is not significant)\n\n\n\n1\n\nline 1 - select the variables of interest, country, maths scores, maths prefernce, maths motivation, and perception of easiness of maths\n\n2\n\nline 2 - filter for country of interest - i.e. the UK\n\n3\n\nline 3 - drop any NAs in the data\n\n4\n\nline 4 - use aov to perform the anova calculation. We set the data we are passing (data = UK_data) - we put the output into a new variable resaov\n\n5\n\nline 5 -and set that we want to determine the variance in maths scores by math preference, motivation and ease (PV1MATH ~ MATHPREF + MATHMOT + MATHEASE)\n\n6\n\nline 6 - produce a summary of resaov\n\n7\n\nline 7 - load the lsr library for the etaSquared function\n\n8\n\nline 8 - use etaSquared(resaov) to find the eta squared value. We convert this to a data frame so we can perform the next steps\n\n9\n\nline 9 - to convert the eta squared value into a percentage of variance explained, we multiply by 100\n\n\n10\n\nline 10 - print the result\n\n\n\n\n               Df   Sum Sq Mean Sq F value   Pr(&gt;F)    \nMATHPREF        1   981096  981096 108.868  &lt; 2e-16 ***\nMATHMOT         1    39980   39980   4.436   0.0352 *  \nMATHEASE        1   247557  247557  27.470 1.63e-07 ***\nResiduals   10579 95335543    9012                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n             eta.sq eta.sq.part\nMATHPREF 0.53998100  0.54418893\nMATHMOT  0.06829671  0.06915768\nMATHEASE 0.25625926  0.25899678",
    "crumbs": [
      "Appendices",
      "Selecting statistical tools"
    ]
  },
  {
    "objectID": "chapters/A4-Other_datasets.html",
    "href": "chapters/A4-Other_datasets.html",
    "title": "Other datasets",
    "section": "",
    "text": "There exist thousands of datasets that you can freely analyse. This section covers a few of the major ones for education, or that might fruitfully be combined with educational datasets such as PISA.",
    "crumbs": [
      "Appendices",
      "Other datasets"
    ]
  },
  {
    "objectID": "chapters/A4-Other_datasets.html#global-gender-gap-index-gggi",
    "href": "chapters/A4-Other_datasets.html#global-gender-gap-index-gggi",
    "title": "Other datasets",
    "section": "\n2.1 Global Gender Gap Index (GGGI)",
    "text": "2.1 Global Gender Gap Index (GGGI)\nThe world economic forum produces the Global Gender Gap Index (GGGI), this index combines female and male outcomes on Economic participation and opportunity, educational attainment, health and survival, and political empowerment.\nReports for: 2022, 2021, 2020,2018,2017,2016, 2015\nIt has proven difficult to find the 2015 dataset used by Stoet & Geary, the 2013 dataset is here",
    "crumbs": [
      "Appendices",
      "Other datasets"
    ]
  },
  {
    "objectID": "chapters/A4-Other_datasets.html#united-nations",
    "href": "chapters/A4-Other_datasets.html#united-nations",
    "title": "Other datasets",
    "section": "\n2.2 United Nations",
    "text": "2.2 United Nations\nThe UN reports on two gender specific indexes:\nGender Inequality Index (GII)\nThe Gender Inequality Index is a index incorporating data on reproductive health, empowerment and the labour market. Values range from 0 - full equality for men and women, to 0, full inequality.\nGender Development Index (GDI)\nThe Gender Development Index measures inequalities in human development, combining data on female and male life expectancy, years of schooling and earned income. Values of 1 indicate equality, with values of less than 1 showing males performing better, and values over 1 showing females doing better.\nDownloads for the GII and GDI are here",
    "crumbs": [
      "Appendices",
      "Other datasets"
    ]
  },
  {
    "objectID": "chapters/A4-Other_datasets.html#piaac",
    "href": "chapters/A4-Other_datasets.html#piaac",
    "title": "Other datasets",
    "section": "\n5.1 PIAAC",
    "text": "5.1 PIAAC\nThe Programme for the International Assessment of Adult Competencies (PIAAC) is a data set that covers the cognitive and workplace skills around numeracy, literacy and problem solving using ICT, for 16-65 year olds in 24 countries (including England/NI). Data was first collected in 2013 and again in 2023.",
    "crumbs": [
      "Appendices",
      "Other datasets"
    ]
  },
  {
    "objectID": "chapters/07-Rpublications.html",
    "href": "chapters/07-Rpublications.html",
    "title": "Publishing using R and quarto",
    "section": "",
    "text": "Quarto is a publishing framework that works with R and RStudio (and python and Julia) to allow you to produce pdfs, word docs, websites and power points for publication. Using quarto you can combine your data cleaning, data analysis, model building and graph creation, with your writing and bibliography, all in one place. This means\n\nyou don’t need to keep copy and pasting, or exporting results and graphs from R to your write up\nif the underlying data sets or models change any changes automatically filter through to your write up\nit’s easy to include the code that you use so readers can see exactly what you have done\n\nQuarto also allows you to present your findings alongside your R code. This allows for better reproducibility of work and transparency in terms of methodology.",
    "crumbs": [
      "Publications",
      "Publishing using R and quarto"
    ]
  },
  {
    "objectID": "chapters/07-Rpublications.html#the-structure-of-a-quarto-file",
    "href": "chapters/07-Rpublications.html#the-structure-of-a-quarto-file",
    "title": "Publishing using R and quarto",
    "section": "\n2.1 The structure of a quarto file",
    "text": "2.1 The structure of a quarto file\nA quarto file has three main components,\n\nthe YAML block at the top of the .qmd page allows you to specify metadata about the work, including authors, affiliations, type of output (e.g. HTML or pdf), the title, the date, license information, referencing style, location of the bibliography file etc. The YAML block needs to come at the top of the page and is delimited by the three dashes --- at the beginning and three dashes --- at the end of the YAML block\ncode blocks - quarto files allow you to intermix code blocks with text, you can define how quarto handles these blocks, e.g. displaying/hiding the code, suppressing warnings, or stopping the code block executing. More on this below\nmarkdown - this is the text and image output of your work. Markdown offers . Whilst not as fully featured as a word processor Markdown allows you to create work with simple text formatting, tables, image manipulation, links and references. For more complex formatting you can inline HTML/CSS and latex code.",
    "crumbs": [
      "Publications",
      "Publishing using R and quarto"
    ]
  },
  {
    "objectID": "chapters/07-Rpublications.html#visual-editor",
    "href": "chapters/07-Rpublications.html#visual-editor",
    "title": "Publishing using R and quarto",
    "section": "\n2.2 Visual editor",
    "text": "2.2 Visual editor\nRStudio comes with a built in what you see is what you get (WYSIWYG) visual editor for quarto files. You can toggle between the source/text view and the visual editor at the top left of the editor. Most things you can do in the source editor can be replicated in the Visual editor, though the markdown produced can sometimes be messy, especially when dealing with hand made tables.",
    "crumbs": [
      "Publications",
      "Publishing using R and quarto"
    ]
  },
  {
    "objectID": "chapters/07-Rpublications.html#basic-formatting",
    "href": "chapters/07-Rpublications.html#basic-formatting",
    "title": "Publishing using R and quarto",
    "section": "\n3.1 Basic formatting",
    "text": "3.1 Basic formatting\nYou can write a .qmd file much like you would write a plain text document, but it does also allow basic formatting using a language called markdown. Markdown lets you have text that is **bold**, *italic*and &lt;u&gt;underlined&lt;/u&gt;, it allows for linking actions, such as hyperlinks to webpages through [webpages](https://en.wikipedia.org/wiki/Main_Page)\n### This is sub header\n#### This is an even smaller header\nFor something that might be less important, you can have multiple levels of subheading by adding more #s, for example ##### would be a level 5 heading, the more #s you have the smaller the heading.",
    "crumbs": [
      "Publications",
      "Publishing using R and quarto"
    ]
  },
  {
    "objectID": "chapters/07-Rpublications.html#lists",
    "href": "chapters/07-Rpublications.html#lists",
    "title": "Publishing using R and quarto",
    "section": "\n3.2 Lists",
    "text": "3.2 Lists\nIf you need to create lists\n-   this is a list\n-   of bullet pointed\n-   created by\n-   items, which can be\n    -   indented with four spaces\n    -   before the hyphen `-`\n\nthis is a list\nof bullet pointed\ncreated by\nitems, which can be\n\nindented with four spaces\nbefore the hyphen -\n\n\n\n\nYou can also have:\n1.  numbered lists\n2.  by using numbers followed by\n3.  bullet points\n4.  You can embed [links](https://stackoverflow.com/questions/73066792/how-to-create-lettered-lists-using-quarto) in lists\n\nnumbered lists\nby using numbers followed by\nbullet points\nYou can embed links in lists",
    "crumbs": [
      "Publications",
      "Publishing using R and quarto"
    ]
  },
  {
    "objectID": "chapters/07-Rpublications.html#inserting-images",
    "href": "chapters/07-Rpublications.html#inserting-images",
    "title": "Publishing using R and quarto",
    "section": "\n3.3 Inserting images",
    "text": "3.3 Inserting images\nIf you have images that you would like to include in your writing you can insert them by using ![image caption](images/brock.jpg):\n\n\nimage caption\n\nMake sure that your images are in the images/ folder and that the address you use includes the image type, here it is .jpg in images/brock.jpg. Try to give your images sensible names or place the images for your chapter in a sub folder of the images folder, e.g. images/chpt4/amy.jpg.\nYou can adjust the size and location of the image by using the curly brackets { } and setting the width, fig-align etc:\n![image caption](images/brock.jpg){width=\"10%\" fig-align=\"left\"}\n\n\nimage caption\n\nIf you’re including images you are likely to want to reference them. Quarto allows you to use links to images within your text. First, you will need to give your image a label, this is done by adding #fig-&lt;name&gt; to the end of the image line. Note, you need a hyphen - following the word fig, you can’t use an underscore or anything else. For example:\n![image caption](images/brock.jpg){width=\"10%\" fig-align=\"left\" #fig-brock}\n\n\n\n\n\nFigure 3.1: image caption\n\n\nYou can now reference the image in your text using the @ symbol followed by the label, for example @fig-brock. This will automatically create a link to the image in the text and give the figure a number:\nYou can see a picture of Richard in @fig-brock, where the image is aligned to the left and is 10% of the page width.\nYou can see a picture of Richard in Figure 3.1, where the image is aligned to the left and is 10% of the page width.\nFind out more about using figures in the quarto documentation",
    "crumbs": [
      "Publications",
      "Publishing using R and quarto"
    ]
  },
  {
    "objectID": "chapters/07-Rpublications.html#questions-intro-to-markdown",
    "href": "chapters/07-Rpublications.html#questions-intro-to-markdown",
    "title": "Publishing using R and quarto",
    "section": "\n3.4 Questions: intro to markdown",
    "text": "3.4 Questions: intro to markdown\n\nCreate a new .qmd file to output html. Include:\n\nYAML with a title: and author:\n\na header\na sub header\na list\nitalic, bold and underlined text\ncreate a folder of images in the same location as your .qmd file\nadd an image\nrender your file using the  button\nadjust the width of the image and it’s alignment\nadd a reference to the image in the text (remember the #fig- label and the @ reference)\nexperiment with the Visual editor\nExtension: add multiple rows of images by looking at the quarto documentation and the lightbox class",
    "crumbs": [
      "Publications",
      "Publishing using R and quarto"
    ]
  },
  {
    "objectID": "chapters/07-Rpublications.html#quotes-and-references",
    "href": "chapters/07-Rpublications.html#quotes-and-references",
    "title": "Publishing using R and quarto",
    "section": "\n3.5 Quotes and references",
    "text": "3.5 Quotes and references\nIf someone has said something interesting, you can block quote them by using the right arrow &gt; quote goes here.\n\nDirt glitters as long as the sun shines. – Goethe\n\nIf you want to find out more about how to format your writing in quarto take a look at one of the helpsheet or the help website\nWhen writing you might want to add academic references to your quarto document. This is very straight forward using `bibtex` - a structured way of recording references. You can find bibtex entries for most academic references through the Google scholar cite menu:\n\nYou can also hand-craft your own references if you can’t find them online.\nYou need to add this reference to a .bib file, you can do this by creating a new file in the same folder as your .qmd file and calling it my_references.bib. You then need to go to the YAML block at the top of your .qmd file and add the line bibliography: my_references.bib. This tells quarto where to look for your references file.\n---\ntitle: \"My Thesis\"\nauthor: \"Peter EJ Kemp\"\nbibliography: my_references.bib\n---\n\n\nfile structure of a simple quarto project\n\nThe name of the reference is at the top of each entry, in the example below kuhn1970structure:\n@book{kuhn1970structure,\n  title={The structure of scientific revolutions},\n  author={Kuhn, Thomas S},\n  volume={111},\n  year={1970},\n  publisher={Chicago University of Chicago Press}\n}\nTo add a reference to your writing use [@kuhn1970structure] (remember the @ symbol) to get (Kuhn 1970). If you just require the year use [-@kuhn1970structure] - (1970). If you want to include multiple references together, use the ;, e.g. [@kuhn1970structure; @stoet2018gender] - (Kuhn 1970; Stoet and Geary 2018).\nAll your references will be included at the bottom of the page (go check them out once you have rendered your file) and you can quickly access reference information by hovering over the references inline in the text. Depending on the fields you provide and the format, e.g. @book and @article, the references will display differently.",
    "crumbs": [
      "Publications",
      "Publishing using R and quarto"
    ]
  },
  {
    "objectID": "chapters/07-Rpublications.html#questions-referencing",
    "href": "chapters/07-Rpublications.html#questions-referencing",
    "title": "Publishing using R and quarto",
    "section": "\n3.6 Questions: referencing",
    "text": "3.6 Questions: referencing\n\nUpdate your .qmd file to include:\n\na quotation\na hyperlink\ncreate a .bib file and link it from your YAML\nfind a bibtex entry on Google scholar and add it to your .bib file\nadd a reference to your text\nadd a second reference to your text\nadd a reference to the text that only includes the year\nEXTENSION: hand-craft a bibtex entry and add it to your .bib file",
    "crumbs": [
      "Publications",
      "Publishing using R and quarto"
    ]
  },
  {
    "objectID": "chapters/07-Rpublications.html#code-chunks",
    "href": "chapters/07-Rpublications.html#code-chunks",
    "title": "Publishing using R and quarto",
    "section": "\n4.1 Code chunks",
    "text": "4.1 Code chunks\nTo add a code chunk we need to place it between ```{r} and ``` lines, the results will be automatically displayed below the code:\n\n```{r}\n#| eval: true\n1 + 1\n```\n\n[1] 2\n\n\nCode blocks work much as code in a normal .R file, here we load the PISA teacher data set, filter it to only include data from Portugal, Korea, Germany and Georgia, and save the result in an object, i.e. the code doesn’t output anything. Note we load the libraries as we would in a normal .R file and set warning: false to stop the library(tidyverse) warnings from displaying in our page.\n\n```{r}\n#| eval: true\n#| warning: false\nlibrary(glue)\nlibrary(arrow)\nlibrary(tidyverse)\nteacher_df &lt;- read_parquet(glue(\"{qerkcl_data}pisa/2022/PISA_teacher_2022.parquet\"))\nteacher_df &lt;- teacher_df %&gt;% \n                filter(CNT %in% c(\"Portugal\", \"Korea\", \"Germany\", \"Georgia\"))\n```\n\nNow that we have data loaded we can peek at the top few rows using head(&lt;rows&gt;):\n\n```{r}\n#| eval: true\nteacher_df %&gt;% \n  select(CNT,TCHTYPE) %&gt;% \n  head(3)\n```\n\n# A tibble: 3 × 2\n  CNT     TCHTYPE            \n  &lt;fct&gt;   &lt;fct&gt;              \n1 Georgia Mathematics Teacher\n2 Georgia General Teacher    \n3 Georgia Mathematics Teacher\n\n\nBut maybe we want to show the reviewer some code without actually running it. To do this we can pass variables to the code chunks through the use of #| setting: value that tell quarto how to handle each chunk. For example, by adding #| eval: false to the top of the code chunk. The code then displays, but doesn’t run (evaluate):\n\n```{r}\nteacher_df %&gt;% \n  head(3)\n```\n\nWe might want to do the opposite, to run the code chunk but display the output and not the code that produced the output. To do this we can either fold the code by adding #| code-fold: true to top of the code chunk:\n\nCode```{r}\n#| eval: true\n#| code-fold: true\nteacher_df %&gt;% \n  group_by(CNT) %&gt;%\n  summarise(n = n(), \n             median_age = median(TC002Q01NA, na.rm = TRUE),\n             males = sum(ifelse(TC001Q01NA == \"Male\", 1,0), na.rm = TRUE),\n             females = sum(ifelse(TC001Q01NA == \"Female\", 1,0), na.rm = TRUE))\n```\n\n# A tibble: 4 × 5\n  CNT          n median_age males females\n  &lt;fct&gt;    &lt;int&gt;      &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;\n1 Germany   3631         44  1449    2141\n2 Georgia   3202         52   432    2727\n3 Korea     3614         44  1584    2025\n4 Portugal  3487         51  1051    2407\n\n\nOr we can hide the code entirely by adding #| echo: false\n\n\n# A tibble: 4 × 5\n  CNT          n median_age males females\n  &lt;fct&gt;    &lt;int&gt;      &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;\n1 Germany   3631         44  1449    2141\n2 Georgia   3202         52   432    2727\n3 Korea     3614         44  1584    2025\n4 Portugal  3487         51  1051    2407\n\n\nThe above examples show how you can output tables and simple sums to the screen, you might also want to output calculated values and graphs. Imagine we want to add the number of male teachers to a report, in the middle of some text, but we might change the focus questions. We don’t want to keep changing this number as we adjust the countries that we are focused on, it would be far better if this automatically updated itself. First we need to calculate this value and store it in an object male_num. Note here that we use the pull(&lt;column&gt;) command, this returns the vector stored in the males column, rather than the column datatype. Next we note the countries that we are studying and store that in an object countries:\n\n```{r}\n#| eval: true\n# get number of male teachers in total\nmale_num &lt;- teacher_df %&gt;% \n  summarise(males = sum(ifelse(TC001Q01NA == \"Male\", 1,0), \n                        na.rm = TRUE)) %&gt;% pull(males)\n\ncountries &lt;- teacher_df %&gt;% distinct(CNT) %&gt;% pull(CNT)\n```\n\nNow that this has been calculated we can insert it into our text using the inline Georgia, Germany, Korea, Portugal and 4516 commands:\nThe number of male teachers in the PISA data set for &#96;r countries&#96; is &#96;r male_num&#96;\n\nThe number of male teachers in the PISA data set for Georgia, Germany, Korea, Portugal is 4516.\n\nThe great thing about the above is that if the data set changes, the names and the number will automatically update.",
    "crumbs": [
      "Publications",
      "Publishing using R and quarto"
    ]
  },
  {
    "objectID": "chapters/07-Rpublications.html#including-graphs",
    "href": "chapters/07-Rpublications.html#including-graphs",
    "title": "Publishing using R and quarto",
    "section": "\n4.2 Including graphs",
    "text": "4.2 Including graphs\nWe saw above how we can include images into our quarto document, you could output ggplot to png and include them in this way. However, quarto allows you to dynamically create the graph each time the document is rendered. This means that if the data changes, the graph will automatically update.\nTo add graphs to your booklets use the ```{r} coding blocks as normal. Create your graph and it should display. You can add a caption to the graph using the #| fig-cap: &lt;text&gt; command:\n\n```{r}\n#| fig-cap: median age of teacher by country\n#| label: fig-teachers\n#| warning: false\n#| eval: true\n# get number of male teachers in total\ngraph_data &lt;- teacher_df %&gt;% \n  filter(TC001Q01NA %in% c(\"Male\",\"Female\")) %&gt;%\n  rename(gender = TC001Q01NA) %&gt;%\n  group_by(CNT, gender) %&gt;%\n  summarise(median_age = median(TC002Q01NA, na.rm = TRUE))\n\nggplot(data=graph_data, \n       aes(x=CNT, y=median_age, fill=gender)) +\n  geom_bar(stat=\"identity\", position = \"dodge\") +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n```\n\n\n\n\n\n\nFigure 4.1: median age of teacher by country\n\n\n\n\nNote that the above also includes #| warning: false, this stops group_by placing a warning message as output. The #| label: fig-teachers command allows us to reference the graph in the text in the same way we referenced images above, for example, “see @fig-teachers for the median age of teachers by country”.\n\n\n\n\n\n\nImportant\n\n\n\nIf you want to reference a graph in your text you can use the #| label: &lt;name&gt;, where &lt;name&gt; has to start with fig-, for example: label: fig-correlation_graph. the hyphen - is essential after fig-, you can’t use an underscore _ or any other character.\n\n\nSometimes your graphs will be too big or too small, you can adjust the height and width by using\n#| fig.width: 5 #| fig.height: 5\n\n\n\n\n\n\nTip\n\n\n\nIf you want to quickly make interactive graphs you can using the plotly package. This allows you to hover over the graph and see the data points. To do this you need to install plotly and wrap up your plot within a code chunk. For example:\n\n```{r}\n#| eval: true\nlibrary(plotly)\ngraph_data &lt;- teacher_df %&gt;% \n  filter(TC001Q01NA %in% c(\"Male\",\"Female\")) %&gt;%\n  rename(gender = TC001Q01NA) %&gt;%\n  group_by(CNT, gender) %&gt;%\n  summarise(median_age = median(TC002Q01NA, na.rm = TRUE))\n\nplt_teacher_age &lt;- ggplot(data=graph_data, \n       aes(x=CNT, y=median_age, fill=gender)) +\n  geom_bar(stat=\"identity\", position = \"dodge\") +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\nggplotly(plt_teacher_age)\n```",
    "crumbs": [
      "Publications",
      "Publishing using R and quarto"
    ]
  },
  {
    "objectID": "chapters/07-Rpublications.html#questions-code-chunks-and-graphs",
    "href": "chapters/07-Rpublications.html#questions-code-chunks-and-graphs",
    "title": "Publishing using R and quarto",
    "section": "\n4.3 Questions: code chunks and graphs",
    "text": "4.3 Questions: code chunks and graphs\n\nUpdate your .qmd file to include:\n\na code chunk ```{r} ... ``` with libraries and loading the PISA teacher data set. Set #| echo: false and #| warning: false to stop the code displaying and the warnings from showing.\n\n\nhintlibrary(arrow)\nlibrary(tidyverse)\n\nteacher_df &lt;- read_parquet(\"your_location/pisa/2022/PISA_teacher_2022.parquet\")\n\n\n\nCreate a code chunk that displays the first 3 rows of teacher_df %&gt;% select(TCHTYPE, LANGTEST_QQQ, TC001Q01NA).\n\n\nhintteacher_df %&gt;% select(TCHTYPE, LANGTEST_QQQ, TC001Q01NA) %&gt;% head(3)\n\n\n\nCreate a code chunk that sets an object n_rows to be the number of rows in the data set. Use this object within some markdown text to tell the reader how many rows are in the data.\n\n\nhintn_rows &lt;- nrow(teacher_df)\n# The markdown outside the code chunk would look like this:\n#&gt; \"The data set contains `r n_rows` rows.\"\n\n\n\nCreate a code chunk that makes a graph showing mean_service years of a teacher in a school (TC007Q02NA) by country.\n\n\nhint# get number of male teachers in total\ngraph_data &lt;- teacher_df %&gt;% \n  group_by(CNT) %&gt;%\n  summarise(mean_service = mean(TC007Q02NA, na.rm = TRUE))\n\n\nggplot(data=graph_data, \n       aes(x=CNT, y=mean_service)) +\n  geom_bar(stat=\"identity\", position = \"dodge\") +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n\n\ngive the above graph a #| label: fig-service_years and a caption #| fig-cap: mean service years of a teacher by country. Reference the graph in the text, E.g. “@fig-service_years shows the mean number of years served by teachers in each country, with Portugal having the highest mean service years.”",
    "crumbs": [
      "Publications",
      "Publishing using R and quarto"
    ]
  },
  {
    "objectID": "chapters/07-Rpublications.html#loading-code-files-from-outside-the-.qmd-file",
    "href": "chapters/07-Rpublications.html#loading-code-files-from-outside-the-.qmd-file",
    "title": "Publishing using R and quarto",
    "section": "\n4.4 Loading code files from outside the .qmd file",
    "text": "4.4 Loading code files from outside the .qmd file\nyour quarto files can quickly become unwieldy if you have a lot of code in them. To help with this you can load code from external files. This is done by using the source() command in a code chunk. For example, if you have a file called load_data.R in the same folder as your .qmd file you can load it using:\n\n```{r}\n#| warning: false\nsource(\"setup.R\") # this file contains the libraries and the location of the data\nsource(\"load_data.R\") # this file loads the data\nsource(\"create_tables.R\") # this file creates tables for display\nsource(\"create_graphs.R\") # this file creates graphs for display\n```\n\nThe above code will load the setup.R, load_data.R, create_tables.R and create_graphs.R files into your .qmd file. Within these files you might do the following:\n\n\nsetup.R you would load the libraries that you need for your analysis and any objects that you need in other files such as the location of the data, or the countries that you are interested in.\n\nload_data.R you would load the large data sets into memory, these could then be used to create tables and graphs\n\ncreate_tables.R you would create the tables that you want to display in your document, try to stick to a naming convention, for example tbl_staff_gender\n\n\ncreate_graphs.R you would create the graphs that you want to display in your document, try to stick to a naming convention, for example plt_staff_gender\n\n\nOnce these files have been loaded you can access the created objects quite easily in code chunks:\n\n```{r}\n#| label: fig-staff_gender\n#| warning: false\n\nplt_staff_gender\n```",
    "crumbs": [
      "Publications",
      "Publishing using R and quarto"
    ]
  },
  {
    "objectID": "chapters/07-Rpublications.html#gt-great-tables",
    "href": "chapters/07-Rpublications.html#gt-great-tables",
    "title": "Publishing using R and quarto",
    "section": "\n5.1 gt (great tables)",
    "text": "5.1 gt (great tables)\nTo use gt you need to install it and load the package. Converting a data frame to a gt table is as simple as using the gt() function:\n\nlibrary(gt)\n\ndf_teach_ages &lt;- teacher_df %&gt;% \n  filter(CNT %in% c(\"Portugal\", \"Korea\")) %&gt;%\n  group_by(CNT) %&gt;%\n  mutate(n = n(), \n         median_age = median(TC002Q01NA, na.rm = TRUE)) %&gt;%\n  group_by(CNT, TC001Q01NA, n, median_age) %&gt;%\n  summarise(n_gen = n(),\n            med_age_gender = median(TC002Q01NA, na.rm = TRUE),\n            pct_gender = n_gen/n) %&gt;%\n  distinct()\n\ndf_teach_ages %&gt;% gt()\n\n\n\n\n\nn_gen\nmed_age_gender\npct_gender\n\n\n\nKorea - Female - 3614 - 44\n\n\n2025\n43\n0.560320974\n\n\nKorea - Male - 3614 - 44\n\n\n1584\n46\n0.438295517\n\n\nKorea - NA - 3614 - 44\n\n\n5\nNA\n0.001383509\n\n\nPortugal - Female - 3487 - 51\n\n\n2407\n51\n0.690278176\n\n\nPortugal - Male - 3487 - 51\n\n\n1051\n51\n0.301405219\n\n\nPortugal - NA - 3487 - 51\n\n\n29\n57\n0.008316605\n\n\n\n\n\n\nThe table looks better already, but there are a few issues that we need to sort out:\n\nthe groups from the group_by commands are visible in the table, we need to ungroup() df_teach_ages before passing it to gt()\n\nthe percentage has far too many decimal places, we can use fmt_percent() to adjust this\nsome n values look unformatted, could we add some commas using fmt_number()\n\n\n\ndf_teach_ages %&gt;% \n  ungroup() %&gt;%  # removes the grouping to put everything in columns\n  gt() %&gt;%\n  fmt_percent(columns = c(\"pct_gender\"),\n              decimals = 1) %&gt;%\n  fmt_number(columns = c(\"n\", \"n_gen\"),\n             decimals = 0) \n\n\n\n\n\nCountry code 3-character\nAre you female or male?\nn\nmedian_age\nn_gen\nmed_age_gender\npct_gender\n\n\n\nKorea\nFemale\n3,614\n44\n2,025\n43\n56.0%\n\n\nKorea\nMale\n3,614\n44\n1,584\n46\n43.8%\n\n\nKorea\nNA\n3,614\n44\n5\nNA\n0.1%\n\n\nPortugal\nFemale\n3,487\n51\n2,407\n51\n69.0%\n\n\nPortugal\nMale\n3,487\n51\n1,051\n51\n30.1%\n\n\nPortugal\nNA\n3,487\n51\n29\n57\n0.8%\n\n\n\n\n\n\nThis is looking better, but there are other issues:\n\nthe headings are a bit messy, we can use cols_label() to rename the columns, at the moment country (CNT) and gender (TC001Q01NA) are using the label from the original SPSS file, we can rename these to Country and Gender\n\nthere are NA values displayed, we can use sub_missing() to replace the med_age_gender with a - and the gender of the teacher with the word “Missing”:\n\n\ndf_teach_ages %&gt;% \n  ungroup() %&gt;%  # removes the grouping to put everything in columns\n  gt() %&gt;%\n  fmt_percent(columns = c(\"pct_gender\"),\n              decimals = 1) %&gt;%\n  fmt_number(columns = c(\"n\", \"n_gen\"),\n             decimals = 0) %&gt;%\n  cols_label(CNT = \"Country\", # note that you use the data frame column heading\n             TC001Q01NA = \"Gender\",\n             pct_gender = \"%\",\n             med_age_gender = \"median age\",\n             n_gen = \"n\",\n             median_age = \"median age\") %&gt;%\n  sub_missing(columns = c(\"TC001Q01NA\"),  # note we have to use the original name\n              missing_text = \"Missing\") %&gt;%\n  sub_missing(columns = c(\"med_age_gender\"),  # note we have to use the original name\n              missing_text = \"-\")\n\n\n\n\n\nCountry\nGender\nn\nmedian age\nn\nmedian age\n%\n\n\n\nKorea\nFemale\n3,614\n44\n2,025\n43\n56.0%\n\n\nKorea\nMale\n3,614\n44\n1,584\n46\n43.8%\n\n\nKorea\nMissing\n3,614\n44\n5\n-\n0.1%\n\n\nPortugal\nFemale\n3,487\n51\n2,407\n51\n69.0%\n\n\nPortugal\nMale\n3,487\n51\n1,051\n51\n30.1%\n\n\nPortugal\nMissing\n3,487\n51\n29\n57\n0.8%\n\n\n\n\n\n\nThis is looking even better, but now we have multiple columns with the same name. We need to group these columns so it’s clear which refers to the total and which to the individual gender group. If we have several fields that contain data with a similar theme and we want to put a title over the top of them we can use tab_spanner(). Remember, when performing calculations on gt columns we need to refer to the original column names, not the new ones we have created through cols_label().\n\nnice_table &lt;- df_teach_ages %&gt;% \n  ungroup() %&gt;%  # removes the grouping to put everything in columns\n  gt() %&gt;%\n  fmt_percent(columns = c(\"pct_gender\"),\n              decimals = 1) %&gt;%\n  fmt_number(columns = c(\"n\", \"n_gen\"),\n             decimals = 0) %&gt;%\n  cols_label(CNT = \"Country\", # note that you use the data frame column heading\n             TC001Q01NA = \"Gender\",\n             pct_gender = \"%\",\n             med_age_gender = \"median age\",\n             n_gen = \"n\",\n             median_age = \"median age\") %&gt;%\n  sub_missing(columns = c(\"TC001Q01NA\"),  # note we have to use the original name\n              missing_text = \"Missing\") %&gt;%\n  sub_missing(columns = c(\"med_age_gender\"),  # note we have to use the original name\n              missing_text = \"-\") %&gt;%\n  tab_spanner(columns = c(\"n_gen\",\"med_age_gender\",\"pct_gender\"),\n              label=\"gender\") %&gt;%\n  tab_spanner(columns = c(\"n\",\"median_age\"),\n              label=\"overall\")\n\nnice_table\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCountry\nGender\n\noverall\n\n\ngender\n\n\n\nn\nmedian age\nn\nmedian age\n%\n\n\n\n\nKorea\nFemale\n3,614\n44\n2,025\n43\n56.0%\n\n\nKorea\nMale\n3,614\n44\n1,584\n46\n43.8%\n\n\nKorea\nMissing\n3,614\n44\n5\n-\n0.1%\n\n\nPortugal\nFemale\n3,487\n51\n2,407\n51\n69.0%\n\n\nPortugal\nMale\n3,487\n51\n1,051\n51\n30.1%\n\n\nPortugal\nMissing\n3,487\n51\n29\n57\n0.8%\n\n\n\n\n\n\nFinally, we might want to add a footnote to the table, this is done using the tab_footnote() command. gt also allows you to insert markdown into the table by wrapping text in the md() command, as shown below. If we want to include this table with caption in the same way we used a caption on the figures above, we can use #| tbl-cap: teacher ages by country and provide a label to reference the table in our text: #| label: tbl-teacher_ages.:\n\n```{r}\n#| eval: true\n#| label: tbl-teacher_ages\n#| tbl-cap: teacher ages by country\nnice_table %&gt;% \n  tab_footnote(footnote = md(\"__source__: PISA 2022 teacher survey\"))\n```\n\n\nTable 5.1: teacher ages by country\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCountry\nGender\n\noverall\n\n\ngender\n\n\n\nn\nmedian age\nn\nmedian age\n%\n\n\n\n\nKorea\nFemale\n3,614\n44\n2,025\n43\n56.0%\n\n\nKorea\nMale\n3,614\n44\n1,584\n46\n43.8%\n\n\nKorea\nMissing\n3,614\n44\n5\n-\n0.1%\n\n\nPortugal\nFemale\n3,487\n51\n2,407\n51\n69.0%\n\n\nPortugal\nMale\n3,487\n51\n1,051\n51\n30.1%\n\n\nPortugal\nMissing\n3,487\n51\n29\n57\n0.8%\n\n\n\n\nsource: PISA 2022 teacher survey\n\n\n\n\n\n\n\n\ngt and the support package gtExtras have a lot of functionality, for example you might want to rearrange the columns in your table with cols_move() or conditionally format the colours of rows using tab_style(), you can find out more about them on their websites gt, gtExtras",
    "crumbs": [
      "Publications",
      "Publishing using R and quarto"
    ]
  },
  {
    "objectID": "chapters/07-Rpublications.html#questions-gt",
    "href": "chapters/07-Rpublications.html#questions-gt",
    "title": "Publishing using R and quarto",
    "section": "\n5.2 Questions: gt",
    "text": "5.2 Questions: gt\n\nUsing the following data frame df_extra_curricular about teacher engagement with extra curricular activities, try to answer these questions:\n\ndf_extra_curricular &lt;- teacher_df %&gt;% \n  select(CNT,TC001Q01NA, TC216Q08JA) %&gt;%\n  filter(CNT %in% c(\"Portugal\", \"Korea\")) %&gt;%\n  group_by(CNT) %&gt;%\n  mutate(n = n(), \n         mean_hours = mean(TC216Q08JA, na.rm = TRUE)) %&gt;%\n  group_by(CNT, TC001Q01NA, n, mean_hours) %&gt;%\n  summarise(n_gen = n(),\n            mean_ec_gender = mean(TC216Q08JA, na.rm = TRUE),\n            pct_gender = n_gen/n) %&gt;%\n  distinct()\ndf_extra_curricular\n\n# A tibble: 6 × 7\n# Groups:   CNT, TC001Q01NA, n, mean_hours [6]\n  CNT      TC001Q01NA     n mean_hours n_gen mean_ec_gender pct_gender\n  &lt;fct&gt;    &lt;fct&gt;      &lt;int&gt;      &lt;dbl&gt; &lt;int&gt;          &lt;dbl&gt;      &lt;dbl&gt;\n1 Korea    Female      3614       2.10  2025           1.94    0.560  \n2 Korea    Male        3614       2.10  1584           2.31    0.438  \n3 Korea    &lt;NA&gt;        3614       2.10     5           0       0.00138\n4 Portugal Female      3487       1.52  2407           1.53    0.690  \n5 Portugal Male        3487       1.52  1051           1.51    0.301  \n6 Portugal &lt;NA&gt;        3487       1.52    29           1       0.00832\n\n\nCreate a table using gt that has the following formating:\n\nuse ungroup to create a column for each variable\n\n\nanswerdf_extra_curricular %&gt;% \n  ungroup() %&gt;%\n  gt()\n\n\n\nformat pct_gender to be a percentage with one decimal place\n\n\nanswerdf_extra_curricular %&gt;% \n  ungroup() %&gt;%\n  gt() %&gt;%\n  fmt_percent(columns = c(\"pct_gender\"),\n              decimals=1) \n\n\n\nformat mean_hours and mean_ec_gender to have two decimal places\n\n\nanswerdf_extra_curricular %&gt;% \n  ungroup() %&gt;%\n  gt() %&gt;%\n  fmt_percent(columns = c(\"pct_gender\"),\n              decimals=1) %&gt;%\n  fmt_number(columns = c(\"mean_hours\", \"mean_ec_gender\"),\n             decimals = 2)\n\n\n\nreplace the NA gender with the word “Missing” (Bonus, make this text bold using markdown!)\n\n\nanswerdf_extra_curricular %&gt;% \n  ungroup() %&gt;%\n  gt() %&gt;%\n  fmt_percent(columns = c(\"pct_gender\"),\n              decimals=1) %&gt;%\n  fmt_number(columns = c(\"mean_hours\", \"mean_ec_gender\"),\n             decimals = 2) %&gt;%\n  sub_missing(columns = c(\"TC001Q01NA\"),\n              missing_text = md(\"__Missing__\"))\n\n\n\nrelabel the CNT to “Country”, TC001Q01NA to “Gender”, n to “Total”, n_gen to “n”, mean_ec_gender to “mean_hours” and pct_gender to “%”.\n\n\nanswerdf_extra_curricular %&gt;% \n  ungroup() %&gt;%\n  gt() %&gt;%\n  fmt_percent(columns = c(\"pct_gender\"),\n              decimals=1) %&gt;%\n  fmt_number(columns = c(\"mean_hours\", \"mean_ec_gender\"),\n             decimals = 2) %&gt;%\n  sub_missing(columns = c(\"TC001Q01NA\"),\n              missing_text = md(\"__Missing__\")) %&gt;%\n  cols_label(CNT = \"Country\",\n             TC001Q01NA = \"Gender\",\n             n = \"Total\",\n             n_gen = \"n\",\n             mean_ec_gender = \"mean_hours\",\n             pct_gender = \"%\")\n\n\n\ncreate a spanner called “by gender” for the gendered results, i.e. n_gen, mean_ec_gender and pct_gender\n\n\n\nanswerdf_extra_curricular %&gt;% \n  ungroup() %&gt;%\n  gt() %&gt;%\n  fmt_percent(columns = c(\"pct_gender\"),\n              decimals=1) %&gt;%\n  fmt_number(columns = c(\"mean_hours\", \"mean_ec_gender\"),\n             decimals = 2) %&gt;%\n  sub_missing(columns = c(\"TC001Q01NA\"),\n              missing_text = md(\"__Missing__\")) %&gt;%\n  cols_label(CNT = \"Country\",\n             TC001Q01NA = \"Gender\",\n             n = \"Total\",\n             n_gen = \"n\",\n             mean_ec_gender = \"mean_hours\",\n             pct_gender = \"%\") %&gt;%\n  tab_spanner(columns = c(\"n_gen\",\"mean_ec_gender\", \"pct_gender\"),\n              label = \"by gender\") \n\n\n\ncreate a footnote that says “source: PISA 2022 teacher survey”\n\n\nanswerdf_extra_curricular %&gt;% \n  ungroup() %&gt;%\n  gt() %&gt;%\n  fmt_percent(columns = c(\"pct_gender\"),\n              decimals=1) %&gt;%\n  fmt_number(columns = c(\"mean_hours\", \"mean_ec_gender\"),\n             decimals = 2) %&gt;%\n  sub_missing(columns = c(\"TC001Q01NA\"),\n              missing_text = md(\"__Missing__\")) %&gt;%\n  cols_label(CNT = \"Country\",\n             TC001Q01NA = \"Gender\",\n             n = \"Total\",\n             n_gen = \"n\",\n             mean_ec_gender = \"mean_hours\",\n             pct_gender = \"%\") %&gt;%\n  tab_spanner(columns = c(\"n_gen\",\"mean_ec_gender\", \"pct_gender\"),\n              label = \"by gender\") %&gt;%\n  tab_footnote(footnote = \"source: PISA 2022 teacher survey\")",
    "crumbs": [
      "Publications",
      "Publishing using R and quarto"
    ]
  },
  {
    "objectID": "chapters/A3-TIMSS_analysis.html",
    "href": "chapters/A3-TIMSS_analysis.html",
    "title": "TIMSS, PIRLS and ICILS",
    "section": "",
    "text": "1 What is TIMSS?\nTrends in International Mathematics and Science Study (TIMSS) is a set of assessments comparing international achievement in mathematics and science. TIMSS is run by the International Association for the Evaluation of Educational Achievement (IEA) an international group of national research institutions and governments working to research and improve education. TIMSS launched in 2015\nThe study surveys both 9-10-year-old and 13-14-year-old students, across 64 countries (in 2019). Contextual data about schools, teachers and parents is collected in the survey. TIMSS advanced (running since 1995) collects data on students in their final year of secondary schooling.\nYou can read more about TIMSS, and download data sets, from the TIMSS website: TIMSS\n\n\n2 What is PIRLS?\nPIRLS (Progress in International Reading Literacy Study) is the IEA’S parallel study to TIMSS which focuses on international literacy. The study samples 9-10-year old students and has taken place every five years since 2001.\nYou can read more about PIRLS, and download data sets, from the PIRLS website: TIMSS\n\n\n3 International Computer and Information Literacy Study (ICILS)\nICILS is the IEA international comparative assessment of students’ computing and IT literacy. First conducted in 2013, the study assesses computer and information literacy (CIL) and computational thinking (CT) of 13-14-year-old students. The assessment takes place every 5 years.\nLearn more about ICILS, and download data sets, from the ICILS website: ICILS",
    "crumbs": [
      "Appendices",
      "TIMSS, PIRLS and ICILS"
    ]
  },
  {
    "objectID": "chapters/A2-DfE_analysis.html",
    "href": "chapters/A2-DfE_analysis.html",
    "title": "DfE England",
    "section": "",
    "text": "There are four main data sources that you can use to gain information about education in England:",
    "crumbs": [
      "Appendices",
      "DfE England"
    ]
  },
  {
    "objectID": "chapters/A2-DfE_analysis.html#school-funding",
    "href": "chapters/A2-DfE_analysis.html#school-funding",
    "title": "DfE England",
    "section": "\n2.1 School funding",
    "text": "2.1 School funding\nSchool funding information is available on the gov uk skillsfunding website. You can download year on year datasets here, with data going back to 2014/15",
    "crumbs": [
      "Appendices",
      "DfE England"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "ECS Introduction to R course",
    "section": "",
    "text": "This book has been written to accompany the King’s Doctoral College course, An Introduction to Quantitative Research Using R for SSPP, A&H, Business and NMES methods course at King’s College London. It will take the reader through the process of learning the R statistical programming language through the analysis of the 2022 PISA survey data. The book does not assume any prior knowledge and should suit the needs of those looking to learn R, learn statistics, learn how to analyse PISA data, or any combination of these.\n\n1 Copyright and usage\nThis book is free to use under a CC BY-NC-ND 4.0 license.\nAll PISA products are published under the Creative Commons Attribution-NonCommercial-ShareAlike 3.0 IGO (CC BY-NC-SA 3.0 IGO) license. This includes the .feather and .parquet formatted datasets linked throughout the text. The PISA 2022 dataset is also available from the OECD website.\nWe have tested the software and datasets used in the making of this book, but cannot guarantee that they are free from errors. If you find any errors or have any questions, please contact peter.kemp@kcl.ac.uk and/or richard.brock@kcl.ac.uk. You are using this book at your own risk and we cannot be held responsible for any loss or damage arising from the use of this book (please don’t overwrite your hard disks!).\nTo reference this book, please use:\n\nKemp, Peter EJ, Richard Brock. 2024. An Introduction to Quantitative Research Using R for SSPP, A&H, Business and NMES. London, United Kingdom: King’s College London. https://peterejkemp.github.io/v3/.\n\nAnd to reference the PISA 2022 dataset, please use:\n\nOECD. 2022. PISA 2022 Results (Volume i). OECD. https://www.oecd-ilibrary.org/docserver/53f23881-en.pdf.",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "chapters/A1-PISA_analysis.html",
    "href": "chapters/A1-PISA_analysis.html",
    "title": "PISA",
    "section": "",
    "text": "The Programme for International Student Assessment (PISA) is an OECD initiative that looks at the reading, mathematics and science abilities of students aged 15 years old. Data is collected from OECD countries and other partner countries every three years (81 countries were in the sample in 2022).\n\n\nDataset\nDescription\n03\n06\n09\n12\n15\n18\n22\n\n\n\nStudent\ndemographic data on student participants\nx\nx\nx\n\nx\n\nx\nx\nx\n\n\nSchool\ndescriptive data about schools\nx\nx\nx\nx\nx\nx\nx\n\n\nParent\na survey for student’s parents including information about home environments and parental education\nx\nx\n\n\n\n\n\n\n\nTeacher\ndemographic, teaching, qualification and training data\n\n\n\nx\nx\nx\nx\n\n\nCognitive\nindividual results for each exam style question students took\nx\nx\nx\nx\nx\nx\n\n\n\n\nPISA datasets above can be found on the OECD website. The links in the table above will allow you to download .parquet versions of these files which we have created, though they might need additional editing, e.g. reducing the number of columns or changing the types of each column. If you want to find out more about what each field stores, take a look at the corresponding codebook: 2022, 2018, 2015.",
    "crumbs": [
      "Appendices",
      "PISA"
    ]
  },
  {
    "objectID": "chapters/A1-PISA_analysis.html#sec-PV",
    "href": "chapters/A1-PISA_analysis.html#sec-PV",
    "title": "PISA",
    "section": "\n4.1 What are Plausible Values?",
    "text": "4.1 What are Plausible Values?\nIn the PISA dataset, the outcomes of student tests are reported as plausible values, for example, in the variables of the science test (PV1SCIE, PV2SCIE, PV3SCIE, PV3SCIE, and PV5SCIE). It might seem counter intuitive that there are five values for a score on a test.\nPlausible values (PVs) are a way of expressing the error in a measurement. The number of questions in the full PISA survey is very large, so students are randomly allocated to take a subset of questions (and even then, the test still takes two hours!). As no student completes the full set of questions (only 40% of students even answer questions in reading, science and mathematics OECD (2014)), estimating how a student would have performed on the full question set involves some error. Plausible values are a way of expressing the uncertainty in the estimation of student scores.\nOne way of thinking of the PV scores is that they represent five different estimates of students’ abilities based on the questions they have answered. To decrease measurement error, five different approaches are applied to create five different estimates, the PV scores.\nThe PISA Data Analysis Manual suggests:\n\nPopulation statistics should be estimated using each plausible value separately. The reported population statistic is then the average of each plausible value statistic. For instance, if one is interested in the correlation coefficient between the social index and the reading performance in PISA, then five correlation coefficients should be computed and then averaged\nPlausible values should never be averaged at the student level, i.e. by computing in the dataset the mean of the five plausible values at the student level and then computing the statistic of interest once using that average PV value. Doing so would be equivalent to an EAP estimate, with a bias as described in the previous section.\n(Monseur et al. 2009, 100)",
    "crumbs": [
      "Appendices",
      "PISA"
    ]
  },
  {
    "objectID": "chapters/A1-PISA_analysis.html#why-are-some-countries-oecd-countries-and-others-arent",
    "href": "chapters/A1-PISA_analysis.html#why-are-some-countries-oecd-countries-and-others-arent",
    "title": "PISA",
    "section": "\n4.2 Why are some countries OECD countries and others aren’t?",
    "text": "4.2 Why are some countries OECD countries and others aren’t?\nThe Organisation for Economic Co-operation and Development (OECD) has 38 member states. PISA is run by the OECD and its member states normally take part in each PISA cycle, but other countries are allowed to take part as Partners. You can find more details on participation here.\nResults for OECD members are generally higher than for Partner countries:\n\nPISA_2022 %&gt;% \n  group_by(OECD) %&gt;% \n  summarise(country_n = length(unique(CNT)),\n            math_mean = mean(PV1MATH, na.rm=TRUE),\n            math_sd = sd(PV1MATH, na.rm=TRUE),\n            students_n = n())\n\n# A tibble: 2 × 5\n  OECD  country_n math_mean math_sd students_n\n  &lt;fct&gt;     &lt;int&gt;     &lt;dbl&gt;   &lt;dbl&gt;      &lt;int&gt;\n1 No           43      409.    97.8     318587\n2 Yes          37      475.    95.0     295157",
    "crumbs": [
      "Appendices",
      "PISA"
    ]
  },
  {
    "objectID": "chapters/A1-PISA_analysis.html#why-are-the-pv-grades-pivoting-around-the-500-mark",
    "href": "chapters/A1-PISA_analysis.html#why-are-the-pv-grades-pivoting-around-the-500-mark",
    "title": "PISA",
    "section": "\n4.3 Why are the PV grades pivoting around the ~500 mark?",
    "text": "4.3 Why are the PV grades pivoting around the ~500 mark?\nThe scores for students in mathematics, reading and science are scaled so that the mean of students in OECD countries is roughly 500 points with a standard deviation of 100 points. To see this, run the following code:\n\nPISA_2022 %&gt;% \n  filter(OECD==\"Yes\") %&gt;% \n  summarise(math_mean = mean(PV1MATH, na.rm=TRUE),\n            math_sd = sd(PV1MATH, na.rm=TRUE),\n            scie_mean = mean(PV1SCIE, na.rm=TRUE),\n            scie_sd = sd(PV1SCIE, na.rm=TRUE),\n            read_mean = mean(PV1READ, na.rm=TRUE),\n            read_sd = sd(PV1READ, na.rm=TRUE))\n\n# A tibble: 1 × 6\n  math_mean math_sd scie_mean scie_sd read_mean read_sd\n      &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n1      475.    95.0      487.    101.      478.    104.",
    "crumbs": [
      "Appendices",
      "PISA"
    ]
  },
  {
    "objectID": "chapters/A1-PISA_analysis.html#but-the-mean-pv-score-isnt-500",
    "href": "chapters/A1-PISA_analysis.html#but-the-mean-pv-score-isnt-500",
    "title": "PISA",
    "section": "\n4.4 But the mean PV score isn’t 500?!",
    "text": "4.4 But the mean PV score isn’t 500?!\nThe OECD’s initial plan (in the 2000 study) was that the mean PC score for OECD countries should be 500 and the standard deviation 100 (OECD 2019a). However, after the 2000 study, scores were scaled to be comparable with the first cycle of data, resulting in means differing from 500 (Pulkkinen and Rautopuro 2022). For example, by 2015, the mean for science had fallen to 493 in science and reading, and 490 in mathematics.",
    "crumbs": [
      "Appendices",
      "PISA"
    ]
  },
  {
    "objectID": "chapters/A1-PISA_analysis.html#why-are-the-letters-ta-and-na-used-in-some-field-names",
    "href": "chapters/A1-PISA_analysis.html#why-are-the-letters-ta-and-na-used-in-some-field-names",
    "title": "PISA",
    "section": "\n4.5 Why are the letters TA and NA used in some field names?",
    "text": "4.5 Why are the letters TA and NA used in some field names?",
    "crumbs": [
      "Appendices",
      "PISA"
    ]
  },
  {
    "objectID": "chapters/A1-PISA_analysis.html#how-do-i-find-fields-that-are-numeric",
    "href": "chapters/A1-PISA_analysis.html#how-do-i-find-fields-that-are-numeric",
    "title": "PISA",
    "section": "\n4.6 How do I find fields that are numeric?",
    "text": "4.6 How do I find fields that are numeric?\n\n# using the following code!\n\nnms &lt;- PISA_2022 %&gt;% select(where(is.numeric)) %&gt;% names()\nlbls &lt;- map_dfr(nms,\\(nme){\n  message(nme)\n  lbl &lt;- attr(PISA_2022[[nme]], \"label\")\n  row &lt;- c(nme, lbl)\n  names(row) &lt;- c(\"name\", \"label\")\n  return(row)\n})",
    "crumbs": [
      "Appendices",
      "PISA"
    ]
  },
  {
    "objectID": "chapters/A1-PISA_analysis.html#how-are-students-selected-to-take-part-in-pisa",
    "href": "chapters/A1-PISA_analysis.html#how-are-students-selected-to-take-part-in-pisa",
    "title": "PISA",
    "section": "\n4.7 How are students selected to take part in PISA?",
    "text": "4.7 How are students selected to take part in PISA?\nThe students who take part in the PISA study are aged between 15 years and 3 (completed) months and 16 years and 2 (completed) months at the beginning of the testing period (OECD 2018). A number of classes of students are excluded from data collection:\n\nStudents classed as ‘functionally disabled’ so that they cannot participate in the test.\nJudged by teachers to have cognitive, emotional or behavioural difficulties that mean they cannot participate.\nThe student lacks language abilities to take the test in the assessment language.\nThere are no test material available in the student’s language\nAnother agreed reason\n\nThe OECD expect that 85% of schools in their original sample participate - nonparticipating schools can be replaced with a substitute, ‘replacement’ school. A minimum weighted response rate of 80% is required within schools.\nThe sampling strategy for PISA is a stratified two-stage sample design. That is schools are sampled to represent proportional distribution by size (referring to the number of enrolled 15-year-olds) sampling. Within schools, students are sampled with equal probability.\nFrom the data, you can see that 50% of schools entered fewer than 30 students into PISA.\n\nPISA_2022 %&gt;% \n  group_by(CNTSCHID) %&gt;%\n  summarise(size = n()) %&gt;%\n  mutate(quartile = ntile(size, 4)) %&gt;%\n  group_by(quartile) %&gt;%\n  summarise(Qmax = max(size),\n            Qmedian = median(size),\n            Qmean = mean(size))\n\n# A tibble: 4 × 4\n  quartile  Qmax Qmedian Qmean\n     &lt;int&gt; &lt;int&gt;   &lt;dbl&gt; &lt;dbl&gt;\n1        1    19      10  10.1\n2        2    30      25  25.2\n3        3    37      34  33.8\n4        4   475      40  44.4\n\nggplot(PISA_2022 %&gt;% \n  group_by(CNTSCHID) %&gt;%\n  summarise(size = n()), aes(x=size)) +\n  geom_density()",
    "crumbs": [
      "Appendices",
      "PISA"
    ]
  },
  {
    "objectID": "chapters/A1-PISA_analysis.html#what-are-the-pisa-test-questions-like",
    "href": "chapters/A1-PISA_analysis.html#what-are-the-pisa-test-questions-like",
    "title": "PISA",
    "section": "\n4.8 What are the PISA test questions like?",
    "text": "4.8 What are the PISA test questions like?\nYou can view sample PISA science, reading and mathematics questions here.",
    "crumbs": [
      "Appendices",
      "PISA"
    ]
  },
  {
    "objectID": "chapters/A1-PISA_analysis.html#how-can-i-find-the-ethnicity-or-race-of-a-student-taking-the-pisa-test",
    "href": "chapters/A1-PISA_analysis.html#how-can-i-find-the-ethnicity-or-race-of-a-student-taking-the-pisa-test",
    "title": "PISA",
    "section": "\n4.9 How can I find the ethnicity or race of a student taking the PISA test?",
    "text": "4.9 How can I find the ethnicity or race of a student taking the PISA test?\nThis data isn’t collected by PISA. Instead they collect information on the language spoken at home (LANGN) and the language of the test (LANGTEST_QQQ), as well as the immigration status and country of birth (COBN_S student, COBN_M mother, COBN_F father). Details on ethnicity and outcomes in the England are published through the country specific research report for 2018. Note that Chinese students are categorised under “Other” rather than “Asian”.",
    "crumbs": [
      "Appendices",
      "PISA"
    ]
  },
  {
    "objectID": "chapters/A1-PISA_analysis.html#what-are-the-pisa-domains",
    "href": "chapters/A1-PISA_analysis.html#what-are-the-pisa-domains",
    "title": "PISA",
    "section": "\n4.10 What are the PISA domains?",
    "text": "4.10 What are the PISA domains?\nEvery PISA test has included test items measuring literacy, numeracy and science. In each cycle, one of three areas is the focus of study (the major domain). In addition, extra domains have been added to cycles (for example, creative thinking and collaborative problem solving). The additional domains are shown in the table below.\n\n\n\n\n\n\n\nYear\nMajor Domain\nMinor Domains\n\n\n\n2000\nReading literacy\nMathematics, Science\n\n\n2003\nMathematics\nReading literacy, Science, Cross-curricular problem solving\n\n\n2006\nScience\nReading literacy, Mathematics\n\n\n2009\nReading literacy\nMathematics, Science\n\n\n2012\nMathematics\nReading literacy, Science, Creative problem solving\n\n\n2015\nScience\nMathematics, Reading literacy, Collaborative problem solving\n\n\n2018\nReading literacy\nMathematics, Science, Global Competence\n\n\n2022\nMathematics\nReading literacy, Science, Creative thinking\n\n\n2025\nScience\nMathematics, Reading literacy, Learning in the Digital World",
    "crumbs": [
      "Appendices",
      "PISA"
    ]
  },
  {
    "objectID": "chapters/A1-PISA_analysis.html#why-is-china-given-the-cnt-value-b-s-j-z-china-2018-or-b-s-j-g-china-2015",
    "href": "chapters/A1-PISA_analysis.html#why-is-china-given-the-cnt-value-b-s-j-z-china-2018-or-b-s-j-g-china-2015",
    "title": "PISA",
    "section": "\n4.11 Why is China given the CNT value B-S-J-Z (China) (2018) or B-S-J-G (China) (2015)?",
    "text": "4.11 Why is China given the CNT value B-S-J-Z (China) (2018) or B-S-J-G (China) (2015)?\nB-S-J-G/Z (China) is an acronym for Beijing, Shanghai, Jiangsu and Guangdong/Zhejiang, the four provinces/municipalities of the People’s Republic of China that take part in PISA data collection. Zhejiang took the place of Guangdong in the 2018 dataset. Several authors (including (Du and Wong 2019)) comment that sampling only from some of the most developed regions of China means the country’s data is unlikely to be nationally representative.",
    "crumbs": [
      "Appendices",
      "PISA"
    ]
  },
  {
    "objectID": "chapters/A1-PISA_analysis.html#where-is-mainland-china-in-pisa-2022",
    "href": "chapters/A1-PISA_analysis.html#where-is-mainland-china-in-pisa-2022",
    "title": "PISA",
    "section": "\n4.12 Where is mainland China in PISA 2022?",
    "text": "4.12 Where is mainland China in PISA 2022?\n\nChinese provinces/municipalities (Beijing, Shanghai, Jiangsu and Zhejiang) and Lebanon are participants in PISA 2022 but were unable to collect data because schools were closed during the intended data collection period. - PISA 2022 participants",
    "crumbs": [
      "Appendices",
      "PISA"
    ]
  },
  {
    "objectID": "chapters/A1-PISA_analysis.html#how-do-i-calculate-weighted-means-of-the-pv-scores",
    "href": "chapters/A1-PISA_analysis.html#how-do-i-calculate-weighted-means-of-the-pv-scores",
    "title": "PISA",
    "section": "\n4.13 How do I calculate weighted means of the PV scores?",
    "text": "4.13 How do I calculate weighted means of the PV scores?\nYou can use a function written by Miguel Diaz Kusztrick, here is his slightly tidied function for calculating weighted means and standard deviations (original link):\n\n# Copyright Miguel Diaz Kusztrick\nwght_meansd_pv &lt;- function(sdata, pv, weight, brr) {\n    mmeans  &lt;- c(0, 0, 0, 0)\n    names(mmeans) &lt;- c(\"MEAN\",\"SE-MEAN\",\"STDEV\",\"SE-STDEV\")\n    \n    mmeanspv &lt;- rep(0,length(pv))\n    stdspv   &lt;- rep(0,length(pv))\n    mmeansbr &lt;- rep(0,length(pv))\n    stdsbr   &lt;- rep(0,length(pv))\n    sum_weight &lt;- sum(sdata[,weight])\n    \n    for (i in 1:length(pv)) {\n        mmeanspv[i] &lt;- sum(sdata[,weight]*sdata[,pv[i]])/sum_weight\n        stdspv[i]   &lt;- sqrt((sum(sdata[,weight]*(sdata[,pv[i]]^2))/swght)-mmeanspv[i]^2)\n        for (j in 1:length(brr)) {\n            sbrr&lt;-sum(sdata[,brr[j]])\n            mbrrj&lt;-sum(sdata[,brr[j]]*sdata[,pv[i]])/sbrr\n            mmeansbr[i]&lt;-mmeansbr[i] + (mbrrj - mmeanspv[i])^2\n            stdsbr[i]&lt;-stdsbr[i] + (sqrt((sum(sdata[,brr[j]]*(sdata[,pv[i]]^2))/sbrr)-mbrrj^2) - stdspv[i])^2\n        }       \n    }\n    mmeans[1] &lt;- sum(mmeanspv) / length(pv)\n    mmeans[2] &lt;- sum((mmeansbr * 4) / length(brr)) / length(pv)\n    mmeans[3] &lt;- sum(stdspv) / length(pv)\n    mmeans[4] &lt;- sum((stdsbr * 4) / length(brr)) / length(pv)\n    ivar &lt;- c(0,0)\n    \n    for (i in 1:length(pv)) {\n        ivar[1] &lt;- ivar[1] + (mmeanspv[i] - mmeans[1])^2;\n        ivar[2] &lt;- ivar[2] + (stdspv[i] - mmeans[3])^2;\n    }\n    ivar = (1 + (1 / length(pv))) * (ivar / (length(pv) - 1));\n    mmeans[2] &lt;- sqrt(mmeans[2] + ivar[1]);\n    mmeans[4] &lt;- sqrt(mmeans[4] + ivar[2]);\n    return(mmeans);\n}",
    "crumbs": [
      "Appendices",
      "PISA"
    ]
  },
  {
    "objectID": "chapters/A1-PISA_analysis.html#empty-fields",
    "href": "chapters/A1-PISA_analysis.html#empty-fields",
    "title": "PISA",
    "section": "\n5.1 Empty fields",
    "text": "5.1 Empty fields\nAll 2022 school responses to questions about the clubs and extra curricular activities run in a school SC053Q____ are coded as NA, as are SC207____. It’s not clear why this data is included in the dataset or whether this data should have values but doesn’t. These (albeit empty) fields are included in the full PISA_school_2022.parquet file linked above.\n\nCodeclub_flds &lt;- c(\"SC053Q01TA\",\"SC053Q02TA\",\"SC053Q03TA\",\"SC053Q04TA\",\"SC053Q05NA\",\n               \"SC053Q06NA\",\"SC053Q07TA\",\"SC053Q08TA\",\"SC053Q09TA\",\"SC053Q10TA\")\n\nPISA_2022_school %&gt;% \n  select(c(\"CNT\", starts_with(\"SC053Q\"), starts_with(\"SC207\"))) %&gt;% \n  group_by(CNT) %&gt;%\n  pivot_longer(-CNT, \n               names_to = \"club\",\n               values_to = \"present\") %&gt;%\n  filter(!is.na(present)) %&gt;%\n  pull(club) %&gt;% \n  unique()\n\n# Note: SC053D11TA is present:\n# &lt;This academic year&gt;,follow. activities/school offers&lt;national modal grade for 15-year-olds&gt;? &lt;country specific item&gt;\n\n\nAdditionally, creativity fields stored in ST334_____, ST340_____, ST341_____, PA185_____ and CREA____ on the student questionnaire are missing answers for all countries:\n\nCodePISA_2022 %&gt;% \n  select(c(\"CNT\", \"IMAGINE\", \n           starts_with(\"ST334\"),\n           starts_with(\"ST340\"), \n           starts_with(\"ST341\"),\n           starts_with(\"PA185\"),\n           starts_with(\"CREA\"))) %&gt;% \n  mutate(across(everything(), as.numeric)) %&gt;%\n  group_by(CNT) %&gt;%\n  pivot_longer(-CNT, \n               names_to = \"creativity\",\n               values_to = \"present\") %&gt;%\n  filter(!is.na(present)) %&gt;%\n  pull(creativity) %&gt;% \n  unique()",
    "crumbs": [
      "Appendices",
      "PISA"
    ]
  },
  {
    "objectID": "chapters/A1-PISA_analysis.html#cyprus-present-but-missing",
    "href": "chapters/A1-PISA_analysis.html#cyprus-present-but-missing",
    "title": "PISA",
    "section": "\n5.2 Cyprus present but missing",
    "text": "5.2 Cyprus present but missing\nCyprus is still present in the levels of CNT even though PISA hasn’t recorded data on Cyprus since 2012. Other countries that didn’t participate in the 2022 round have been removed from the levels, e.g. China.\n\nCodecountries &lt;- PISA_2022 %&gt;% pull(CNT) %&gt;% unique()\ncountry_lvls &lt;- PISA_2022 %&gt;% pull(CNT) %&gt;% levels()\nsetdiff(country_lvls, countries)",
    "crumbs": [
      "Appendices",
      "PISA"
    ]
  },
  {
    "objectID": "chapters/A1-PISA_analysis.html#great-britain-vs-the-united-kingdom",
    "href": "chapters/A1-PISA_analysis.html#great-britain-vs-the-united-kingdom",
    "title": "PISA",
    "section": "\n5.3 Great Britain vs the United Kingdom",
    "text": "5.3 Great Britain vs the United Kingdom\nThe United Kingdom is the country referred to when correctly combining the results of England, Scotland, Wales and Northern Ireland. However, the regions of the United Kingdom listed by the OECD are “Great Britain:” England, Scotland, Wales and Northern Ireland. Northern Ireland isn’t part of Great Britain.\n\nCodePISA_2022 %&gt;% select(CNT, REGION) %&gt;% \n  filter(grepl(\"Great Britain\", REGION)) %&gt;% distinct()",
    "crumbs": [
      "Appendices",
      "PISA"
    ]
  },
  {
    "objectID": "chapters/A10-Leaflet.html",
    "href": "chapters/A10-Leaflet.html",
    "title": "Leaflet",
    "section": "",
    "text": "Leaflet is a popular open-source JavaScript library for interactive maps. It is widely used across the web and is a great way to display location data. In this tutorial, we will learn how to use leaflet in R to create interactive maps.",
    "crumbs": [
      "Appendices",
      "Leaflet"
    ]
  },
  {
    "objectID": "chapters/A10-Leaflet.html#an-introduction-to-using-leaflet-in-r",
    "href": "chapters/A10-Leaflet.html#an-introduction-to-using-leaflet-in-r",
    "title": "Leaflet",
    "section": "",
    "text": "Leaflet is a popular open-source JavaScript library for interactive maps. It is widely used across the web and is a great way to display location data. In this tutorial, we will learn how to use leaflet in R to create interactive maps.",
    "crumbs": [
      "Appendices",
      "Leaflet"
    ]
  },
  {
    "objectID": "chapters/A10-Leaflet.html#the-data-sets",
    "href": "chapters/A10-Leaflet.html#the-data-sets",
    "title": "Leaflet",
    "section": "\n0.2 The data sets",
    "text": "0.2 The data sets\nWe will use Department for education progress 8 data to examine school performance in England. We will use two dats sets, one containing the location of schools and the other containing the progress 8 scores for each school.\nSchool location data Progress 8 data\n\n\n\n\n\n\nTip\n\n\n\nThe progress 8 refers to a value added measure used by the Department for Education in the UK to report the performance of secondary schools. It is calculated by comparing the progress of students from the end of primary school to the end of secondary school. Pupils are placed into bands by their performance at tests in English and mathematics during primary school (the KS2 SATS) and their progress is compared to the average progress of pupils with similar results.\nWhen students sits national examinations at age 16 (GCSEs) their results in English and mathematics and six other subjects (sciences, computer science, geography, history, languages and three further subjects). English and mathematics are double weighted in the calculation of Progress 8. For each student an attainment 8 score is calculated, a measure of average attainment across the eight subjects.\nProgress 8 is calculated by subtracting the average attainment 8 score of pupils in the school from the average attainment 8 score of pupils with the same prior attainment at the end of primary school. The difference is divided by ten to give a Progress 8 score. A school with a Progress 8 score of 0 is performing in line with the national average. A school with a positive Progress 8 score is performing better than the national average and a school with a negative Progress 8 score is performing worse than the national average.",
    "crumbs": [
      "Appendices",
      "Leaflet"
    ]
  },
  {
    "objectID": "chapters/A10-Leaflet.html#loading-the-data-and-merging-the-data-sets",
    "href": "chapters/A10-Leaflet.html#loading-the-data-and-merging-the-data-sets",
    "title": "Leaflet",
    "section": "\n0.3 Loading the data and merging the data sets",
    "text": "0.3 Loading the data and merging the data sets\nThe first step is to load the two data sets. Often in projects data may be spread across multiple sources - here the location data and the progress 8 data are in separate files. We will load the data and then merge the two data sets together.\nWe don’t need all the columns in the data sets, and will keep the following entries from the two data sets:\nschool_descriptive data set\n\n\n\n\n\n\nVariable label\nDescription\n\n\n\nyear\nyear of data collection\n\n\nURN\nSchool unique reference number\n\n\nSCHNAME\nSchool name\n\n\nPostcode\nPostcode\n\n\nLA\nLocal authority\n\n\nEasting\nAn easting is a geo-location code used by the Ordnance Survey. The reference point for eastings in the Ordnance Survey National Grid is the zero easting, located off the Western Isles. The eastings numbers run across the map from left to right, increasing in value as you move east. An easing can be thought of as a vertical line on a map. The National Grid divides the UK unto squares of sides 100km by 100km.\n\n\nNorthing\nA northing is the equivalent to an easting but based on horizontal lines (i.e. like a latitude)\n\n\nGENDER\nThe gender of students at the school (Mixed, Boys, Girls)\n\n\nstu_total\nThe total number of students\n\n\nNFTYPE\nNational Funding Type (Maintained School, Special School, Independent School)\n\n\nADMPOL\nAdmissions Policy (can be Not applicable, Comprehensive, Non selective, Selective)\n\n\n\nprogress 8 data set\n\n\nVariable label\nDescription\n\n\n\nThe mean progress 8 score\nP8MEA\n\n\n\nPSENE4\n\n\n\n\n\n\n\n\n# Select variables of interest\n# Note the URN in both data sets to perform the merge\n\nschool_descriptive &lt;- school_descriptive %&gt;%\n  select(year, URN, SCHNAME, Postcode, LA, Easting, Northing, NFTYPE)\n\nprogress_8_data &lt;- progress_8_data %&gt;%\n  select(URN, P8MEA, PSENE4)\n\nWe will filter the school_descriptive data for 2018 data only and for secondary schools which have returned Progress 8 data.\n\n# Filter the descriptive data\nschool_descriptive &lt;- school_descriptive %&gt;%\n  filter(year == 2018)\n\nprogress_8_data &lt;- progress_8_data %&gt;%\n  filter(!is.na(P8MEA)) %&gt;%\n  filter(P8MEA != \"NP\" & P8MEA != \"NE\" & P8MEA != \"SUPP\")\n\nWe can then merge the two data sets together using the left_join() function from the dplyr package. The left_join() function is used to combine two data frames by matching the values of one or more variables. In this case, we will merge the two data sets using the URN variable.\n\n# Merge data sets\n\nmerged_data &lt;- left_join(progress_8_data, school_descriptive, by = \"URN\")",
    "crumbs": [
      "Appendices",
      "Leaflet"
    ]
  },
  {
    "objectID": "chapters/A10-Leaflet.html#converting-coordinates-to-latitude-and-longitude",
    "href": "chapters/A10-Leaflet.html#converting-coordinates-to-latitude-and-longitude",
    "title": "Leaflet",
    "section": "\n0.4 Converting coordinates to latitude and longitude",
    "text": "0.4 Converting coordinates to latitude and longitude\nA common issue with geographical data is that the coordinates are often in a different from those used by mapping software. For example, the coordinates in the data set are in eastings and northings rather than latitude and longitude. We will use the sp package to convert the eastings and northings to latitude and longitude. The sp package is a popular package for working with spatial data in R.\nFirst we use the coordinates() function in R, from by the sp package, which is used to assign or retrieve spatial coordinates for a dataset\n\n# Converting Eastings and northings to latitude and longitude\n\nlibrary(sp)\n\n# Omit any schools with missing eastings or northings\n\nmerged_data &lt;- merged_data %&gt;%\n  filter(!is.na(Easting) & !is.na(Northing))\n\n# Create a SpatialPoints object from the eastings and northings\ncoordinates(merged_data) &lt;- c(\"Easting\", \"Northing\")\n\n# Define the CRS for British National Grid (EPSG:27700)\nproj4string(merged_data) &lt;- CRS(\"+proj=tmerc +lat_0=49 +lon_0=-2 +k=0.9996012717 \n                        +x_0=400000 +y_0=-100000 +ellps=airy \n                        +datum=OSGB36 +units=m +no_defs\")\n\n# Transform to WGS84 (latitude and longitude)\ndf_ll &lt;- spTransform(merged_data, CRS(\"+proj=longlat +datum=WGS84\"))\n\n# Add latitude and longitude to the original data frame\nmerged_data$longitude &lt;- coordinates(df_ll)[, 1]\nmerged_data$latitude &lt;- coordinates(df_ll)[, 2]",
    "crumbs": [
      "Appendices",
      "Leaflet"
    ]
  },
  {
    "objectID": "chapters/A10-Leaflet.html#creating-an-interactive-map-with-leaflet",
    "href": "chapters/A10-Leaflet.html#creating-an-interactive-map-with-leaflet",
    "title": "Leaflet",
    "section": "\n0.5 Creating an interactive map with leaflet",
    "text": "0.5 Creating an interactive map with leaflet\nNow that we have the data in the correct format, we can create an interactive map using the leaflet package in R.First, we will create a map that displays the location of schools in England. We will use the leaflet() function to create a new leaflet map object, and then add markers to the map using the addMarkers() function.\nFirst let us just create a basic map around the Waterloo campus of KCL.\n\nlibrary(leaflet)\n\n# Create a blank leaflet map\n\nleaflet() %&gt;%\n  addTiles() %&gt;%  # Add the default OpenStreetMap tiles \n  setView(lng = -0.1134284, lat =  51.50556315 , zoom = 16)  # Set the view by adding the lat and long of Waterloo\n\n\n\n\n\nYou can change the style of the map by adding different tile layers. For example, you can use the addProviderTiles() function to add a different tile layer to the map. The addProviderTiles() function allows you to add tiles from different providers. See options for tile styles here. You can change the level of zoom in the setView() function.\n\n# Create a blank leaflet map in a different style\n\nleaflet() %&gt;%\n  addProviderTiles(provider = \"OpenTopoMap\") %&gt;%  # Add OpenTopoMap tiles \n  setView(lng = -0.1134284, lat =  51.50556315 , zoom = 14)",
    "crumbs": [
      "Appendices",
      "Leaflet"
    ]
  },
  {
    "objectID": "chapters/A10-Leaflet.html#adding-markers-to-the-map",
    "href": "chapters/A10-Leaflet.html#adding-markers-to-the-map",
    "title": "Leaflet",
    "section": "\n0.6 Adding markers to the map",
    "text": "0.6 Adding markers to the map\nThe simplest way to add data to the map is to use the addCircles() function. This function allows you to add a cricle to the map at specific locations. You can customize the markers by changing the color, size, and shape of the markers. You can also add popups to the markers to display additional information.\n\n# Create a map with a marker\n\nleaflet() %&gt;%\n  addTiles() %&gt;%  # Add the default OpenStreetMap tiles \n  setView(lng = -0.1134284, lat =  51.50556315 , zoom = 16) %&gt;%\n  addCircles(\n    lng = -0.1134284, \n    lat = 51.50556315, \n    radius = 50,  # Radius in meters\n    color = \"red\",  # Circle outline color\n    fillColor = \"red\",  # Circle fill color\n    fillOpacity = 0.5  # Opacity of the fill\n  )\n\n\n\n\n\nAlternative, you can use the addMarkers() function to add markers to the map. The addMarkers() function allows you to add markers to the map at specific locations. You can customize the markers by changing the icon, size, and shape of the markers. You can also add popups to the markers to display additional information.\n\n# Create a leaflet map wtih a marker with a popup label\n\nleaflet() %&gt;%\n  addTiles() %&gt;%  # Add the default OpenStreetMap tiles \n  setView(lng = -0.1134284, lat =  51.50556315 , zoom = 16) %&gt;%\n  addMarkers(\n    lng = -0.1134284, \n    lat = 51.50556315, \n    popup = \"This is the Waterloo Bridge Wing\"  # Optional popup text\n  )",
    "crumbs": [
      "Appendices",
      "Leaflet"
    ]
  },
  {
    "objectID": "chapters/A10-Leaflet.html#adding-data-from-a-data-frame-to-maps",
    "href": "chapters/A10-Leaflet.html#adding-data-from-a-data-frame-to-maps",
    "title": "Leaflet",
    "section": "\n0.7 Adding data from a data frame to maps",
    "text": "0.7 Adding data from a data frame to maps\nRather than simply adding markers, we can add data from a data frame to the map. We can use the addMarkers() function to add data from our school data frame to the map. This time we will pipe (%&gt;%) the merged_data data frame into leaflet. We will use the addMarkers() function to add markers to the map at the location of each school. We will also add a popup to each marker that displays the name of the school.\n\n# Create a map with data from a data frame\n\nmerged_data %&gt;%\n  leaflet() %&gt;%\n  addTiles() %&gt;%\n  setView(lng = -0.1134284, lat = 51.50556315, zoom = 13) %&gt;%\n  addMarkers(\n    lng = ~longitude,   # Use the 'longitude' column from your data frame\n    lat = ~latitude,    # Use the 'latitude' column from your data frame\n    popup = ~as.character(SCHNAME)    # Use the 'SCHNAME' column for the popup\n  )\n\n\n\n\n\nAlternatively, you can use the addCircleMarkers() function to add markers to the map. The addCircleMarkers() function allows you to add circle markers to the map at specific locations. You can customize the markers by changing the color, size, and shape of the markers. You can also add popups to the markers to display additional information. Here we set the fill to the type of school.\nWe need to specify a palette for the fill. We can use the colorFactor() function from the leaflet package to create a color palette based on the NFTYPE variable in the data frame. The colorFactor() function creates a color palette based on the unique values in a variable. We can then use the fillColor argument in the addCircleMarkers() function to set the fill color based on the NFTYPE variable.\nThe NFTYPE variable can have the following values:\n\nunique(merged_data$NFTYPE)\n\n [1] \"Community school\"                    \n [2] \"Voluntary aided school\"              \n [3] \"Academy sponsor led mainstream\"      \n [4] \"Free school - Mainstream\"            \n [5] \"Community special school\"            \n [6] \"Academy - Converter mainstream\"      \n [7] \"Foundation school\"                   \n [8] \"Free school - Special\"               \n [9] \"Foundation special school\"           \n[10] \"Academy - Converter special school\"  \n[11] \"Voluntary controlled school\"         \n[12] \"University technical college\"        \n[13] \"General further education college\"   \n[14] \"Academy - Sponsor led special school\"\n[15] \"City technology college\"             \n[16] \"Studio school\"                       \n[17] \"Non-maintained special school\"       \n\n\nHence we set the pallete as follows for the 29 values (the colours run in the same order as the order of the unique values in the NFTYPE variable).\n\n# set a pallete for the fill\n\n# Define a custom color palette (use your preferred colors)\ncustom_colors &lt;- c(\"#FF5733\", \"#33FF57\", \"#3357FF\", \"#F1C40F\", \"#9B59B6\", \"#1ABC9C\", \"#E74C3C\", \n                   \"#F39C12\", \"#D35400\", \"#8E44AD\", \"#3498DB\", \"#2ECC71\", \"#16A085\", \"#9B59B6\", \n                   \"#F7DC6F\", \"#E67E22\", \"#1F618D\", \"#7D3C98\", \"#F1948A\", \"#7DFF33\", \"#FF8000\", \n                   \"#9B59B6\", \"#16A085\", \"#F39C12\", \"#E74C3C\", \"#8E44AD\", \"#3498DB\", \"#2ECC71\")\n\n\npal &lt;- colorFactor(\n  palette = custom_colors,  # Set the colors for the palette\n  domain = merged_data$NFTYPE  # Set the domain for the palette\n)\n\n# Create a map with data from a data frame\n\nmerged_data %&gt;%\n  leaflet() %&gt;%\n  addTiles() %&gt;%\n  setView(lng = -0.1134284, lat = 51.50556315, zoom = 13) %&gt;%\n  addCircleMarkers(\n    lng = ~longitude,   \n    lat = ~latitude,   \n    radius = 8,         \n    color = NA, # No outline coulor      \n    fillColor =  ~pal(NFTYPE),  # Use the palette to color the markers by NFTYP\n    fillOpacity = 0.8,  \n    popup = ~ as.character(SCHNAME)  # Use the 'SCHNAME' column for the popup    \n  )\n\n\n\n\n\nWe can follow a similar process to add the progess 8 data to the map. This time we will create a continuous colour scale to show variation in progress 8 score. First let us convert P8MEA to numeric and check its range:\n\n# Convert P8MEA to numeric\n\nmerged_data$P8MEA &lt;- as.numeric(merged_data$P8MEA)\n\n# Check the range of P8MEA\nrange(merged_data$P8MEA, na.rm = T)\n\n[1] -3.84  2.55\n\n\nWe can now define a continuous colour palette using the colorNumeric() function from the leaflet package. The colorNumeric() function creates a continuous color palette based on a numeric variable. We can then use the fillColor argument in the addCircleMarkers() function to set the fill color based on the P8MEA variable. There are a number of options for the palette, in the colorNumeric() function see here for a full list. Palettes include:\n\n“YlGnBu”: Yellow to green to blue\n“RdYlBu”: Red to yellow to blue (good for diverging data)\n“Viridis”: A perceptually uniform color map (great for continuous data)\n“Magma”: A perceptually uniform palette with darker tones\n“Plasma”: Bright and perceptually uniform\n“Inferno”: A bright, perceptually uniform palette\n\n\n# Create a continuous color palette based on P8MEA values\npal &lt;- colorNumeric(\n  palette = \"RdYlBu\",  # Choose the palette (can be changed to any desired palette)\n  domain = c(-3.84, 2.55)  # Set the domain to the range of P8MEA\n)\n\n# Create the leaflet map\nmerged_data %&gt;%\n  na.omit() %&gt;% # filter NAs\n  leaflet() %&gt;%\n  addTiles() %&gt;%\n  setView(lng = -0.1134284, lat = 51.50556315, zoom = 13) %&gt;%\n  addCircleMarkers(\n    lng = ~longitude,    # Use the 'longitude' column from your data\n    lat = ~latitude,     # Use the 'latitude' column from your data\n    radius = 10,          # Radius of the circle markers\n    color = NA,          # Remove the outline by setting color to NA\n    fillColor = ~pal(P8MEA),  # Use the continuous color scale for fillColor\n    fillOpacity = 0.9,   # Opacity of the fill\n    popup = ~as.character(SCHNAME)     # Show the school name in the popup\n  ) %&gt;%\n  addLegend(\n    position = \"bottomright\",   # Position of the legend\n    pal = pal,                  # The color palette\n    values = merged_data$P8MEA, # The values to use in the legend\n    title = \"P8MEA\",            # Title of the legend\n    opacity = 1                 # Opacity of the legend\n  )",
    "crumbs": [
      "Appendices",
      "Leaflet"
    ]
  },
  {
    "objectID": "chapters/A7-QandA.html",
    "href": "chapters/A7-QandA.html",
    "title": "Questions and Answers",
    "section": "",
    "text": "When you are loading packages, sometimes different packages have the same function names in them, and the functions themselves will do very different things. For example, there is a select function in the tidyverse, but also another select function in the package MASS that does something very different. If we load the tidyverse before loading MASS, then the MASS version of select is the one that will be used?!\n\nlibrary(tidyverse)\nlibrary(MASS)\n\ndiamonds %&gt;% select(carat, cut, color)\n\nTo get around this make sure that you load the tidyverse after MASS, to be safe you should always load the tidyverse last.\n\nlibrary(MASS) \nlibrary(tidyverse)\n\ndiamonds %&gt;% select(carat, cut, color)\n\n# A tibble: 53,940 × 3\n   carat cut       color\n   &lt;dbl&gt; &lt;ord&gt;     &lt;ord&gt;\n 1  0.23 Ideal     E    \n 2  0.21 Premium   E    \n 3  0.23 Good      E    \n 4  0.29 Premium   I    \n 5  0.31 Good      J    \n 6  0.24 Very Good J    \n 7  0.24 Very Good I    \n 8  0.26 Very Good H    \n 9  0.22 Fair      E    \n10  0.23 Very Good H    \n# ℹ 53,930 more rows\n\n\nyou can also specify the package that select comes from (in this case from a package within the tidyverse called dplyr):\n\ndiamonds %&gt;% dplyr::select(carat, cut, color)\n\n# A tibble: 53,940 × 3\n   carat cut       color\n   &lt;dbl&gt; &lt;ord&gt;     &lt;ord&gt;\n 1  0.23 Ideal     E    \n 2  0.21 Premium   E    \n 3  0.23 Good      E    \n 4  0.29 Premium   I    \n 5  0.31 Good      J    \n 6  0.24 Very Good J    \n 7  0.24 Very Good I    \n 8  0.26 Very Good H    \n 9  0.22 Fair      E    \n10  0.23 Very Good H    \n# ℹ 53,930 more rows\n\n\nFinally, there is a package that helps your deal with conflicts called conflicted. At the top of your script you can define which version of a function you prefer, this will be the version that will always be used. If you want to specify another version of a function, you can still use other versions of the function using the :: notation:\n\nlibrary(conflicted)\nconflicts_prefer(dplyr::select)\nconflicts_prefer(dplyr::mutate)\nconflicts_prefer(dplyr::summarise)\nconflicts_prefer(dplyr::filter)\n\ndf %&gt;% select(name, age) # uses select from dplyr\ndf %&gt;% MASS::select(name) # uses select from MASS\n\nTo find out if you have any conflicts, you can run conflict_scout().\n\nIf you are finding yourself with a conflict as mentioned above and want to unload packages, then you need to run the following code:\n\n# adapted from: @mmfrgmpds https://stackoverflow.com/questions/7505547/detach-all-packages-while-working-in-r\nwhile(!is.null(sessionInfo()$loadedOnly)){\n  lapply(names(sessionInfo()$loadedOnly), require, character.only = TRUE)\n  invisible(lapply(paste0('package:', names(sessionInfo()$otherPkgs)), detach, character.only=TRUE, unload=TRUE, force=TRUE))    \n}\n\n\nThe pipe operator %&gt;% is loaded when you load the tidyverse package - make sure you have installed tidyverse and loaded it\n\ninstall.packages(\"tidyverse\")  # install\nlibrary(tidyverse)             # load\n\n\nThis may be caused by having a bracket after the geom rather than before it\n\ndata&lt;-data.frame(x=5:1,\n                 y=10:6)\nggplot(data, aes(x, y) +           # Reproduce error message\n         geom_point())\n\n\ndata&lt;-data.frame(x=5:1,\n                 y=10:6)\nggplot(data, aes(x, y)) +           # Fixed error by moving bracket\n         geom_point()\n\n\nIf you want to use long axis titles you may find they overrun the space available\n\ndata&lt;-data.frame(x=5:1,\n                 y=10:6)\nggplot(data, aes(x=x, y=y)) +           \n         geom_col()+\n  ylab(\"A very long description for the y-axis label that will overflow and not look very nice\")\n\nTo insert a line break in the axis label, add \\n to the text where you want line breaks.\n\ndata&lt;-data.frame(x=5:1,\n                 y=10:6)\nggplot(data, aes(x=x, y=y)) +           \n         geom_col()+\n  ylab(\"A very long description \\n for the y-axis label that will \\n overflow and not look very nice\")\n\n\nThe code below will give you a list of all the item labels\n\n# You may want to set the maximun print output to see all the labels\noptions(max.print = 1300)\n\nlapply(PISA_2022, attr, \"label\")\n\n\nYou can use the gt package to convert data frames to aesthetically pleasing outputs.\n\n# load the gt package - you will need to run install.packages(\"gt\") the first time\n# install.packages(\"gt\")\nlibrary(gt)\n\n# Make the data frame you want you want to output\nscience_mean_scores &lt;- PISA_2022 %&gt;%\n  group_by(CNT) %&gt;%\n  summarise(mean_science_score = mean(PV1SCIE, na.rm = TRUE),\n            sd_science = sd(PV1SCIE, na.rm =TRUE))\n\n# Use gt to produce an output - you can copy and paste the table from the\n# viewer window to your report\n\ngt(science_mean_scores)\n\n\n\n\n\nCountry code 3-character\nmean_science_score\nsd_science\n\n\n\nAlbania\n375.8650\n81.17499\n\n\nUnited Arab Emirates\n435.9609\n108.04562\n\n\nArgentina\n415.0584\n86.30466\n\n\nAustralia\n507.7795\n106.78340\n\n\nAustria\n494.0894\n99.10689\n\n\nBelgium\n495.0015\n99.89222\n\n\nBulgaria\n421.9872\n94.68480\n\n\nBrazil\n406.3370\n93.33488\n\n\nBrunei Darussalam\n444.8849\n93.49958\n\n\nCanada\n499.4697\n98.78625\n\n\nSwitzerland\n501.4123\n97.88277\n\n\nChile\n463.1057\n94.91051\n\n\nColombia\n420.9458\n88.24887\n\n\nCosta Rica\n411.2082\n80.40614\n\n\nCzech Republic\n510.7872\n102.76484\n\n\nGermany\n495.2547\n105.42084\n\n\nDenmark\n480.3369\n96.87209\n\n\nDominican Republic\n361.6200\n68.71457\n\n\nSpain\n492.9236\n90.06178\n\n\nEstonia\n527.3109\n87.67284\n\n\nFinland\n497.9649\n111.47589\n\n\nFrance\n481.3834\n105.72320\n\n\nUnited Kingdom\n492.2651\n102.15378\n\n\nGeorgia\n385.6145\n81.63218\n\n\nGreece\n445.4408\n88.95744\n\n\nGuatemala\n374.5886\n65.37109\n\n\nHong Kong (China)\n524.5497\n91.06857\n\n\nCroatia\n483.1283\n91.97320\n\n\nHungary\n492.1069\n94.69703\n\n\nIndonesia\n394.9906\n69.89182\n\n\nIreland\n504.3750\n91.95203\n\n\nIceland\n448.0546\n94.76950\n\n\nIsrael\n464.0777\n108.57084\n\n\nItaly\n481.3281\n91.97045\n\n\nJamaica\n395.7114\n91.97299\n\n\nJordan\n374.6990\n73.68470\n\n\nJapan\n545.5399\n92.72193\n\n\nKazakhstan\n440.9755\n84.44319\n\n\nCambodia\n340.4659\n50.34331\n\n\nKorea\n530.6552\n103.99342\n\n\nKosovo\n353.5723\n64.84509\n\n\nLithuania\n480.0535\n92.51359\n\n\nLatvia\n492.5822\n84.61410\n\n\nMacao (China)\n543.1331\n86.61414\n\n\nMorocco\n363.4098\n66.20574\n\n\nRepublic of Moldova\n416.8691\n82.50639\n\n\nMexico\n410.7969\n74.97042\n\n\nNorth Macedonia\n382.3574\n82.77203\n\n\nMalta\n469.8360\n101.83745\n\n\nMontenegro\n404.9706\n83.35015\n\n\nMongolia\n411.4142\n77.72520\n\n\nMalaysia\n417.1980\n77.85995\n\n\nNetherlands\n486.8380\n111.77833\n\n\nNorway\n478.9396\n106.09425\n\n\nNew Zealand\n504.8458\n107.85424\n\n\nPanama\n385.0859\n84.92427\n\n\nPeru\n410.8352\n85.35240\n\n\nPhilippines\n353.7724\n76.99187\n\n\nPoland\n505.1500\n94.16577\n\n\nPortugal\n488.2668\n89.70144\n\n\nParaguay\n371.6893\n74.52611\n\n\nPalestinian Authority\n367.0259\n70.91610\n\n\nQatar\n428.8246\n96.25937\n\n\nBaku (Azerbaijan)\n381.5571\n78.67151\n\n\nUkrainian regions (18 of 27)\n454.4918\n88.72635\n\n\nRomania\n436.4904\n96.24036\n\n\nSaudi Arabia\n390.1679\n72.21294\n\n\nSingapore\n560.8252\n99.60358\n\n\nEl Salvador\n374.9843\n73.44363\n\n\nSerbia\n446.7715\n88.26844\n\n\nSlovak Republic\n467.2694\n102.95534\n\n\nSlovenia\n487.1098\n93.85904\n\n\nSweden\n494.1717\n107.51162\n\n\nChinese Taipei\n526.8225\n102.25648\n\n\nThailand\n429.1863\n93.12958\n\n\nTürkiye\n476.0276\n89.06750\n\n\nUruguay\n433.2891\n92.41654\n\n\nUnited States\n498.2506\n108.85390\n\n\nUzbekistan\n355.3407\n63.34434\n\n\nViet Nam\n473.3375\n78.42436\n\n\n\n\n\n# You can see more options on formating the table here: https://gt.rstudio.com\n# For example to add a heading\n\ngt(science_mean_scores) %&gt;% tab_header(\n    title = \"Mean science scores\",\n    subtitle = \"PISA 2022 data\")\n\n\n\n\n\n\nMean science scores\n\n\nPISA 2022 data\n\n\nCountry code 3-character\nmean_science_score\nsd_science\n\n\n\n\nAlbania\n375.8650\n81.17499\n\n\nUnited Arab Emirates\n435.9609\n108.04562\n\n\nArgentina\n415.0584\n86.30466\n\n\nAustralia\n507.7795\n106.78340\n\n\nAustria\n494.0894\n99.10689\n\n\nBelgium\n495.0015\n99.89222\n\n\nBulgaria\n421.9872\n94.68480\n\n\nBrazil\n406.3370\n93.33488\n\n\nBrunei Darussalam\n444.8849\n93.49958\n\n\nCanada\n499.4697\n98.78625\n\n\nSwitzerland\n501.4123\n97.88277\n\n\nChile\n463.1057\n94.91051\n\n\nColombia\n420.9458\n88.24887\n\n\nCosta Rica\n411.2082\n80.40614\n\n\nCzech Republic\n510.7872\n102.76484\n\n\nGermany\n495.2547\n105.42084\n\n\nDenmark\n480.3369\n96.87209\n\n\nDominican Republic\n361.6200\n68.71457\n\n\nSpain\n492.9236\n90.06178\n\n\nEstonia\n527.3109\n87.67284\n\n\nFinland\n497.9649\n111.47589\n\n\nFrance\n481.3834\n105.72320\n\n\nUnited Kingdom\n492.2651\n102.15378\n\n\nGeorgia\n385.6145\n81.63218\n\n\nGreece\n445.4408\n88.95744\n\n\nGuatemala\n374.5886\n65.37109\n\n\nHong Kong (China)\n524.5497\n91.06857\n\n\nCroatia\n483.1283\n91.97320\n\n\nHungary\n492.1069\n94.69703\n\n\nIndonesia\n394.9906\n69.89182\n\n\nIreland\n504.3750\n91.95203\n\n\nIceland\n448.0546\n94.76950\n\n\nIsrael\n464.0777\n108.57084\n\n\nItaly\n481.3281\n91.97045\n\n\nJamaica\n395.7114\n91.97299\n\n\nJordan\n374.6990\n73.68470\n\n\nJapan\n545.5399\n92.72193\n\n\nKazakhstan\n440.9755\n84.44319\n\n\nCambodia\n340.4659\n50.34331\n\n\nKorea\n530.6552\n103.99342\n\n\nKosovo\n353.5723\n64.84509\n\n\nLithuania\n480.0535\n92.51359\n\n\nLatvia\n492.5822\n84.61410\n\n\nMacao (China)\n543.1331\n86.61414\n\n\nMorocco\n363.4098\n66.20574\n\n\nRepublic of Moldova\n416.8691\n82.50639\n\n\nMexico\n410.7969\n74.97042\n\n\nNorth Macedonia\n382.3574\n82.77203\n\n\nMalta\n469.8360\n101.83745\n\n\nMontenegro\n404.9706\n83.35015\n\n\nMongolia\n411.4142\n77.72520\n\n\nMalaysia\n417.1980\n77.85995\n\n\nNetherlands\n486.8380\n111.77833\n\n\nNorway\n478.9396\n106.09425\n\n\nNew Zealand\n504.8458\n107.85424\n\n\nPanama\n385.0859\n84.92427\n\n\nPeru\n410.8352\n85.35240\n\n\nPhilippines\n353.7724\n76.99187\n\n\nPoland\n505.1500\n94.16577\n\n\nPortugal\n488.2668\n89.70144\n\n\nParaguay\n371.6893\n74.52611\n\n\nPalestinian Authority\n367.0259\n70.91610\n\n\nQatar\n428.8246\n96.25937\n\n\nBaku (Azerbaijan)\n381.5571\n78.67151\n\n\nUkrainian regions (18 of 27)\n454.4918\n88.72635\n\n\nRomania\n436.4904\n96.24036\n\n\nSaudi Arabia\n390.1679\n72.21294\n\n\nSingapore\n560.8252\n99.60358\n\n\nEl Salvador\n374.9843\n73.44363\n\n\nSerbia\n446.7715\n88.26844\n\n\nSlovak Republic\n467.2694\n102.95534\n\n\nSlovenia\n487.1098\n93.85904\n\n\nSweden\n494.1717\n107.51162\n\n\nChinese Taipei\n526.8225\n102.25648\n\n\nThailand\n429.1863\n93.12958\n\n\nTürkiye\n476.0276\n89.06750\n\n\nUruguay\n433.2891\n92.41654\n\n\nUnited States\n498.2506\n108.85390\n\n\nUzbekistan\n355.3407\n63.34434\n\n\nViet Nam\n473.3375\n78.42436\n\n\n\n\n\n# Or to change the number of decimal places and a column name\n\ngt(science_mean_scores) %&gt;% tab_header(\n  title = \"Mean science scores\",\n  subtitle = \"PISA 2022 data\") %&gt;%\n  fmt_number(columns = c(mean_science_score , sd_science), decimals = 1) %&gt;%\n  cols_label(\"CNT\" = md(\"**Country**\"))\n\n\n\n\n\n\nMean science scores\n\n\nPISA 2022 data\n\n\nCountry\nmean_science_score\nsd_science\n\n\n\n\nAlbania\n375.9\n81.2\n\n\nUnited Arab Emirates\n436.0\n108.0\n\n\nArgentina\n415.1\n86.3\n\n\nAustralia\n507.8\n106.8\n\n\nAustria\n494.1\n99.1\n\n\nBelgium\n495.0\n99.9\n\n\nBulgaria\n422.0\n94.7\n\n\nBrazil\n406.3\n93.3\n\n\nBrunei Darussalam\n444.9\n93.5\n\n\nCanada\n499.5\n98.8\n\n\nSwitzerland\n501.4\n97.9\n\n\nChile\n463.1\n94.9\n\n\nColombia\n420.9\n88.2\n\n\nCosta Rica\n411.2\n80.4\n\n\nCzech Republic\n510.8\n102.8\n\n\nGermany\n495.3\n105.4\n\n\nDenmark\n480.3\n96.9\n\n\nDominican Republic\n361.6\n68.7\n\n\nSpain\n492.9\n90.1\n\n\nEstonia\n527.3\n87.7\n\n\nFinland\n498.0\n111.5\n\n\nFrance\n481.4\n105.7\n\n\nUnited Kingdom\n492.3\n102.2\n\n\nGeorgia\n385.6\n81.6\n\n\nGreece\n445.4\n89.0\n\n\nGuatemala\n374.6\n65.4\n\n\nHong Kong (China)\n524.5\n91.1\n\n\nCroatia\n483.1\n92.0\n\n\nHungary\n492.1\n94.7\n\n\nIndonesia\n395.0\n69.9\n\n\nIreland\n504.4\n92.0\n\n\nIceland\n448.1\n94.8\n\n\nIsrael\n464.1\n108.6\n\n\nItaly\n481.3\n92.0\n\n\nJamaica\n395.7\n92.0\n\n\nJordan\n374.7\n73.7\n\n\nJapan\n545.5\n92.7\n\n\nKazakhstan\n441.0\n84.4\n\n\nCambodia\n340.5\n50.3\n\n\nKorea\n530.7\n104.0\n\n\nKosovo\n353.6\n64.8\n\n\nLithuania\n480.1\n92.5\n\n\nLatvia\n492.6\n84.6\n\n\nMacao (China)\n543.1\n86.6\n\n\nMorocco\n363.4\n66.2\n\n\nRepublic of Moldova\n416.9\n82.5\n\n\nMexico\n410.8\n75.0\n\n\nNorth Macedonia\n382.4\n82.8\n\n\nMalta\n469.8\n101.8\n\n\nMontenegro\n405.0\n83.4\n\n\nMongolia\n411.4\n77.7\n\n\nMalaysia\n417.2\n77.9\n\n\nNetherlands\n486.8\n111.8\n\n\nNorway\n478.9\n106.1\n\n\nNew Zealand\n504.8\n107.9\n\n\nPanama\n385.1\n84.9\n\n\nPeru\n410.8\n85.4\n\n\nPhilippines\n353.8\n77.0\n\n\nPoland\n505.1\n94.2\n\n\nPortugal\n488.3\n89.7\n\n\nParaguay\n371.7\n74.5\n\n\nPalestinian Authority\n367.0\n70.9\n\n\nQatar\n428.8\n96.3\n\n\nBaku (Azerbaijan)\n381.6\n78.7\n\n\nUkrainian regions (18 of 27)\n454.5\n88.7\n\n\nRomania\n436.5\n96.2\n\n\nSaudi Arabia\n390.2\n72.2\n\n\nSingapore\n560.8\n99.6\n\n\nEl Salvador\n375.0\n73.4\n\n\nSerbia\n446.8\n88.3\n\n\nSlovak Republic\n467.3\n103.0\n\n\nSlovenia\n487.1\n93.9\n\n\nSweden\n494.2\n107.5\n\n\nChinese Taipei\n526.8\n102.3\n\n\nThailand\n429.2\n93.1\n\n\nTürkiye\n476.0\n89.1\n\n\nUruguay\n433.3\n92.4\n\n\nUnited States\n498.3\n108.9\n\n\nUzbekistan\n355.3\n63.3\n\n\nViet Nam\n473.3\n78.4\n\n\n\n\n\n## If you have an output from a linear model, there is an additional step to do before using gt\n# You need to use the broom package, which has the `tidy` function which gets the output of `lm`\n# Into a suitable format for turing into a table\n# install.packages(\"broom\")\n\nlibrary(broom)\n\n# Create example dataframe\n\nUK_PISA &lt;- PISA_2022 %&gt;%\n  select(PV1SCIE, PV1MATH, CNT) %&gt;%\n  filter(CNT == \"United Kingdom\")\n\n# Run the model\n\nuk_mod &lt;- lm(data = UK_PISA, PV1SCIE ~ PV1MATH)\n\n# tidy the model\n\nuk_mod_tidy &lt;- tidy(uk_mod)\n\n# pass to gt to produce nice output\n\ngt(uk_mod_tidy)\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n(Intercept)\n42.3335278\n2.304412214\n18.37064\n1.978594e-74\n\n\nPV1MATH\n0.9324181\n0.004685464\n199.00232\n0.000000e+00\n\n\n\n\n\n\n\nWhen you have run some tests, the outputs (for example the degrees of freedom, test statistic and p-value) should be formatted in your paper in line with the citation convention of the journal or assessment (for example, KCL assignments follow the American Psychological Association (APA) citation style). You can find a general guide to presenting your results in APA style here: APA numbers and statistics style guide.\nFor example, to report a chi-square result:\n\n# Create example dataframe\n\nUK_gender_differences &lt;- PISA_2022 %&gt;%\n  select(CNT, ST004D01T) %&gt;%\n  filter(CNT == \"United Kingdom\") %&gt;% \n  droplevels()\n\ncont_tab &lt;- xtabs(data = UK_gender_differences, ~ ST004D01T)\n\n# Run a chi sqaure goodness of fit test\n\nchisq.test(cont_tab, p = c(0.5, 0.5))\n\n\n    Chi-squared test for given probabilities\n\ndata:  cont_tab\nX-squared = 2.4425, df = 1, p-value = 0.1181\n\n\nA chi-square test of goodness-of-fit was conducted to compare the observed frequencies in the contingency table to the expected frequencies (equal numbers of boys and girls). The result was not statistically significant, χ²(1, N = 12973) = 2.44, p = .12, indicating no significant difference between the observed and expected frequencies.\nTo report a t-test of the mathematics scores of girls and boys in the UK:\n\n# Create example dataframe\n\nUK_PISA &lt;- PISA_2022 %&gt;%\n  select(PV1MATH, CNT, ST004D01T) %&gt;%\n  filter(CNT == \"United Kingdom\")\n\n# Run a t-test\n\nt.test(data = UK_PISA, PV1MATH ~ ST004D01T)\n\n\n    Welch Two Sample t-test\n\ndata:  PV1MATH by ST004D01T\nt = -8.2246, df = 12942, p-value &lt; 2.2e-16\nalternative hypothesis: true difference in means between group Female and group Male is not equal to 0\n95 percent confidence interval:\n -16.9470 -10.4238\nsample estimates:\nmean in group Female   mean in group Male \n            475.6061             489.2915 \n\n\nThe output of that test would be reported as follows:\nThe results of a Welch’s t-test indicated a statistically significant difference in mean mathematics scores between UK females (M = 475.61) and UK males (M = 489.29), t(12,942) = -8.22, p &lt; .001, 95% CI [-16.95, -10.42].\nAlternatively, consider the output of an anova to look at the difference in wealth scores between Finland, Norway, and Sweden:\n\n# Create example dataframe\n\nwealth_scores &lt;- PISA_2022 %&gt;%\n  select(HOMEPOS, CNT) %&gt;%\n  filter(CNT == \"Finland\" | CNT == \"Norway\" | CNT == \"Sweden\")\n\n# Run an anova and summarise\n\naov_out &lt;- aov(data = wealth_scores, HOMEPOS ~ CNT)\nsummary(aov_out)\n\n               Df Sum Sq Mean Sq F value Pr(&gt;F)    \nCNT             2    575  287.61   356.7 &lt;2e-16 ***\nResiduals   22335  18008    0.81                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n584 observations deleted due to missingness\n\nTukeyHSD(aov_out)\n\n  Tukey multiple comparisons of means\n    95% family-wise confidence level\n\nFit: aov(formula = HOMEPOS ~ CNT, data = wealth_scores)\n\n$CNT\n                     diff        lwr        upr p adj\nNorway-Finland  0.3846629  0.3508747  0.4184511     0\nSweden-Finland  0.1645141  0.1301168  0.1989114     0\nSweden-Norway  -0.2201488 -0.2581530 -0.1821445     0\n\n\nA one-way ANOVA was conducted to compare levels of home possessions (HOMEPOS) across three countries (CNT: Finland, Norway, and Sweden). The analysis revealed a statistically significant effect of country on home possessions, F(2, 22,335) = 356.7, p &lt; .001, η² = .031.\nPost hoc Tukey’s HSD tests indicated the following pairwise differences:\nNorway had significantly higher HOMEPOS scores than Finland (M difference = 0.38, 95% CI [0.35, 0.42], p &lt; .001). Sweden had significantly higher HOMEPOS scores than Finland (M difference = 0.16, 95% CI [0.13, 0.20], p &lt; .001). Sweden had significantly lower HOMEPOS scores than Norway (M difference = -0.22, 95% CI [-0.26, -0.18], p &lt; .001). A total of 584 observations were excluded due to missing data.\nAlternatively, you can use the report function in the easystats package to give a summary of an output.\n\nlibrary(easystats)\n\n# Get a summary of an anova\n\nreport(aov_out)\n\nThe ANOVA (formula: HOMEPOS ~ CNT) suggests that:\n\n  - The main effect of CNT is statistically significant and small (F(2, 22335) =\n356.72, p &lt; .001; Eta2 = 0.03, 95% CI [0.03, 1.00])\n\nEffect sizes were labelled following Field's (2013) recommendations.\n\n# And of a linear model\n\nmod1 &lt;- lm(data = wealth_scores, HOMEPOS ~ CNT)\n\nreport(mod1)\n\nWe fitted a linear model (estimated using OLS) to predict HOMEPOS with CNT\n(formula: HOMEPOS ~ CNT). The model explains a statistically significant and\nweak proportion of variance (R2 = 0.03, F(2, 22335) = 356.72, p &lt; .001, adj. R2\n= 0.03). The model's intercept, corresponding to CNT = Albania, is at 0.16 (95%\nCI [0.14, 0.18], t(22335) = 18.13, p &lt; .001). Within this model:\n\n  - The effect of CNT [Norway] is statistically significant and positive (beta =\n0.38, 95% CI [0.36, 0.41], t(22335) = 26.68, p &lt; .001; Std. beta = 0.42, 95% CI\n[0.39, 0.45])\n  - The effect of CNT [Sweden] is statistically significant and positive (beta =\n0.16, 95% CI [0.14, 0.19], t(22335) = 11.21, p &lt; .001; Std. beta = 0.18, 95% CI\n[0.15, 0.21])\n\nStandardized parameters were obtained by fitting the model on a standardized\nversion of the dataset. 95% Confidence Intervals (CIs) and p-values were\ncomputed using a Wald t-distribution approximation.\n\n\nTo produce tables in APA format, you can use the apa.aov.table (for anovas) or apa.reg.table (for linear model outputs) functions from the apaTables package. You will need to install the package first using install.packages(\"apaTables\").\n\nlibrary(apaTables)\n\n# Get a summary table from an anova\n\napa.aov.table(aov_out)\n\n\n\nANOVA results using HOMEPOS as the dependent variable\n \n\n   Predictor       SS    df     MS      F    p partial_eta2 CI_90_partial_eta2\n (Intercept)   264.91     1 264.91 328.56 .000                                \n         CNT   575.22     2 287.61 356.72 .000          .03         [.03, .03]\n       Error 18007.84 22335   0.81                                            \n\nNote: Values in square brackets indicate the bounds of the 90% confidence interval for partial eta-squared \n\n# And of a linear model\n\napa.reg.table(mod1)\n\n\n\nRegression results using HOMEPOS as the criterion\n \n\n   Predictor      b     b_95%_CI sr2 sr2_95%_CI             Fit\n (Intercept) 0.16** [0.14, 0.18]                               \n   CNTNorway 0.38** [0.36, 0.41] .03 [.03, .04]                \n   CNTSweden 0.16** [0.14, 0.19] .01 [.00, .01]                \n                                                    R2 = .031**\n                                                95% CI[.03,.04]\n                                                               \n\nNote. A significant b-weight indicates the semi-partial correlation is also significant.\nb represents unstandardized regression weights. \nsr2 represents the semi-partial correlation squared.\nSquare brackets are used to enclose the lower and upper limits of a confidence interval.\n* indicates p &lt; .05. ** indicates p &lt; .01.\n \n\n\nYou can get more aesthetically pleasing versions of both tables using the gt function in the gt package. Before passing the outputs of avo of lm to gt, you will need to use the tidy fucntion from the broom package to tidy the output.\n\nlibrary(gt)\nlibrary(broom)\n\n# Tidy the outputs\n\ntidied_aov &lt;- tidy(aov_out)\ntidied_mod1 &lt;- tidy(mod1)\n\n\n# Produced a nicely formatted table from an anova\n\ngt(tidied_aov)\n\n\n\n\n\nterm\ndf\nsumsq\nmeansq\nstatistic\np.value\n\n\n\nCNT\n2\n575.2171\n287.6085570\n356.719\n3.175047e-153\n\n\nResiduals\n22335\n18007.8370\n0.8062609\nNA\nNA\n\n\n\n\n\n# And of a linear model\n\ngt(tidied_mod1)\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n(Intercept)\n0.1622658\n0.008951941\n18.12632\n6.584384e-73\n\n\nCNTNorway\n0.3846629\n0.014415658\n26.68369\n1.915252e-154\n\n\nCNTSweden\n0.1645141\n0.014675508\n11.21011\n4.349919e-29\n\n\n\n\n\n\n\nThere are a number of helpful packages that can add data to charts. First ggpubr lets you add data about the regression line to your plot using the stat_regline_equation() function. You will need to tweak the coordinates (label.x and label.y) to appear appropiately on your chart.\n\n# Load the ggpbur library (you will need to run install.packages(\"ggpubr\") the first time you use it)\nlibrary(ggpubr)\n\n# Create example dataframe\n\nUK_wealth_reading &lt;- PISA_2022 %&gt;%\n  select(CNT, PV1READ, HOMEPOS) %&gt;%\n  filter(CNT == \"United Kingdom\") \n\n# Plot a scatter plot with the regression equation\n\nggplot(UK_wealth_reading, aes(x = HOMEPOS, y = PV1READ)) +\n  geom_point(colour = \"lightgreen\", size = 0.1) +\n  geom_smooth(method = \"lm\") +\n  stat_regline_equation(label.x = -5, label.y = 600)  # Add regression equation\n\n\n\n\n\n\n\nYou can also use stat_regline_equation to add additional information like the p-value of the model and the R2 value:\n\n# Load the ggpbur library (you will need to run install.packages(\"ggpubr\") the first time you use it)\nlibrary(ggpubr)\n\n# Create example dataframe\n\nUK_wealth_reading &lt;- PISA_2022 %&gt;%\n  select(CNT, PV1READ, HOMEPOS) %&gt;%\n  filter(CNT == \"United Kingdom\") \n\n# Plot a scatter plot with the regression equation\n\nggplot(UK_wealth_reading, aes(x = HOMEPOS, y = PV1READ)) +\n  geom_point(colour = \"lightgreen\", size = 0.1) +\n  geom_smooth(method = \"lm\", formula = y ~ x) + # Ensure formula is specified here too\n  stat_regline_equation(\n    aes(label = paste(..eq.label.., ..adj.rr.label.., sep = \"~~~~\")), # Indicate you want the equation and R2 value and the seperator text\n    label.x = -10, label.y = 600,\n    formula = y ~ x)\n\n\n\n\n\n\n\nAnother powerful package for adding data to graphs is ggstatsplot. For example, it can anotate a plot with anova data. For example, if you want compare the science scores of the UK, Japan and the US:\n\n# Load the ggstatplot library (you will need to run install.packages(\"ggstatsplot\") the first time you use it)\nlibrary(ggstatsplot)\n\n# Create example dataframe\n\ncountry_sci_data &lt;- PISA_2022 %&gt;%\n  select(CNT, PV1SCIE) %&gt;%\n  filter(CNT == \"United Kingdom\" | CNT == \"Japan\" | CNT == \"United States\")\n\n# Use ggstatplot to create an annotated plot with an anova result\n\nggbetweenstats(\n  data  = country_sci_data,\n  x     = CNT,\n  y     = PV1SCIE,\n  title = \"Science scores in the UK, US and Japan\",\n  type  = \"parametric\" # Forces the test to be ANOVA\n)",
    "crumbs": [
      "Appendices",
      "Questions and Answers"
    ]
  },
  {
    "objectID": "chapters/A7-QandA.html#why-doesnt-my-selectfilter-statement-work",
    "href": "chapters/A7-QandA.html#why-doesnt-my-selectfilter-statement-work",
    "title": "Questions and Answers",
    "section": "",
    "text": "When you are loading packages, sometimes different packages have the same function names in them, and the functions themselves will do very different things. For example, there is a select function in the tidyverse, but also another select function in the package MASS that does something very different. If we load the tidyverse before loading MASS, then the MASS version of select is the one that will be used?!\n\nlibrary(tidyverse)\nlibrary(MASS)\n\ndiamonds %&gt;% select(carat, cut, color)\n\nTo get around this make sure that you load the tidyverse after MASS, to be safe you should always load the tidyverse last.\n\nlibrary(MASS) \nlibrary(tidyverse)\n\ndiamonds %&gt;% select(carat, cut, color)\n\n# A tibble: 53,940 × 3\n   carat cut       color\n   &lt;dbl&gt; &lt;ord&gt;     &lt;ord&gt;\n 1  0.23 Ideal     E    \n 2  0.21 Premium   E    \n 3  0.23 Good      E    \n 4  0.29 Premium   I    \n 5  0.31 Good      J    \n 6  0.24 Very Good J    \n 7  0.24 Very Good I    \n 8  0.26 Very Good H    \n 9  0.22 Fair      E    \n10  0.23 Very Good H    \n# ℹ 53,930 more rows\n\n\nyou can also specify the package that select comes from (in this case from a package within the tidyverse called dplyr):\n\ndiamonds %&gt;% dplyr::select(carat, cut, color)\n\n# A tibble: 53,940 × 3\n   carat cut       color\n   &lt;dbl&gt; &lt;ord&gt;     &lt;ord&gt;\n 1  0.23 Ideal     E    \n 2  0.21 Premium   E    \n 3  0.23 Good      E    \n 4  0.29 Premium   I    \n 5  0.31 Good      J    \n 6  0.24 Very Good J    \n 7  0.24 Very Good I    \n 8  0.26 Very Good H    \n 9  0.22 Fair      E    \n10  0.23 Very Good H    \n# ℹ 53,930 more rows\n\n\nFinally, there is a package that helps your deal with conflicts called conflicted. At the top of your script you can define which version of a function you prefer, this will be the version that will always be used. If you want to specify another version of a function, you can still use other versions of the function using the :: notation:\n\nlibrary(conflicted)\nconflicts_prefer(dplyr::select)\nconflicts_prefer(dplyr::mutate)\nconflicts_prefer(dplyr::summarise)\nconflicts_prefer(dplyr::filter)\n\ndf %&gt;% select(name, age) # uses select from dplyr\ndf %&gt;% MASS::select(name) # uses select from MASS\n\nTo find out if you have any conflicts, you can run conflict_scout().",
    "crumbs": [
      "Appendices",
      "Questions and Answers"
    ]
  },
  {
    "objectID": "chapters/A7-QandA.html#how-can-i-unload-packages",
    "href": "chapters/A7-QandA.html#how-can-i-unload-packages",
    "title": "Questions and Answers",
    "section": "",
    "text": "If you are finding yourself with a conflict as mentioned above and want to unload packages, then you need to run the following code:\n\n# adapted from: @mmfrgmpds https://stackoverflow.com/questions/7505547/detach-all-packages-while-working-in-r\nwhile(!is.null(sessionInfo()$loadedOnly)){\n  lapply(names(sessionInfo()$loadedOnly), require, character.only = TRUE)\n  invisible(lapply(paste0('package:', names(sessionInfo()$otherPkgs)), detach, character.only=TRUE, unload=TRUE, force=TRUE))    \n}",
    "crumbs": [
      "Appendices",
      "Questions and Answers"
    ]
  },
  {
    "objectID": "chapters/A7-QandA.html#why-am-i-getting-the-error-could-not-find-function",
    "href": "chapters/A7-QandA.html#why-am-i-getting-the-error-could-not-find-function",
    "title": "Questions and Answers",
    "section": "",
    "text": "The pipe operator %&gt;% is loaded when you load the tidyverse package - make sure you have installed tidyverse and loaded it\n\ninstall.packages(\"tidyverse\")  # install\nlibrary(tidyverse)             # load",
    "crumbs": [
      "Appendices",
      "Questions and Answers"
    ]
  },
  {
    "objectID": "chapters/A7-QandA.html#i-am-getting-the-error-error-mapping-should-be-created-with-aes-or-aes_.-when-using-ggplot",
    "href": "chapters/A7-QandA.html#i-am-getting-the-error-error-mapping-should-be-created-with-aes-or-aes_.-when-using-ggplot",
    "title": "Questions and Answers",
    "section": "",
    "text": "This may be caused by having a bracket after the geom rather than before it\n\ndata&lt;-data.frame(x=5:1,\n                 y=10:6)\nggplot(data, aes(x, y) +           # Reproduce error message\n         geom_point())\n\n\ndata&lt;-data.frame(x=5:1,\n                 y=10:6)\nggplot(data, aes(x, y)) +           # Fixed error by moving bracket\n         geom_point()",
    "crumbs": [
      "Appendices",
      "Questions and Answers"
    ]
  },
  {
    "objectID": "chapters/A7-QandA.html#my-axis-labels-are-too-long",
    "href": "chapters/A7-QandA.html#my-axis-labels-are-too-long",
    "title": "Questions and Answers",
    "section": "",
    "text": "If you want to use long axis titles you may find they overrun the space available\n\ndata&lt;-data.frame(x=5:1,\n                 y=10:6)\nggplot(data, aes(x=x, y=y)) +           \n         geom_col()+\n  ylab(\"A very long description for the y-axis label that will overflow and not look very nice\")\n\nTo insert a line break in the axis label, add \\n to the text where you want line breaks.\n\ndata&lt;-data.frame(x=5:1,\n                 y=10:6)\nggplot(data, aes(x=x, y=y)) +           \n         geom_col()+\n  ylab(\"A very long description \\n for the y-axis label that will \\n overflow and not look very nice\")",
    "crumbs": [
      "Appendices",
      "Questions and Answers"
    ]
  },
  {
    "objectID": "chapters/A7-QandA.html#how-can-i-find-out-the-full-item-labels-in-the-pisa-data-frame",
    "href": "chapters/A7-QandA.html#how-can-i-find-out-the-full-item-labels-in-the-pisa-data-frame",
    "title": "Questions and Answers",
    "section": "",
    "text": "The code below will give you a list of all the item labels\n\n# You may want to set the maximun print output to see all the labels\noptions(max.print = 1300)\n\nlapply(PISA_2022, attr, \"label\")",
    "crumbs": [
      "Appendices",
      "Questions and Answers"
    ]
  },
  {
    "objectID": "chapters/A7-QandA.html#how-do-i-turn-a-data-frame-into-a-form-i-can-put-into-an-assingment-or-paper",
    "href": "chapters/A7-QandA.html#how-do-i-turn-a-data-frame-into-a-form-i-can-put-into-an-assingment-or-paper",
    "title": "Questions and Answers",
    "section": "",
    "text": "You can use the gt package to convert data frames to aesthetically pleasing outputs.\n\n# load the gt package - you will need to run install.packages(\"gt\") the first time\n# install.packages(\"gt\")\nlibrary(gt)\n\n# Make the data frame you want you want to output\nscience_mean_scores &lt;- PISA_2022 %&gt;%\n  group_by(CNT) %&gt;%\n  summarise(mean_science_score = mean(PV1SCIE, na.rm = TRUE),\n            sd_science = sd(PV1SCIE, na.rm =TRUE))\n\n# Use gt to produce an output - you can copy and paste the table from the\n# viewer window to your report\n\ngt(science_mean_scores)\n\n\n\n\n\nCountry code 3-character\nmean_science_score\nsd_science\n\n\n\nAlbania\n375.8650\n81.17499\n\n\nUnited Arab Emirates\n435.9609\n108.04562\n\n\nArgentina\n415.0584\n86.30466\n\n\nAustralia\n507.7795\n106.78340\n\n\nAustria\n494.0894\n99.10689\n\n\nBelgium\n495.0015\n99.89222\n\n\nBulgaria\n421.9872\n94.68480\n\n\nBrazil\n406.3370\n93.33488\n\n\nBrunei Darussalam\n444.8849\n93.49958\n\n\nCanada\n499.4697\n98.78625\n\n\nSwitzerland\n501.4123\n97.88277\n\n\nChile\n463.1057\n94.91051\n\n\nColombia\n420.9458\n88.24887\n\n\nCosta Rica\n411.2082\n80.40614\n\n\nCzech Republic\n510.7872\n102.76484\n\n\nGermany\n495.2547\n105.42084\n\n\nDenmark\n480.3369\n96.87209\n\n\nDominican Republic\n361.6200\n68.71457\n\n\nSpain\n492.9236\n90.06178\n\n\nEstonia\n527.3109\n87.67284\n\n\nFinland\n497.9649\n111.47589\n\n\nFrance\n481.3834\n105.72320\n\n\nUnited Kingdom\n492.2651\n102.15378\n\n\nGeorgia\n385.6145\n81.63218\n\n\nGreece\n445.4408\n88.95744\n\n\nGuatemala\n374.5886\n65.37109\n\n\nHong Kong (China)\n524.5497\n91.06857\n\n\nCroatia\n483.1283\n91.97320\n\n\nHungary\n492.1069\n94.69703\n\n\nIndonesia\n394.9906\n69.89182\n\n\nIreland\n504.3750\n91.95203\n\n\nIceland\n448.0546\n94.76950\n\n\nIsrael\n464.0777\n108.57084\n\n\nItaly\n481.3281\n91.97045\n\n\nJamaica\n395.7114\n91.97299\n\n\nJordan\n374.6990\n73.68470\n\n\nJapan\n545.5399\n92.72193\n\n\nKazakhstan\n440.9755\n84.44319\n\n\nCambodia\n340.4659\n50.34331\n\n\nKorea\n530.6552\n103.99342\n\n\nKosovo\n353.5723\n64.84509\n\n\nLithuania\n480.0535\n92.51359\n\n\nLatvia\n492.5822\n84.61410\n\n\nMacao (China)\n543.1331\n86.61414\n\n\nMorocco\n363.4098\n66.20574\n\n\nRepublic of Moldova\n416.8691\n82.50639\n\n\nMexico\n410.7969\n74.97042\n\n\nNorth Macedonia\n382.3574\n82.77203\n\n\nMalta\n469.8360\n101.83745\n\n\nMontenegro\n404.9706\n83.35015\n\n\nMongolia\n411.4142\n77.72520\n\n\nMalaysia\n417.1980\n77.85995\n\n\nNetherlands\n486.8380\n111.77833\n\n\nNorway\n478.9396\n106.09425\n\n\nNew Zealand\n504.8458\n107.85424\n\n\nPanama\n385.0859\n84.92427\n\n\nPeru\n410.8352\n85.35240\n\n\nPhilippines\n353.7724\n76.99187\n\n\nPoland\n505.1500\n94.16577\n\n\nPortugal\n488.2668\n89.70144\n\n\nParaguay\n371.6893\n74.52611\n\n\nPalestinian Authority\n367.0259\n70.91610\n\n\nQatar\n428.8246\n96.25937\n\n\nBaku (Azerbaijan)\n381.5571\n78.67151\n\n\nUkrainian regions (18 of 27)\n454.4918\n88.72635\n\n\nRomania\n436.4904\n96.24036\n\n\nSaudi Arabia\n390.1679\n72.21294\n\n\nSingapore\n560.8252\n99.60358\n\n\nEl Salvador\n374.9843\n73.44363\n\n\nSerbia\n446.7715\n88.26844\n\n\nSlovak Republic\n467.2694\n102.95534\n\n\nSlovenia\n487.1098\n93.85904\n\n\nSweden\n494.1717\n107.51162\n\n\nChinese Taipei\n526.8225\n102.25648\n\n\nThailand\n429.1863\n93.12958\n\n\nTürkiye\n476.0276\n89.06750\n\n\nUruguay\n433.2891\n92.41654\n\n\nUnited States\n498.2506\n108.85390\n\n\nUzbekistan\n355.3407\n63.34434\n\n\nViet Nam\n473.3375\n78.42436\n\n\n\n\n\n# You can see more options on formating the table here: https://gt.rstudio.com\n# For example to add a heading\n\ngt(science_mean_scores) %&gt;% tab_header(\n    title = \"Mean science scores\",\n    subtitle = \"PISA 2022 data\")\n\n\n\n\n\n\nMean science scores\n\n\nPISA 2022 data\n\n\nCountry code 3-character\nmean_science_score\nsd_science\n\n\n\n\nAlbania\n375.8650\n81.17499\n\n\nUnited Arab Emirates\n435.9609\n108.04562\n\n\nArgentina\n415.0584\n86.30466\n\n\nAustralia\n507.7795\n106.78340\n\n\nAustria\n494.0894\n99.10689\n\n\nBelgium\n495.0015\n99.89222\n\n\nBulgaria\n421.9872\n94.68480\n\n\nBrazil\n406.3370\n93.33488\n\n\nBrunei Darussalam\n444.8849\n93.49958\n\n\nCanada\n499.4697\n98.78625\n\n\nSwitzerland\n501.4123\n97.88277\n\n\nChile\n463.1057\n94.91051\n\n\nColombia\n420.9458\n88.24887\n\n\nCosta Rica\n411.2082\n80.40614\n\n\nCzech Republic\n510.7872\n102.76484\n\n\nGermany\n495.2547\n105.42084\n\n\nDenmark\n480.3369\n96.87209\n\n\nDominican Republic\n361.6200\n68.71457\n\n\nSpain\n492.9236\n90.06178\n\n\nEstonia\n527.3109\n87.67284\n\n\nFinland\n497.9649\n111.47589\n\n\nFrance\n481.3834\n105.72320\n\n\nUnited Kingdom\n492.2651\n102.15378\n\n\nGeorgia\n385.6145\n81.63218\n\n\nGreece\n445.4408\n88.95744\n\n\nGuatemala\n374.5886\n65.37109\n\n\nHong Kong (China)\n524.5497\n91.06857\n\n\nCroatia\n483.1283\n91.97320\n\n\nHungary\n492.1069\n94.69703\n\n\nIndonesia\n394.9906\n69.89182\n\n\nIreland\n504.3750\n91.95203\n\n\nIceland\n448.0546\n94.76950\n\n\nIsrael\n464.0777\n108.57084\n\n\nItaly\n481.3281\n91.97045\n\n\nJamaica\n395.7114\n91.97299\n\n\nJordan\n374.6990\n73.68470\n\n\nJapan\n545.5399\n92.72193\n\n\nKazakhstan\n440.9755\n84.44319\n\n\nCambodia\n340.4659\n50.34331\n\n\nKorea\n530.6552\n103.99342\n\n\nKosovo\n353.5723\n64.84509\n\n\nLithuania\n480.0535\n92.51359\n\n\nLatvia\n492.5822\n84.61410\n\n\nMacao (China)\n543.1331\n86.61414\n\n\nMorocco\n363.4098\n66.20574\n\n\nRepublic of Moldova\n416.8691\n82.50639\n\n\nMexico\n410.7969\n74.97042\n\n\nNorth Macedonia\n382.3574\n82.77203\n\n\nMalta\n469.8360\n101.83745\n\n\nMontenegro\n404.9706\n83.35015\n\n\nMongolia\n411.4142\n77.72520\n\n\nMalaysia\n417.1980\n77.85995\n\n\nNetherlands\n486.8380\n111.77833\n\n\nNorway\n478.9396\n106.09425\n\n\nNew Zealand\n504.8458\n107.85424\n\n\nPanama\n385.0859\n84.92427\n\n\nPeru\n410.8352\n85.35240\n\n\nPhilippines\n353.7724\n76.99187\n\n\nPoland\n505.1500\n94.16577\n\n\nPortugal\n488.2668\n89.70144\n\n\nParaguay\n371.6893\n74.52611\n\n\nPalestinian Authority\n367.0259\n70.91610\n\n\nQatar\n428.8246\n96.25937\n\n\nBaku (Azerbaijan)\n381.5571\n78.67151\n\n\nUkrainian regions (18 of 27)\n454.4918\n88.72635\n\n\nRomania\n436.4904\n96.24036\n\n\nSaudi Arabia\n390.1679\n72.21294\n\n\nSingapore\n560.8252\n99.60358\n\n\nEl Salvador\n374.9843\n73.44363\n\n\nSerbia\n446.7715\n88.26844\n\n\nSlovak Republic\n467.2694\n102.95534\n\n\nSlovenia\n487.1098\n93.85904\n\n\nSweden\n494.1717\n107.51162\n\n\nChinese Taipei\n526.8225\n102.25648\n\n\nThailand\n429.1863\n93.12958\n\n\nTürkiye\n476.0276\n89.06750\n\n\nUruguay\n433.2891\n92.41654\n\n\nUnited States\n498.2506\n108.85390\n\n\nUzbekistan\n355.3407\n63.34434\n\n\nViet Nam\n473.3375\n78.42436\n\n\n\n\n\n# Or to change the number of decimal places and a column name\n\ngt(science_mean_scores) %&gt;% tab_header(\n  title = \"Mean science scores\",\n  subtitle = \"PISA 2022 data\") %&gt;%\n  fmt_number(columns = c(mean_science_score , sd_science), decimals = 1) %&gt;%\n  cols_label(\"CNT\" = md(\"**Country**\"))\n\n\n\n\n\n\nMean science scores\n\n\nPISA 2022 data\n\n\nCountry\nmean_science_score\nsd_science\n\n\n\n\nAlbania\n375.9\n81.2\n\n\nUnited Arab Emirates\n436.0\n108.0\n\n\nArgentina\n415.1\n86.3\n\n\nAustralia\n507.8\n106.8\n\n\nAustria\n494.1\n99.1\n\n\nBelgium\n495.0\n99.9\n\n\nBulgaria\n422.0\n94.7\n\n\nBrazil\n406.3\n93.3\n\n\nBrunei Darussalam\n444.9\n93.5\n\n\nCanada\n499.5\n98.8\n\n\nSwitzerland\n501.4\n97.9\n\n\nChile\n463.1\n94.9\n\n\nColombia\n420.9\n88.2\n\n\nCosta Rica\n411.2\n80.4\n\n\nCzech Republic\n510.8\n102.8\n\n\nGermany\n495.3\n105.4\n\n\nDenmark\n480.3\n96.9\n\n\nDominican Republic\n361.6\n68.7\n\n\nSpain\n492.9\n90.1\n\n\nEstonia\n527.3\n87.7\n\n\nFinland\n498.0\n111.5\n\n\nFrance\n481.4\n105.7\n\n\nUnited Kingdom\n492.3\n102.2\n\n\nGeorgia\n385.6\n81.6\n\n\nGreece\n445.4\n89.0\n\n\nGuatemala\n374.6\n65.4\n\n\nHong Kong (China)\n524.5\n91.1\n\n\nCroatia\n483.1\n92.0\n\n\nHungary\n492.1\n94.7\n\n\nIndonesia\n395.0\n69.9\n\n\nIreland\n504.4\n92.0\n\n\nIceland\n448.1\n94.8\n\n\nIsrael\n464.1\n108.6\n\n\nItaly\n481.3\n92.0\n\n\nJamaica\n395.7\n92.0\n\n\nJordan\n374.7\n73.7\n\n\nJapan\n545.5\n92.7\n\n\nKazakhstan\n441.0\n84.4\n\n\nCambodia\n340.5\n50.3\n\n\nKorea\n530.7\n104.0\n\n\nKosovo\n353.6\n64.8\n\n\nLithuania\n480.1\n92.5\n\n\nLatvia\n492.6\n84.6\n\n\nMacao (China)\n543.1\n86.6\n\n\nMorocco\n363.4\n66.2\n\n\nRepublic of Moldova\n416.9\n82.5\n\n\nMexico\n410.8\n75.0\n\n\nNorth Macedonia\n382.4\n82.8\n\n\nMalta\n469.8\n101.8\n\n\nMontenegro\n405.0\n83.4\n\n\nMongolia\n411.4\n77.7\n\n\nMalaysia\n417.2\n77.9\n\n\nNetherlands\n486.8\n111.8\n\n\nNorway\n478.9\n106.1\n\n\nNew Zealand\n504.8\n107.9\n\n\nPanama\n385.1\n84.9\n\n\nPeru\n410.8\n85.4\n\n\nPhilippines\n353.8\n77.0\n\n\nPoland\n505.1\n94.2\n\n\nPortugal\n488.3\n89.7\n\n\nParaguay\n371.7\n74.5\n\n\nPalestinian Authority\n367.0\n70.9\n\n\nQatar\n428.8\n96.3\n\n\nBaku (Azerbaijan)\n381.6\n78.7\n\n\nUkrainian regions (18 of 27)\n454.5\n88.7\n\n\nRomania\n436.5\n96.2\n\n\nSaudi Arabia\n390.2\n72.2\n\n\nSingapore\n560.8\n99.6\n\n\nEl Salvador\n375.0\n73.4\n\n\nSerbia\n446.8\n88.3\n\n\nSlovak Republic\n467.3\n103.0\n\n\nSlovenia\n487.1\n93.9\n\n\nSweden\n494.2\n107.5\n\n\nChinese Taipei\n526.8\n102.3\n\n\nThailand\n429.2\n93.1\n\n\nTürkiye\n476.0\n89.1\n\n\nUruguay\n433.3\n92.4\n\n\nUnited States\n498.3\n108.9\n\n\nUzbekistan\n355.3\n63.3\n\n\nViet Nam\n473.3\n78.4\n\n\n\n\n\n## If you have an output from a linear model, there is an additional step to do before using gt\n# You need to use the broom package, which has the `tidy` function which gets the output of `lm`\n# Into a suitable format for turing into a table\n# install.packages(\"broom\")\n\nlibrary(broom)\n\n# Create example dataframe\n\nUK_PISA &lt;- PISA_2022 %&gt;%\n  select(PV1SCIE, PV1MATH, CNT) %&gt;%\n  filter(CNT == \"United Kingdom\")\n\n# Run the model\n\nuk_mod &lt;- lm(data = UK_PISA, PV1SCIE ~ PV1MATH)\n\n# tidy the model\n\nuk_mod_tidy &lt;- tidy(uk_mod)\n\n# pass to gt to produce nice output\n\ngt(uk_mod_tidy)\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n(Intercept)\n42.3335278\n2.304412214\n18.37064\n1.978594e-74\n\n\nPV1MATH\n0.9324181\n0.004685464\n199.00232\n0.000000e+00",
    "crumbs": [
      "Appendices",
      "Questions and Answers"
    ]
  },
  {
    "objectID": "chapters/A7-QandA.html#how-do-i-report-the-results-of-tests-in-apa-format",
    "href": "chapters/A7-QandA.html#how-do-i-report-the-results-of-tests-in-apa-format",
    "title": "Questions and Answers",
    "section": "",
    "text": "When you have run some tests, the outputs (for example the degrees of freedom, test statistic and p-value) should be formatted in your paper in line with the citation convention of the journal or assessment (for example, KCL assignments follow the American Psychological Association (APA) citation style). You can find a general guide to presenting your results in APA style here: APA numbers and statistics style guide.\nFor example, to report a chi-square result:\n\n# Create example dataframe\n\nUK_gender_differences &lt;- PISA_2022 %&gt;%\n  select(CNT, ST004D01T) %&gt;%\n  filter(CNT == \"United Kingdom\") %&gt;% \n  droplevels()\n\ncont_tab &lt;- xtabs(data = UK_gender_differences, ~ ST004D01T)\n\n# Run a chi sqaure goodness of fit test\n\nchisq.test(cont_tab, p = c(0.5, 0.5))\n\n\n    Chi-squared test for given probabilities\n\ndata:  cont_tab\nX-squared = 2.4425, df = 1, p-value = 0.1181\n\n\nA chi-square test of goodness-of-fit was conducted to compare the observed frequencies in the contingency table to the expected frequencies (equal numbers of boys and girls). The result was not statistically significant, χ²(1, N = 12973) = 2.44, p = .12, indicating no significant difference between the observed and expected frequencies.\nTo report a t-test of the mathematics scores of girls and boys in the UK:\n\n# Create example dataframe\n\nUK_PISA &lt;- PISA_2022 %&gt;%\n  select(PV1MATH, CNT, ST004D01T) %&gt;%\n  filter(CNT == \"United Kingdom\")\n\n# Run a t-test\n\nt.test(data = UK_PISA, PV1MATH ~ ST004D01T)\n\n\n    Welch Two Sample t-test\n\ndata:  PV1MATH by ST004D01T\nt = -8.2246, df = 12942, p-value &lt; 2.2e-16\nalternative hypothesis: true difference in means between group Female and group Male is not equal to 0\n95 percent confidence interval:\n -16.9470 -10.4238\nsample estimates:\nmean in group Female   mean in group Male \n            475.6061             489.2915 \n\n\nThe output of that test would be reported as follows:\nThe results of a Welch’s t-test indicated a statistically significant difference in mean mathematics scores between UK females (M = 475.61) and UK males (M = 489.29), t(12,942) = -8.22, p &lt; .001, 95% CI [-16.95, -10.42].\nAlternatively, consider the output of an anova to look at the difference in wealth scores between Finland, Norway, and Sweden:\n\n# Create example dataframe\n\nwealth_scores &lt;- PISA_2022 %&gt;%\n  select(HOMEPOS, CNT) %&gt;%\n  filter(CNT == \"Finland\" | CNT == \"Norway\" | CNT == \"Sweden\")\n\n# Run an anova and summarise\n\naov_out &lt;- aov(data = wealth_scores, HOMEPOS ~ CNT)\nsummary(aov_out)\n\n               Df Sum Sq Mean Sq F value Pr(&gt;F)    \nCNT             2    575  287.61   356.7 &lt;2e-16 ***\nResiduals   22335  18008    0.81                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n584 observations deleted due to missingness\n\nTukeyHSD(aov_out)\n\n  Tukey multiple comparisons of means\n    95% family-wise confidence level\n\nFit: aov(formula = HOMEPOS ~ CNT, data = wealth_scores)\n\n$CNT\n                     diff        lwr        upr p adj\nNorway-Finland  0.3846629  0.3508747  0.4184511     0\nSweden-Finland  0.1645141  0.1301168  0.1989114     0\nSweden-Norway  -0.2201488 -0.2581530 -0.1821445     0\n\n\nA one-way ANOVA was conducted to compare levels of home possessions (HOMEPOS) across three countries (CNT: Finland, Norway, and Sweden). The analysis revealed a statistically significant effect of country on home possessions, F(2, 22,335) = 356.7, p &lt; .001, η² = .031.\nPost hoc Tukey’s HSD tests indicated the following pairwise differences:\nNorway had significantly higher HOMEPOS scores than Finland (M difference = 0.38, 95% CI [0.35, 0.42], p &lt; .001). Sweden had significantly higher HOMEPOS scores than Finland (M difference = 0.16, 95% CI [0.13, 0.20], p &lt; .001). Sweden had significantly lower HOMEPOS scores than Norway (M difference = -0.22, 95% CI [-0.26, -0.18], p &lt; .001). A total of 584 observations were excluded due to missing data.\nAlternatively, you can use the report function in the easystats package to give a summary of an output.\n\nlibrary(easystats)\n\n# Get a summary of an anova\n\nreport(aov_out)\n\nThe ANOVA (formula: HOMEPOS ~ CNT) suggests that:\n\n  - The main effect of CNT is statistically significant and small (F(2, 22335) =\n356.72, p &lt; .001; Eta2 = 0.03, 95% CI [0.03, 1.00])\n\nEffect sizes were labelled following Field's (2013) recommendations.\n\n# And of a linear model\n\nmod1 &lt;- lm(data = wealth_scores, HOMEPOS ~ CNT)\n\nreport(mod1)\n\nWe fitted a linear model (estimated using OLS) to predict HOMEPOS with CNT\n(formula: HOMEPOS ~ CNT). The model explains a statistically significant and\nweak proportion of variance (R2 = 0.03, F(2, 22335) = 356.72, p &lt; .001, adj. R2\n= 0.03). The model's intercept, corresponding to CNT = Albania, is at 0.16 (95%\nCI [0.14, 0.18], t(22335) = 18.13, p &lt; .001). Within this model:\n\n  - The effect of CNT [Norway] is statistically significant and positive (beta =\n0.38, 95% CI [0.36, 0.41], t(22335) = 26.68, p &lt; .001; Std. beta = 0.42, 95% CI\n[0.39, 0.45])\n  - The effect of CNT [Sweden] is statistically significant and positive (beta =\n0.16, 95% CI [0.14, 0.19], t(22335) = 11.21, p &lt; .001; Std. beta = 0.18, 95% CI\n[0.15, 0.21])\n\nStandardized parameters were obtained by fitting the model on a standardized\nversion of the dataset. 95% Confidence Intervals (CIs) and p-values were\ncomputed using a Wald t-distribution approximation.\n\n\nTo produce tables in APA format, you can use the apa.aov.table (for anovas) or apa.reg.table (for linear model outputs) functions from the apaTables package. You will need to install the package first using install.packages(\"apaTables\").\n\nlibrary(apaTables)\n\n# Get a summary table from an anova\n\napa.aov.table(aov_out)\n\n\n\nANOVA results using HOMEPOS as the dependent variable\n \n\n   Predictor       SS    df     MS      F    p partial_eta2 CI_90_partial_eta2\n (Intercept)   264.91     1 264.91 328.56 .000                                \n         CNT   575.22     2 287.61 356.72 .000          .03         [.03, .03]\n       Error 18007.84 22335   0.81                                            \n\nNote: Values in square brackets indicate the bounds of the 90% confidence interval for partial eta-squared \n\n# And of a linear model\n\napa.reg.table(mod1)\n\n\n\nRegression results using HOMEPOS as the criterion\n \n\n   Predictor      b     b_95%_CI sr2 sr2_95%_CI             Fit\n (Intercept) 0.16** [0.14, 0.18]                               \n   CNTNorway 0.38** [0.36, 0.41] .03 [.03, .04]                \n   CNTSweden 0.16** [0.14, 0.19] .01 [.00, .01]                \n                                                    R2 = .031**\n                                                95% CI[.03,.04]\n                                                               \n\nNote. A significant b-weight indicates the semi-partial correlation is also significant.\nb represents unstandardized regression weights. \nsr2 represents the semi-partial correlation squared.\nSquare brackets are used to enclose the lower and upper limits of a confidence interval.\n* indicates p &lt; .05. ** indicates p &lt; .01.\n \n\n\nYou can get more aesthetically pleasing versions of both tables using the gt function in the gt package. Before passing the outputs of avo of lm to gt, you will need to use the tidy fucntion from the broom package to tidy the output.\n\nlibrary(gt)\nlibrary(broom)\n\n# Tidy the outputs\n\ntidied_aov &lt;- tidy(aov_out)\ntidied_mod1 &lt;- tidy(mod1)\n\n\n# Produced a nicely formatted table from an anova\n\ngt(tidied_aov)\n\n\n\n\n\nterm\ndf\nsumsq\nmeansq\nstatistic\np.value\n\n\n\nCNT\n2\n575.2171\n287.6085570\n356.719\n3.175047e-153\n\n\nResiduals\n22335\n18007.8370\n0.8062609\nNA\nNA\n\n\n\n\n\n# And of a linear model\n\ngt(tidied_mod1)\n\n\n\n\n\nterm\nestimate\nstd.error\nstatistic\np.value\n\n\n\n(Intercept)\n0.1622658\n0.008951941\n18.12632\n6.584384e-73\n\n\nCNTNorway\n0.3846629\n0.014415658\n26.68369\n1.915252e-154\n\n\nCNTSweden\n0.1645141\n0.014675508\n11.21011\n4.349919e-29",
    "crumbs": [
      "Appendices",
      "Questions and Answers"
    ]
  },
  {
    "objectID": "chapters/A7-QandA.html#how-do-i-add-the-results-from-statistical-tests-to-ggplot",
    "href": "chapters/A7-QandA.html#how-do-i-add-the-results-from-statistical-tests-to-ggplot",
    "title": "Questions and Answers",
    "section": "",
    "text": "There are a number of helpful packages that can add data to charts. First ggpubr lets you add data about the regression line to your plot using the stat_regline_equation() function. You will need to tweak the coordinates (label.x and label.y) to appear appropiately on your chart.\n\n# Load the ggpbur library (you will need to run install.packages(\"ggpubr\") the first time you use it)\nlibrary(ggpubr)\n\n# Create example dataframe\n\nUK_wealth_reading &lt;- PISA_2022 %&gt;%\n  select(CNT, PV1READ, HOMEPOS) %&gt;%\n  filter(CNT == \"United Kingdom\") \n\n# Plot a scatter plot with the regression equation\n\nggplot(UK_wealth_reading, aes(x = HOMEPOS, y = PV1READ)) +\n  geom_point(colour = \"lightgreen\", size = 0.1) +\n  geom_smooth(method = \"lm\") +\n  stat_regline_equation(label.x = -5, label.y = 600)  # Add regression equation\n\n\n\n\n\n\n\nYou can also use stat_regline_equation to add additional information like the p-value of the model and the R2 value:\n\n# Load the ggpbur library (you will need to run install.packages(\"ggpubr\") the first time you use it)\nlibrary(ggpubr)\n\n# Create example dataframe\n\nUK_wealth_reading &lt;- PISA_2022 %&gt;%\n  select(CNT, PV1READ, HOMEPOS) %&gt;%\n  filter(CNT == \"United Kingdom\") \n\n# Plot a scatter plot with the regression equation\n\nggplot(UK_wealth_reading, aes(x = HOMEPOS, y = PV1READ)) +\n  geom_point(colour = \"lightgreen\", size = 0.1) +\n  geom_smooth(method = \"lm\", formula = y ~ x) + # Ensure formula is specified here too\n  stat_regline_equation(\n    aes(label = paste(..eq.label.., ..adj.rr.label.., sep = \"~~~~\")), # Indicate you want the equation and R2 value and the seperator text\n    label.x = -10, label.y = 600,\n    formula = y ~ x)\n\n\n\n\n\n\n\nAnother powerful package for adding data to graphs is ggstatsplot. For example, it can anotate a plot with anova data. For example, if you want compare the science scores of the UK, Japan and the US:\n\n# Load the ggstatplot library (you will need to run install.packages(\"ggstatsplot\") the first time you use it)\nlibrary(ggstatsplot)\n\n# Create example dataframe\n\ncountry_sci_data &lt;- PISA_2022 %&gt;%\n  select(CNT, PV1SCIE) %&gt;%\n  filter(CNT == \"United Kingdom\" | CNT == \"Japan\" | CNT == \"United States\")\n\n# Use ggstatplot to create an annotated plot with an anova result\n\nggbetweenstats(\n  data  = country_sci_data,\n  x     = CNT,\n  y     = PV1SCIE,\n  title = \"Science scores in the UK, US and Japan\",\n  type  = \"parametric\" # Forces the test to be ANOVA\n)",
    "crumbs": [
      "Appendices",
      "Questions and Answers"
    ]
  },
  {
    "objectID": "chapters/A9-Corpus.html",
    "href": "chapters/A9-Corpus.html",
    "title": "Corpus Analysis",
    "section": "",
    "text": "Corpus analysis is the empirical study of lingusitic patterns associated with language use in different contexts, often now carried out using computer-based approaches.\n\nOne of the most widely used packages for corpus analysis in R is the quanteda package. quanteda is a comprehensive package that allows researchers to manage corpora and carry out a wide range of analyses on them. To install quanteda, use the following code, if this is the first time you are using the package you will need to include the install.packages(\"quanteda\") function. We will also load the tidyverse package, which is a collection of packages that are commonly used in data analysis in R.\n\nTypically, the first step in a corpus analysis project is to create a corpus object. A corpus object is a collection of texts that can be analysed together. In quanteda, a corpus object can be created from a variety of sources, including text files, data frames, and character vectors. There are a number of different approaches to reading in textual data.\n\n\n\n\n\n\nTip\n\n\n\nThe data in this teaching page are drawn from talkbank.org, a repository of spoken language data. The data are from the UK component of the CHILDES database, which is a collection of transcripts of child language development.\nAn acknowledgement of the data set is shown below:\nCHILDES: MacWhinney, B. (2000). The CHILDES Project: Tools for analyzing talk. Third Edition. Mahwah, NJ: Lawrence Erlbaum Associates. Note: Please also acknowledge this grant support for CHILDES – NICHD HD082736.\n\n\nFirst data may be read from a text file. You can download three example files here: CHILDES project Gathburn 11. CHILDES project Gathburn 12. CHILDES project Gathburn 13.\nThe files are records of conversations between some children and a teacher. The speakers in the transcript are given the following codes:\n\n\n\n\n\n\n\n\n\n\n\n\nTranscript\nSpeaker 1\nSpeaker 2\nSpeaker 3\nSpeaker 4\nSpeaker 5\nSpeaker 6\nSpeaker 7\n\n\n\nTranscript 11\nSTE Teacher\nLOU Child\nJER Child\nCAT Child\nCHR Child\nALL Child\nUNK Child\n\n\nTranscript 12\nSTE Teacher\nNAN Child\nGEO Child\nRIT Child\nBAR Child\n\n\n\n\nTranscript 13\nSTE Teacher\nGER Child\nSTE Teacher\nKAT Child\nVID Child\nJAS Child\nALL Child\n\n\n\nYou can load files singly or as a group. The code below shows how to load a single file.\n\n# Please replace the file path with the path to the file on your computer\n\ntranscript_11 &lt;- readlines(\"&lt;file path&gt;\")\n\nit is common to have a number of files that you want to load in together. The package readtext can be used to read in multiple files at once. The code below shows how to load in all the files in a folder. Using the readtext function, you can read in all the files in a folder by giving the path of the folder, rather than a fie.\n\n# You will need to copy the address of the folder on your computer into the quotation marks below\n# For example on my laptop the path name is: /Users/k1765032/Library/CloudStorage/OneDrive-King'sCollegeLondon/QERKCL_PISA/data/corpus/Talk Bank/CHILDES/*.txt\n\nlibrary(readtext)\n\nCHILDES_text &lt;- readtext(\"data/folder/*.txt\")\n\n\n\n\n\n\n\nTip\n\n\n\nTo find the path to a file:\nOn a PC: hold Shift and right-click the file or folder, then select “Copy as Path” from the context menu.\nOn a Mac: hold down the Option key and right-click the file or folder, then select “Copy as Pathname” from the context menu.\n\n\nOnce the text files have been read in, they need to be converted to a format quanteda can work with. This is done using the corpus function. The code below shows how to convert the CHILDES_text object to a corpus object. You can think of a corpus like a library of the documents you are using in your project.\n\n# Converting a text file to a corpus object\n\nCHILDES_corpus &lt;- corpus(CHILDES_text)\n\n\nOnce you have created a corpus object, you can carry out a range of analyses on it. The quanteda package provides a wide range of functions for analysing corpora. A first step is geting some summary descriptive statistics related to your corpus. The code below shows how to get a summary of the corpus object.\n\n# A simple descriptive summary of the corpus\n\nsummary(CHILDES_corpus)\n\nCorpus consisting of 3 documents, showing 3 documents:\n\n                    Text Types Tokens Sentences\n CHILDES_Gathburn_11.txt   595   9252      1012\n CHILDES_Gathburn_12.txt   605   6157       712\n CHILDES_Gathburn_13.txt   688   8629       983\n\n\nIn quanteda, types and tokens refer to different ways of counting the unique and total words in a corpus:\nTokens: This refers to the total number of words (or word-like units) in the corpus, including repetitions. Each individual occurrence of a word, regardless of whether it appears elsewhere in the corpus, counts as a token. Types: This refers to the number of unique words in the corpus, disregarding any repetitions. A type is counted only once, no matter how many times it appears in the text.\nYou may want to add some metadata to your corpus object. This can be done using the docvars function. The code below shows how to add metadata to the CHILDES_corpus object. For example, each file has different number of speakers, and you may want to add this information to the corpus object.\n\n\n\n\n\n\n\n\n\n\n\n\nTranscript\nSpeaker 1\nSpeaker 2\nSpeaker 3\nSpeaker 4\nSpeaker 5\nSpeaker 6\nSpeaker 7\n\n\n\nTranscript 11\nSTE Teacher\nLOU Child\nJER Child\nCAT Child\nCHR Child\nALL Child\nUNK Child\n\n\nTranscript 12\nSTE Teacher\nNAN Child\nGEO Child\nRIT Child\nBAR Child\n\n\n\n\nTranscript 13\nSTE Teacher\nGER Child\nSTE Teacher\nKAT Child\nVID Child\nJAS Child\nALL Child\n\n\n\nYou can use the docvars function to add metadata to the corpus object. The code below shows how to add the number of speakers to the CHILDES_corpus object.\n\n# Adding metadata to the corpus\n\n# Adding to row 1 (i.e. transcript 11) CHILDES_corpus[1]\n\ndocvars(CHILDES_corpus, \"no_of_speakers\") &lt;- c(7, 5, 7)\n\nsummary(CHILDES_corpus)\n\nCorpus consisting of 3 documents, showing 3 documents:\n\n                    Text Types Tokens Sentences no_of_speakers\n CHILDES_Gathburn_11.txt   595   9252      1012              7\n CHILDES_Gathburn_12.txt   605   6157       712              5\n CHILDES_Gathburn_13.txt   688   8629       983              7\n\n\nTo view your corpus you can as.character function. This will show you the text in the corpus object. Be careful, this can produce a long output! You can print out elements of the corpus object using the as.character(CHILDES_corpus[3]) gives the third text: CHILDES_Gathburn_13.txt.\n\n# Printing\n\nas.character(CHILDES_corpus[3])\n\nIf you want to filter the corpus, you can use the corpus_subset function. This function allows you to filter the corpus object based on the metadata you have added. The code below shows how to filter the CHILDES_corpus object to only include the texts with 7 speakers.\n\n# Creating a new corpus which contain transcripts with 7 speakers\n\nCHILDES_corpus_7 &lt;- corpus_subset(CHILDES_corpus, no_of_speakers == 7)\nsummary(CHILDES_corpus_7)\n\nCorpus consisting of 2 documents, showing 2 documents:\n\n                    Text Types Tokens Sentences no_of_speakers\n CHILDES_Gathburn_11.txt   595   9252      1012              7\n CHILDES_Gathburn_13.txt   688   8629       983              7\n\n\nTo start investigating the text in the corpus, you can use the kwic function. The kwic, key words in context, function allows you to search for a word or phrase in the corpus and see the context in which it appears. The code below shows how to use the kwic function to search for the word “teacher” in the CHILDES_corpus object. The first step in the process is to convert the corpus into a tokens object (i.e. to break it into individual words). This is done using the tokens function.\n\n# Doing a key word in context search\n# Tokenising the corpus\n\nCHILDES_tokens &lt;- tokens(CHILDES_corpus)\n\nThen the keywords in context search can be performed. The code below shows how to use the kwic function to search for the word “teacher” in the CHILDES_tokens object. The pattern argument is used to specify the word or phrase you want to search for, for example here the word “want”. You can use the `window argument to set how many tokens eithe side of the keyword you want to see. Here we have set the window to 10.\n\n# Doing a key word in context search\n\n\nkwic(CHILDES_tokens, pattern = \"want\", window = 10)\n\nKeyword-in-context with 28 matches.                                                                              \n [CHILDES_Gathburn_11.txt, 4986]                     put [/ ] this goes [/ ] I\n [CHILDES_Gathburn_11.txt, 5351]                 couple more. STE: mhm. CAT: I\n [CHILDES_Gathburn_11.txt, 5969]                   STE: here you are. JER: &lt; I\n [CHILDES_Gathburn_11.txt, 6005]                         : xxx [ &gt; ]. JER: &lt; I\n [CHILDES_Gathburn_11.txt, 6031]             ones, haven't you, Jeremy. JER: I\n [CHILDES_Gathburn_11.txt, 6047]                       : mhm. STE: xxx. JER: I\n                                                    \n | want | [/ ] this &lt; goes like &gt; [ &gt;               \n | want | &lt; to go back to the nursery &gt; [*          \n | want | more &gt; [ &gt; ] white ones. LOU:             \n | want | more white ones &gt; [ &lt; ]. STE:             \n | want | more white ones. STE: mhm. STE:           \n | want | more white ones. STE: you want more white \n [ reached 'max' / getOption(\"max.print\") -- omitted 22 rows ]\n\n\nYou can carry out a more flexible range of searches using regular expressions (regex). Regex is a sequence of characters that specifies a match pattern in text.\n\n\n\n\n\n\nTip\n\n\n\nFor more information on regular expressions, see the R documentation.\nThe following symbols can be useful in\n\n\n\n\n\n\nPattern\nDescription\n\n\n\n.\nAny single character except a newline\n\n\n^\nBeginning of String (or Line)\n\n\n$\nEnd of String (or Line)\n\n\n[]\nA set of characters, e.g., [a-z] for lowercase letters\n\n\n[^]\nNegation inside square brackets, e.g., [^a-z] for non-lowercase letters\n\n\n()\nGrouping (capturing group), used for subpatterns\n\n\n\n\n\n\n*\n0 or more of the preceding element\n\n\n+\n1 or more of the preceding element\n\n\n?\n0 or 1 of the preceding element (optional)\n\n\n{n}\nExactly n occurrences of the preceding element\n\n\n{n,}\nn or more occurrences of the preceding element\n\n\n{n,m}\nBetween n and m occurrences of the preceding element\n\n\nord boundary (matches between word and non-word characters)\n\n\n\n\nNot a word boundary\n\n\n\nBeginning of the string (similar to ^ but anchors the start of the whole string)\n\n\n\nEnd of the string (similar to $ but anchors the end of the whole string)\n\n\n\\1, \\2, …\nBackreference to capturing groups, e.g., \\1 refers to the first captured group\n\n\n(?=…)\nPositive lookahead (assertion, matches a position only if the pattern inside matches)\n\n\n(?!…)\nNegative lookahead (assertion, matches a position only if the pattern inside does not match)\n\n\n(?&lt;=…)\nPositive lookbehind (matches if preceded by a pattern)\n\n\n(?&lt;!…)\nNegative lookbehind (matches if not preceded by a pattern)\n\n\n[:alpha:]\nAny letter\n\n\n[:lower:]\nAny lowercase letter\n\n\n[:upper:]\nAny uppercase letter\n\n\n[:digit:]\nAny digit (equivalent to \n\n\n[:alnum:]\nAny letter or number\n\n\n[:xdigit:]\nAny hexadecimal digit\n\n\n[:punct:]\nAny punctuation character\n\n\n[:graph:]\nAny letter, number, or punctuation character\n\n\n[:space:]\nA space, a tab, a new line, etc. (equivalent to )\n\n\n\nFor example: - the regex ^mini will match any word that starts with “mini”. - the regex able$ will match any word that ends with “able”. - the regex colou?r matches both “color” and “colour”. - the regex [J|j]ane matches both “Jane” and “jane”.\n\n\n\n\n\n\n\n\nTip\n\n\n\nThere is a great blog post Baby got backreferences which gives a great introduction to regex (using song lyrics as examples!)\n\n\nTo perform a regex search, you can use the kwic function with the pattern argument set to the regex pattern you want to search for. The code below shows how to use the kwic function to search for words that start with “teach” in the CHILDES_tokens object. You also need to set the valuetype argument to “regex” to indicate that the pattern is a regex pattern. For example, to search for all cases of words that start with “dad” or “Dad” you can use the regex pattern ^[D/d]ad.\n\n# Doing a key word in context search wtih regex\n\nkwic(CHILDES_tokens, pattern = \"^[D/d]ad\", window = 10, valuetype = \"regex\")\n\nKeyword-in-context with 11 matches.                                                                         \n  [CHILDES_Gathburn_12.txt, 957]        wheel (. ) no brakes. STE: your |\n  [CHILDES_Gathburn_12.txt, 976]                it? GEO: hm:? STE: your |\n [CHILDES_Gathburn_12.txt, 1062]          . GEO: one. STE: I heard your |\n [CHILDES_Gathburn_12.txt, 2003]             a [/ ] making a. STE: your |\n [CHILDES_Gathburn_12.txt, 3179] door? NAN: he lives with his mommy and |\n [CHILDES_Gathburn_13.txt, 1710]          GER: yes, except mine [/ ] my |\n                                                            \n Daddy's | car won't steer with no brakes, does it?         \n Daddy's | car won't steer with no brakes [* ].             \n Daddy's | xxx jobs with vans. NAN: 0 [%                    \n   dad   | have a car, Rita? RIT: 0 [                       \n  daddy  | . STE: yes, but do they live very                \n  daddy  | . GER: he hates [! ] dark.                       \n [ reached 'max' / getOption(\"max.print\") -- omitted 5 rows ]\n\n\nNote that you can output the result of kwic search to a dataframe and then use ggplot to represent the data.\n\n# Doing a key word in context search wtih regex and plotting\n\ndad_search &lt;- kwic(CHILDES_tokens, pattern = \"^[D/d]ad\", window = 10, valuetype = \"regex\")\n\nggplot(dad_search, aes(x = keyword, fill = keyword)) +\n  geom_bar() +\n  theme_minimal() +\n  labs(title = \"Occurrences of 'dad' in CHILDES corpus\")\n\n\n\n\n\n\n\nIf you want to look up longer phrases, you can give a pattern within phrase(). For example pattern = phrase(\"I want more\")\n\n# searching for a phrase\n\nkwic(CHILDES_tokens, pattern = phrase(\"I want more\"), window = 10)\n\nKeyword-in-context with 12 matches.                                                                             \n [CHILDES_Gathburn_11.txt, 5968:5970]           . STE: here you are. JER: &lt; |\n [CHILDES_Gathburn_11.txt, 6004:6006]                STE: xxx [ &gt; ]. JER: &lt; |\n [CHILDES_Gathburn_11.txt, 6030:6032] white ones, haven't you, Jeremy. JER: |\n [CHILDES_Gathburn_11.txt, 6046:6048]              STE: mhm. STE: xxx. JER: |\n [CHILDES_Gathburn_11.txt, 6301:6303]              : 0 [ = aids CAT ]. JER: |\n [CHILDES_Gathburn_11.txt, 6328:6330]              &lt; ]. STE: whoops. JER: &lt; |\n                                                        \n I want more | &gt; [ &gt; ] white ones. LOU: there           \n I want more | white ones &gt; [ &lt; ]. STE: oh              \n I want more | white ones. STE: mhm. STE: xxx           \n I want more | white ones. STE: you want more white ones\n I want more | wee bits (. ) to put like that.          \n I want more | bits &gt; [ &gt; ]. STE: xxx [                 \n [ reached 'max' / getOption(\"max.print\") -- omitted 6 rows ]\n\n\n\n\n\n\n\n\nTip\n\n\n\nAn alternative way to represent where words occur in a text is to use the str_view function from the stringr package, which highlights matches:\n\nlibrary(stringr)\n\n# Read in lyrics of Bohemain Rhapsody from Github\n\nurl &lt;- \"https://gist.githubusercontent.com/matematikaadit/3a513cc5fe6ebb9565ee1584e2b4f00d/raw/\"\nfile_content &lt;- readLines(url)\n\nstr_view(file_content, \"poor\")\n\n[10] │ I'm just a &lt;poor&gt; boy, I need no sympathy,\n[45] │ I'm just a &lt;poor&gt; boy, nobody loves me.\n[46] │ He's just a &lt;poor&gt; boy from a &lt;poor&gt; family,\n\n\n\n\n\nYou can also examine the frequency of words in the corpus. The document-feature matrix (DFM) allows you to see the frequency of words in the corpus. The code below shows how to create a DFM object from the CHILDES_tokens object. The dfm function is used to create the DFM object. Then the featfreq function is used to get the word frequencies. Note you can concert the output to a dataframe using as.data.frame() which will allow further processing and use with other packages such as ggplot to make graphs.\n\n# Create a document-feature matrix (DFM)\n\ndfm &lt;- dfm(CHILDES_tokens)\n\n\n# Get word frequencies\nword_frequencies &lt;- featfreq(dfm)\n\nprint(word_frequencies)\n\n        @utf8          @pid             :         11312             / \n            3             3          2772             3           333 \n c-00019181-1        @begin    @languages           eng @participants \n            1             3             3            21             3 \n          ste       teacher             ,           lou         child \n         1577             7           605           103            30 \n          jer           cat           chr           all           unk \n          137            74           110            78             6 \n     @options         multi           @id             |      gathburn \n            3             3            18           180            18 \n        @date   16-may-1984         @tape      location           1.1 \n            1             1             1             1             1 \n @transcriber         ginny    gathercole           and       rebecca \n            1             2             1           131             1 \n        burns     @location     edinburgh      scotland        @types \n            1             1             2             1             3 \n [ reached getOption(\"max.print\") -- omitted 1065 entries ]\n\n# Convert to dataframe\n\nword_frequencies_df &lt;- as.data.frame(word_frequencies)\n\n\nIn some contexts, before analysis, you may want to clean the text. This can involve removing punctuation, numbers, and other non-word characters. The tokens function has a remove_punct argument that can be set to TRUE to remove punctuation. The code below shows how to create a new tokens object with punctuation removed. You can also remove numbers and symbols using the remove_numbers and remove_symbols arguments.\n\n# removing punctuation\n\nCHILDES_tokens_clean &lt;- tokens(CHILDES_corpus, remove_punct = TRUE, remove_numbers = TRUE, remove_symbols = TRUE)\n\nWhen examining word frequencies, you may want to remove stopwords. Stopwords are common words that are often removed from text before analysis. For example, stop words include: “i”, “me” , “my”, “myself”, “we”, “our”, “ours”, “ourselves”, “you”, and “your”. If left in, these common, high frequency words can swap out other terms in the data.\nquanteda has a built in dictionary of stopwords. You can see those included by running head(stopwords(\"en\"), 20) the 20 limits the ouput to the first 20 words. Here en specifies you are interested in stopwords in English.\n\n# quanteda's stop words\n\nhead(stopwords(\"en\"), 20)\n\n [1] \"i\"          \"me\"         \"my\"         \"myself\"     \"we\"        \n [6] \"our\"        \"ours\"       \"ourselves\"  \"you\"        \"your\"      \n[11] \"yours\"      \"yourself\"   \"yourselves\" \"he\"         \"him\"       \n[16] \"his\"        \"himself\"    \"she\"        \"her\"        \"hers\"      \n\n\nTo remove stopwords, you can use the remove argument in the tokens function: tokens_remove(tokens, stopwords(\"en\")). The code below shows how to create a new tokens object with stopwords and punctuation removed. Let us compare outputs with and without the removal of stopwords and punctuation.\n\n# removing stopwords and punctuation\n\nCHILDES_tokens_no_stop &lt;- CHILDES_tokens %&gt;%\n  tokens(remove_punct = TRUE) %&gt;%\n  tokens_remove(stopwords(\"en\"))\n\n# Get word frequencies\n\n# Create a document-feature matrix (DFM)\n\ndfm &lt;- dfm(CHILDES_tokens_no_stop)\n\n\n# Get word frequencies\nword_frequencies_no_stop &lt;- featfreq(dfm)\n\nprint(word_frequencies_no_stop)\n\n        @utf8          @pid         11312  c-00019181-1        @begin \n            3             3             3             1             3 \n   @languages           eng @participants           ste       teacher \n            3            21             3          1577             7 \n          lou         child           jer           cat           chr \n          103            30           137            74           110 \n          unk      @options         multi           @id             | \n            6             3             3            18           180 \n     gathburn         @date   16-may-1984         @tape      location \n           18             1             1             1             1 \n          1.1  @transcriber         ginny    gathercole       rebecca \n            1             1             2             1             1 \n        burns     @location     edinburgh      scotland        @types \n            1             1             2             1             3 \n        cross         group            td           sit           red \n            3             3             3             9            16 \n [ reached getOption(\"max.print\") -- omitted 906 entries ]\n\n# Convert to dataframe\n\nword_frequencies_no_stop_df &lt;- as.data.frame(word_frequencies_no_stop)\n\nWe can compare the results of the two word frequency lists to see the impact of removing stopwords.\n\n# graphs of frequencies before and after removing stopwords\n\nword_frequencies_df &lt;- word_frequencies_df %&gt;%\n  mutate(feat = rownames(word_frequencies_df)) %&gt;%\n  arrange(desc(word_frequencies)) %&gt;%\n  slice_head(n = 20)\n\n\nggplot(word_frequencies_df, aes(x = reorder(feat, - word_frequencies), y = word_frequencies, fill = feat)) +\n  geom_bar(stat = \"identity\") +\n  theme_minimal() +\n  labs(title = \"Top 20 word frequencies before removing stopwords\") +\n  labs(x = \"Word\", y = \"Frequency\")+\n  theme(legend.position = \"none\")\n\n\n\n\n\n\nword_frequencies_no_stop_df &lt;- word_frequencies_no_stop_df %&gt;%\n  mutate(feat = rownames(word_frequencies_no_stop_df)) %&gt;%\n  arrange(desc(word_frequencies_no_stop)) %&gt;%\n  slice_head(n = 20)\n\n\nggplot(word_frequencies_no_stop_df, aes(x = reorder(feat, - word_frequencies_no_stop), y = word_frequencies_no_stop, fill = feat)) +\n  geom_bar(stat = \"identity\") +\n  theme_minimal() +\n  labs(title = \"Top 20 word frequencies after removing stopwords and punctuation\") +\n  labs(x = \"Word\", y = \"Frequency\") +\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\nAs you can see, the build in functions for removing punctuation and stop words are not always ideal. You may want to create your own list of words to remove or use a different method to remove them. You can also use the tokens function with the remove argument to remove specific words. The code below shows how to remove the word “teacher” from the CHILDES_tokens object.\n\n# custom removal of words\n\n# Create a custom list of stop words\ncustom_stopwords &lt;- c(\"ste\", \"&lt;\", \"&gt;\", \"xxx\", \"ger\", \"|\", \"kat\", \"jer\", \"0\", \"geo\", \"=\", \"chr\", \"+\")\n\nCHILDES_tokens_no_stop &lt;- CHILDES_tokens %&gt;%\n  tokens(remove_punct = TRUE) %&gt;%\n  tokens_remove(stopwords(\"en\")) %&gt;%\n  tokens_remove(custom_stopwords)\n\n# Get word frequencies\n\n# Create a document-feature matrix (DFM)\n\ndfm &lt;- dfm(CHILDES_tokens_no_stop)\n\n\n# Get word frequencies\nword_frequencies_no_stop &lt;- featfreq(dfm)\n\nprint(word_frequencies_no_stop)\n\n        @utf8          @pid         11312  c-00019181-1        @begin \n            3             3             3             1             3 \n   @languages           eng @participants       teacher           lou \n            3            21             3             7           103 \n        child           cat           unk      @options         multi \n           30            74             6             3             3 \n          @id      gathburn         @date   16-may-1984         @tape \n           18            18             1             1             1 \n     location           1.1  @transcriber         ginny    gathercole \n            1             1             1             2             1 \n      rebecca         burns     @location     edinburgh      scotland \n            1             1             1             2             1 \n       @types         cross         group            td           sit \n            3             3             3             3             9 \n          red          seat           two          come        around \n           16             5            22            17             5 \n [ reached getOption(\"max.print\") -- omitted 893 entries ]\n\n# Convert to dataframe\n\nword_frequencies_no_stop_df &lt;- as.data.frame(word_frequencies_no_stop)\n\n\nCHILDES_tokens_no_stop&lt;- CHILDES_tokens_no_stop %&gt;%\n  tokens_remove(custom_stopwords)\n\nword_frequencies_no_stop_df &lt;- word_frequencies_no_stop_df %&gt;%\n  mutate(feat = rownames(word_frequencies_no_stop_df)) %&gt;%\n  arrange(desc(word_frequencies_no_stop)) %&gt;%\n  slice_head(n = 20)\n\n\nggplot(word_frequencies_no_stop_df, aes(x = reorder(feat, - word_frequencies_no_stop), y = word_frequencies_no_stop, fill = feat)) +\n  geom_bar(stat = \"identity\") +\n  theme_minimal() +\n  labs(title = \"Top 20 word frequencies after removing stopwords and punctuation\") +\n  labs(x = \"Word\", y = \"Frequency\") +\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\nWe have seen how to search for a single word or phrase in the corpus. You may want to search for multiple words or phrases at once. This can be done using a dictionary. A dictionary is a list of words or phrases that you want to search for in the corpus. The code below shows how to create a dictionary object using the dictionary function. The dictionary function takes a list of words or phrases as input. You can use the dictionary when making a dfm to create word counts\n\n# Setting up a dictionary to search for\n\ndict &lt;- dictionary(list(parent = c(\"dad\", \"daddy\", \"Daddy\", \"Dad\", \"mum\", \"mummy\", \"Mum\", \"Mummy\"),\n                        colour = c(\"red\", \"orange\" , \"yellow\", \"green\", \"blue\", \"violet\")))\n\n# searching for a phrase\n\n# Create a document-feature matrix (DFM) using the dictionary to search for words\n\ndfm &lt;- CHILDES_tokens_no_stop %&gt;%\n       tokens_lookup(dictionary = dict) %&gt;%\n      dfm()\n\n# display the dfm\ndfm\n\nDocument-feature matrix of: 3 documents, 2 features (16.67% sparse) and 1 docvar.\n                         features\ndocs                      parent colour\n  CHILDES_Gathburn_11.txt      0     29\n  CHILDES_Gathburn_12.txt      2      4\n  CHILDES_Gathburn_13.txt      4     20\n\n\n\nA common way to visualise word frequencies is to use a word cloud. A word cloud is a visual representation of text data, where the size of each word indicates its frequency in the text. The quanteda.textplots package can be used to create word clouds in R.\nThe code below shows how to create a word cloud from the CHILDES_tokens_no_stop object. The text_plotwordcloud function is used to create the word cloud from a ‘dfm’ object. The dim.trim function is used to set the minimum frequency of words to include in the word cloud. If low frequencies words are left in, the word cloud is hard to read. The min_termfreq argument is used to set the minimum frequency of words to include in the word cloud. The textplot_wordcloud function is used to create the word cloud.\n\nlibrary(quanteda.textplots)\n\n# Create a word cloud\n# Start from the cleaned dfm object\n\n# Create a custom list of stop words\ncustom_stopwords &lt;- c(\"ste\", \"&lt;\", \"&gt;\", \"xxx\", \"ger\", \"|\", \"kat\", \"jer\", \"0\", \"geo\", \"=\", \"chr\", \"+\")\n\nCHILDES_tokens_no_stop &lt;- CHILDES_tokens %&gt;%\n  tokens(remove_punct = TRUE) %&gt;%\n  tokens_remove(stopwords(\"en\")) %&gt;%\n  tokens_remove(custom_stopwords)\n\n# Get word frequencies\n\n# Create a document-feature matrix (DFM)\n# Trim to remove low frequency words\n\ndfm &lt;- dfm(CHILDES_tokens_no_stop) %&gt;%\n    dfm_trim(min_termfreq = 10, verbose = FALSE)\n\n# Create a word cloud\n\ntextplot_wordcloud(dfm) \n\n\n\n\n\n\n\nThe argument colorcan be use to set a colour gradient by frequency.\n\n# Create a word cloud comparing texts\n \ntextplot_wordcloud(dfm, color =c(\"lightblue\", \"skyblue\", \"blue\", \"darkblue\")) \n\n\n\n\n\n\n\nThe textplot_wordcloud() function has an argument to produce comparative plots by text, by setting the comparison argument to true\n\n# Create a word cloud comparing texts\n \ntextplot_wordcloud(dfm, comparison = TRUE) \n\n\n\n\n\n\n\n\nLexical dispersion plots are a way to visualise the distribution of words in a text. The textplot_xray function from the quanteda.textplots package can be used to create lexical dispersion plots in R. The code below shows how to create a lexical dispersion plot from the CHILDES_tokens_no_stop object. The textplot_xray function is used to create the lexical dispersion plot. Notice kwic search is first used and the regex arguments introduced above can be applied. The plot shows the occuranve of words over time in the transcripts.\n\nlibrary(quanteda.textplots)\n\n\n# Create a lexical dispersion plot\n \nkwic(CHILDES_tokens_no_stop, pattern = \"good\") %&gt;%\n    textplot_xray()\n\n\n\n\n\n\n\nYou can create lexical dispersion plots for multiple words at once. The code below shows how to create a lexical dispersion plot for the words “good” and “like” in the CHILDES_tokens_no_stop object.\n\n# Create a lexical dispersion plot\n\ntextplot_xray(\nkwic(CHILDES_tokens_no_stop, pattern = \"good\"),\nkwic(CHILDES_tokens_no_stop, pattern = \"like\"))",
    "crumbs": [
      "Corpus analysis",
      "Corpus Analysis"
    ]
  },
  {
    "objectID": "chapters/A9-Corpus.html#corpus-analysis-in-r---quanteda",
    "href": "chapters/A9-Corpus.html#corpus-analysis-in-r---quanteda",
    "title": "Corpus Analysis",
    "section": "",
    "text": "One of the most widely used packages for corpus analysis in R is the quanteda package. quanteda is a comprehensive package that allows researchers to manage corpora and carry out a wide range of analyses on them. To install quanteda, use the following code, if this is the first time you are using the package you will need to include the install.packages(\"quanteda\") function. We will also load the tidyverse package, which is a collection of packages that are commonly used in data analysis in R.",
    "crumbs": [
      "Corpus analysis",
      "Corpus Analysis"
    ]
  },
  {
    "objectID": "chapters/A9-Corpus.html#creating-a-corpus",
    "href": "chapters/A9-Corpus.html#creating-a-corpus",
    "title": "Corpus Analysis",
    "section": "",
    "text": "Typically, the first step in a corpus analysis project is to create a corpus object. A corpus object is a collection of texts that can be analysed together. In quanteda, a corpus object can be created from a variety of sources, including text files, data frames, and character vectors. There are a number of different approaches to reading in textual data.\n\n\n\n\n\n\nTip\n\n\n\nThe data in this teaching page are drawn from talkbank.org, a repository of spoken language data. The data are from the UK component of the CHILDES database, which is a collection of transcripts of child language development.\nAn acknowledgement of the data set is shown below:\nCHILDES: MacWhinney, B. (2000). The CHILDES Project: Tools for analyzing talk. Third Edition. Mahwah, NJ: Lawrence Erlbaum Associates. Note: Please also acknowledge this grant support for CHILDES – NICHD HD082736.\n\n\nFirst data may be read from a text file. You can download three example files here: CHILDES project Gathburn 11. CHILDES project Gathburn 12. CHILDES project Gathburn 13.\nThe files are records of conversations between some children and a teacher. The speakers in the transcript are given the following codes:\n\n\n\n\n\n\n\n\n\n\n\n\nTranscript\nSpeaker 1\nSpeaker 2\nSpeaker 3\nSpeaker 4\nSpeaker 5\nSpeaker 6\nSpeaker 7\n\n\n\nTranscript 11\nSTE Teacher\nLOU Child\nJER Child\nCAT Child\nCHR Child\nALL Child\nUNK Child\n\n\nTranscript 12\nSTE Teacher\nNAN Child\nGEO Child\nRIT Child\nBAR Child\n\n\n\n\nTranscript 13\nSTE Teacher\nGER Child\nSTE Teacher\nKAT Child\nVID Child\nJAS Child\nALL Child\n\n\n\nYou can load files singly or as a group. The code below shows how to load a single file.\n\n# Please replace the file path with the path to the file on your computer\n\ntranscript_11 &lt;- readlines(\"&lt;file path&gt;\")\n\nit is common to have a number of files that you want to load in together. The package readtext can be used to read in multiple files at once. The code below shows how to load in all the files in a folder. Using the readtext function, you can read in all the files in a folder by giving the path of the folder, rather than a fie.\n\n# You will need to copy the address of the folder on your computer into the quotation marks below\n# For example on my laptop the path name is: /Users/k1765032/Library/CloudStorage/OneDrive-King'sCollegeLondon/QERKCL_PISA/data/corpus/Talk Bank/CHILDES/*.txt\n\nlibrary(readtext)\n\nCHILDES_text &lt;- readtext(\"data/folder/*.txt\")\n\n\n\n\n\n\n\nTip\n\n\n\nTo find the path to a file:\nOn a PC: hold Shift and right-click the file or folder, then select “Copy as Path” from the context menu.\nOn a Mac: hold down the Option key and right-click the file or folder, then select “Copy as Pathname” from the context menu.\n\n\nOnce the text files have been read in, they need to be converted to a format quanteda can work with. This is done using the corpus function. The code below shows how to convert the CHILDES_text object to a corpus object. You can think of a corpus like a library of the documents you are using in your project.\n\n# Converting a text file to a corpus object\n\nCHILDES_corpus &lt;- corpus(CHILDES_text)",
    "crumbs": [
      "Corpus analysis",
      "Corpus Analysis"
    ]
  },
  {
    "objectID": "chapters/A9-Corpus.html#basic-analysis-in-quanteda",
    "href": "chapters/A9-Corpus.html#basic-analysis-in-quanteda",
    "title": "Corpus Analysis",
    "section": "",
    "text": "Once you have created a corpus object, you can carry out a range of analyses on it. The quanteda package provides a wide range of functions for analysing corpora. A first step is geting some summary descriptive statistics related to your corpus. The code below shows how to get a summary of the corpus object.\n\n# A simple descriptive summary of the corpus\n\nsummary(CHILDES_corpus)\n\nCorpus consisting of 3 documents, showing 3 documents:\n\n                    Text Types Tokens Sentences\n CHILDES_Gathburn_11.txt   595   9252      1012\n CHILDES_Gathburn_12.txt   605   6157       712\n CHILDES_Gathburn_13.txt   688   8629       983\n\n\nIn quanteda, types and tokens refer to different ways of counting the unique and total words in a corpus:\nTokens: This refers to the total number of words (or word-like units) in the corpus, including repetitions. Each individual occurrence of a word, regardless of whether it appears elsewhere in the corpus, counts as a token. Types: This refers to the number of unique words in the corpus, disregarding any repetitions. A type is counted only once, no matter how many times it appears in the text.\nYou may want to add some metadata to your corpus object. This can be done using the docvars function. The code below shows how to add metadata to the CHILDES_corpus object. For example, each file has different number of speakers, and you may want to add this information to the corpus object.\n\n\n\n\n\n\n\n\n\n\n\n\nTranscript\nSpeaker 1\nSpeaker 2\nSpeaker 3\nSpeaker 4\nSpeaker 5\nSpeaker 6\nSpeaker 7\n\n\n\nTranscript 11\nSTE Teacher\nLOU Child\nJER Child\nCAT Child\nCHR Child\nALL Child\nUNK Child\n\n\nTranscript 12\nSTE Teacher\nNAN Child\nGEO Child\nRIT Child\nBAR Child\n\n\n\n\nTranscript 13\nSTE Teacher\nGER Child\nSTE Teacher\nKAT Child\nVID Child\nJAS Child\nALL Child\n\n\n\nYou can use the docvars function to add metadata to the corpus object. The code below shows how to add the number of speakers to the CHILDES_corpus object.\n\n# Adding metadata to the corpus\n\n# Adding to row 1 (i.e. transcript 11) CHILDES_corpus[1]\n\ndocvars(CHILDES_corpus, \"no_of_speakers\") &lt;- c(7, 5, 7)\n\nsummary(CHILDES_corpus)\n\nCorpus consisting of 3 documents, showing 3 documents:\n\n                    Text Types Tokens Sentences no_of_speakers\n CHILDES_Gathburn_11.txt   595   9252      1012              7\n CHILDES_Gathburn_12.txt   605   6157       712              5\n CHILDES_Gathburn_13.txt   688   8629       983              7\n\n\nTo view your corpus you can as.character function. This will show you the text in the corpus object. Be careful, this can produce a long output! You can print out elements of the corpus object using the as.character(CHILDES_corpus[3]) gives the third text: CHILDES_Gathburn_13.txt.\n\n# Printing\n\nas.character(CHILDES_corpus[3])\n\nIf you want to filter the corpus, you can use the corpus_subset function. This function allows you to filter the corpus object based on the metadata you have added. The code below shows how to filter the CHILDES_corpus object to only include the texts with 7 speakers.\n\n# Creating a new corpus which contain transcripts with 7 speakers\n\nCHILDES_corpus_7 &lt;- corpus_subset(CHILDES_corpus, no_of_speakers == 7)\nsummary(CHILDES_corpus_7)\n\nCorpus consisting of 2 documents, showing 2 documents:\n\n                    Text Types Tokens Sentences no_of_speakers\n CHILDES_Gathburn_11.txt   595   9252      1012              7\n CHILDES_Gathburn_13.txt   688   8629       983              7\n\n\nTo start investigating the text in the corpus, you can use the kwic function. The kwic, key words in context, function allows you to search for a word or phrase in the corpus and see the context in which it appears. The code below shows how to use the kwic function to search for the word “teacher” in the CHILDES_corpus object. The first step in the process is to convert the corpus into a tokens object (i.e. to break it into individual words). This is done using the tokens function.\n\n# Doing a key word in context search\n# Tokenising the corpus\n\nCHILDES_tokens &lt;- tokens(CHILDES_corpus)\n\nThen the keywords in context search can be performed. The code below shows how to use the kwic function to search for the word “teacher” in the CHILDES_tokens object. The pattern argument is used to specify the word or phrase you want to search for, for example here the word “want”. You can use the `window argument to set how many tokens eithe side of the keyword you want to see. Here we have set the window to 10.\n\n# Doing a key word in context search\n\n\nkwic(CHILDES_tokens, pattern = \"want\", window = 10)\n\nKeyword-in-context with 28 matches.                                                                              \n [CHILDES_Gathburn_11.txt, 4986]                     put [/ ] this goes [/ ] I\n [CHILDES_Gathburn_11.txt, 5351]                 couple more. STE: mhm. CAT: I\n [CHILDES_Gathburn_11.txt, 5969]                   STE: here you are. JER: &lt; I\n [CHILDES_Gathburn_11.txt, 6005]                         : xxx [ &gt; ]. JER: &lt; I\n [CHILDES_Gathburn_11.txt, 6031]             ones, haven't you, Jeremy. JER: I\n [CHILDES_Gathburn_11.txt, 6047]                       : mhm. STE: xxx. JER: I\n                                                    \n | want | [/ ] this &lt; goes like &gt; [ &gt;               \n | want | &lt; to go back to the nursery &gt; [*          \n | want | more &gt; [ &gt; ] white ones. LOU:             \n | want | more white ones &gt; [ &lt; ]. STE:             \n | want | more white ones. STE: mhm. STE:           \n | want | more white ones. STE: you want more white \n [ reached 'max' / getOption(\"max.print\") -- omitted 22 rows ]\n\n\nYou can carry out a more flexible range of searches using regular expressions (regex). Regex is a sequence of characters that specifies a match pattern in text.\n\n\n\n\n\n\nTip\n\n\n\nFor more information on regular expressions, see the R documentation.\nThe following symbols can be useful in\n\n\n\n\n\n\nPattern\nDescription\n\n\n\n.\nAny single character except a newline\n\n\n^\nBeginning of String (or Line)\n\n\n$\nEnd of String (or Line)\n\n\n[]\nA set of characters, e.g., [a-z] for lowercase letters\n\n\n[^]\nNegation inside square brackets, e.g., [^a-z] for non-lowercase letters\n\n\n()\nGrouping (capturing group), used for subpatterns\n\n\n\n\n\n\n*\n0 or more of the preceding element\n\n\n+\n1 or more of the preceding element\n\n\n?\n0 or 1 of the preceding element (optional)\n\n\n{n}\nExactly n occurrences of the preceding element\n\n\n{n,}\nn or more occurrences of the preceding element\n\n\n{n,m}\nBetween n and m occurrences of the preceding element\n\n\nord boundary (matches between word and non-word characters)\n\n\n\n\nNot a word boundary\n\n\n\nBeginning of the string (similar to ^ but anchors the start of the whole string)\n\n\n\nEnd of the string (similar to $ but anchors the end of the whole string)\n\n\n\\1, \\2, …\nBackreference to capturing groups, e.g., \\1 refers to the first captured group\n\n\n(?=…)\nPositive lookahead (assertion, matches a position only if the pattern inside matches)\n\n\n(?!…)\nNegative lookahead (assertion, matches a position only if the pattern inside does not match)\n\n\n(?&lt;=…)\nPositive lookbehind (matches if preceded by a pattern)\n\n\n(?&lt;!…)\nNegative lookbehind (matches if not preceded by a pattern)\n\n\n[:alpha:]\nAny letter\n\n\n[:lower:]\nAny lowercase letter\n\n\n[:upper:]\nAny uppercase letter\n\n\n[:digit:]\nAny digit (equivalent to \n\n\n[:alnum:]\nAny letter or number\n\n\n[:xdigit:]\nAny hexadecimal digit\n\n\n[:punct:]\nAny punctuation character\n\n\n[:graph:]\nAny letter, number, or punctuation character\n\n\n[:space:]\nA space, a tab, a new line, etc. (equivalent to )\n\n\n\nFor example: - the regex ^mini will match any word that starts with “mini”. - the regex able$ will match any word that ends with “able”. - the regex colou?r matches both “color” and “colour”. - the regex [J|j]ane matches both “Jane” and “jane”.\n\n\n\n\n\n\n\n\nTip\n\n\n\nThere is a great blog post Baby got backreferences which gives a great introduction to regex (using song lyrics as examples!)\n\n\nTo perform a regex search, you can use the kwic function with the pattern argument set to the regex pattern you want to search for. The code below shows how to use the kwic function to search for words that start with “teach” in the CHILDES_tokens object. You also need to set the valuetype argument to “regex” to indicate that the pattern is a regex pattern. For example, to search for all cases of words that start with “dad” or “Dad” you can use the regex pattern ^[D/d]ad.\n\n# Doing a key word in context search wtih regex\n\nkwic(CHILDES_tokens, pattern = \"^[D/d]ad\", window = 10, valuetype = \"regex\")\n\nKeyword-in-context with 11 matches.                                                                         \n  [CHILDES_Gathburn_12.txt, 957]        wheel (. ) no brakes. STE: your |\n  [CHILDES_Gathburn_12.txt, 976]                it? GEO: hm:? STE: your |\n [CHILDES_Gathburn_12.txt, 1062]          . GEO: one. STE: I heard your |\n [CHILDES_Gathburn_12.txt, 2003]             a [/ ] making a. STE: your |\n [CHILDES_Gathburn_12.txt, 3179] door? NAN: he lives with his mommy and |\n [CHILDES_Gathburn_13.txt, 1710]          GER: yes, except mine [/ ] my |\n                                                            \n Daddy's | car won't steer with no brakes, does it?         \n Daddy's | car won't steer with no brakes [* ].             \n Daddy's | xxx jobs with vans. NAN: 0 [%                    \n   dad   | have a car, Rita? RIT: 0 [                       \n  daddy  | . STE: yes, but do they live very                \n  daddy  | . GER: he hates [! ] dark.                       \n [ reached 'max' / getOption(\"max.print\") -- omitted 5 rows ]\n\n\nNote that you can output the result of kwic search to a dataframe and then use ggplot to represent the data.\n\n# Doing a key word in context search wtih regex and plotting\n\ndad_search &lt;- kwic(CHILDES_tokens, pattern = \"^[D/d]ad\", window = 10, valuetype = \"regex\")\n\nggplot(dad_search, aes(x = keyword, fill = keyword)) +\n  geom_bar() +\n  theme_minimal() +\n  labs(title = \"Occurrences of 'dad' in CHILDES corpus\")\n\n\n\n\n\n\n\nIf you want to look up longer phrases, you can give a pattern within phrase(). For example pattern = phrase(\"I want more\")\n\n# searching for a phrase\n\nkwic(CHILDES_tokens, pattern = phrase(\"I want more\"), window = 10)\n\nKeyword-in-context with 12 matches.                                                                             \n [CHILDES_Gathburn_11.txt, 5968:5970]           . STE: here you are. JER: &lt; |\n [CHILDES_Gathburn_11.txt, 6004:6006]                STE: xxx [ &gt; ]. JER: &lt; |\n [CHILDES_Gathburn_11.txt, 6030:6032] white ones, haven't you, Jeremy. JER: |\n [CHILDES_Gathburn_11.txt, 6046:6048]              STE: mhm. STE: xxx. JER: |\n [CHILDES_Gathburn_11.txt, 6301:6303]              : 0 [ = aids CAT ]. JER: |\n [CHILDES_Gathburn_11.txt, 6328:6330]              &lt; ]. STE: whoops. JER: &lt; |\n                                                        \n I want more | &gt; [ &gt; ] white ones. LOU: there           \n I want more | white ones &gt; [ &lt; ]. STE: oh              \n I want more | white ones. STE: mhm. STE: xxx           \n I want more | white ones. STE: you want more white ones\n I want more | wee bits (. ) to put like that.          \n I want more | bits &gt; [ &gt; ]. STE: xxx [                 \n [ reached 'max' / getOption(\"max.print\") -- omitted 6 rows ]\n\n\n\n\n\n\n\n\nTip\n\n\n\nAn alternative way to represent where words occur in a text is to use the str_view function from the stringr package, which highlights matches:\n\nlibrary(stringr)\n\n# Read in lyrics of Bohemain Rhapsody from Github\n\nurl &lt;- \"https://gist.githubusercontent.com/matematikaadit/3a513cc5fe6ebb9565ee1584e2b4f00d/raw/\"\nfile_content &lt;- readLines(url)\n\nstr_view(file_content, \"poor\")\n\n[10] │ I'm just a &lt;poor&gt; boy, I need no sympathy,\n[45] │ I'm just a &lt;poor&gt; boy, nobody loves me.\n[46] │ He's just a &lt;poor&gt; boy from a &lt;poor&gt; family,",
    "crumbs": [
      "Corpus analysis",
      "Corpus Analysis"
    ]
  },
  {
    "objectID": "chapters/A9-Corpus.html#word-frequencies",
    "href": "chapters/A9-Corpus.html#word-frequencies",
    "title": "Corpus Analysis",
    "section": "",
    "text": "You can also examine the frequency of words in the corpus. The document-feature matrix (DFM) allows you to see the frequency of words in the corpus. The code below shows how to create a DFM object from the CHILDES_tokens object. The dfm function is used to create the DFM object. Then the featfreq function is used to get the word frequencies. Note you can concert the output to a dataframe using as.data.frame() which will allow further processing and use with other packages such as ggplot to make graphs.\n\n# Create a document-feature matrix (DFM)\n\ndfm &lt;- dfm(CHILDES_tokens)\n\n\n# Get word frequencies\nword_frequencies &lt;- featfreq(dfm)\n\nprint(word_frequencies)\n\n        @utf8          @pid             :         11312             / \n            3             3          2772             3           333 \n c-00019181-1        @begin    @languages           eng @participants \n            1             3             3            21             3 \n          ste       teacher             ,           lou         child \n         1577             7           605           103            30 \n          jer           cat           chr           all           unk \n          137            74           110            78             6 \n     @options         multi           @id             |      gathburn \n            3             3            18           180            18 \n        @date   16-may-1984         @tape      location           1.1 \n            1             1             1             1             1 \n @transcriber         ginny    gathercole           and       rebecca \n            1             2             1           131             1 \n        burns     @location     edinburgh      scotland        @types \n            1             1             2             1             3 \n [ reached getOption(\"max.print\") -- omitted 1065 entries ]\n\n# Convert to dataframe\n\nword_frequencies_df &lt;- as.data.frame(word_frequencies)",
    "crumbs": [
      "Corpus analysis",
      "Corpus Analysis"
    ]
  },
  {
    "objectID": "chapters/A9-Corpus.html#cleaning-transcripts",
    "href": "chapters/A9-Corpus.html#cleaning-transcripts",
    "title": "Corpus Analysis",
    "section": "",
    "text": "In some contexts, before analysis, you may want to clean the text. This can involve removing punctuation, numbers, and other non-word characters. The tokens function has a remove_punct argument that can be set to TRUE to remove punctuation. The code below shows how to create a new tokens object with punctuation removed. You can also remove numbers and symbols using the remove_numbers and remove_symbols arguments.\n\n# removing punctuation\n\nCHILDES_tokens_clean &lt;- tokens(CHILDES_corpus, remove_punct = TRUE, remove_numbers = TRUE, remove_symbols = TRUE)\n\nWhen examining word frequencies, you may want to remove stopwords. Stopwords are common words that are often removed from text before analysis. For example, stop words include: “i”, “me” , “my”, “myself”, “we”, “our”, “ours”, “ourselves”, “you”, and “your”. If left in, these common, high frequency words can swap out other terms in the data.\nquanteda has a built in dictionary of stopwords. You can see those included by running head(stopwords(\"en\"), 20) the 20 limits the ouput to the first 20 words. Here en specifies you are interested in stopwords in English.\n\n# quanteda's stop words\n\nhead(stopwords(\"en\"), 20)\n\n [1] \"i\"          \"me\"         \"my\"         \"myself\"     \"we\"        \n [6] \"our\"        \"ours\"       \"ourselves\"  \"you\"        \"your\"      \n[11] \"yours\"      \"yourself\"   \"yourselves\" \"he\"         \"him\"       \n[16] \"his\"        \"himself\"    \"she\"        \"her\"        \"hers\"      \n\n\nTo remove stopwords, you can use the remove argument in the tokens function: tokens_remove(tokens, stopwords(\"en\")). The code below shows how to create a new tokens object with stopwords and punctuation removed. Let us compare outputs with and without the removal of stopwords and punctuation.\n\n# removing stopwords and punctuation\n\nCHILDES_tokens_no_stop &lt;- CHILDES_tokens %&gt;%\n  tokens(remove_punct = TRUE) %&gt;%\n  tokens_remove(stopwords(\"en\"))\n\n# Get word frequencies\n\n# Create a document-feature matrix (DFM)\n\ndfm &lt;- dfm(CHILDES_tokens_no_stop)\n\n\n# Get word frequencies\nword_frequencies_no_stop &lt;- featfreq(dfm)\n\nprint(word_frequencies_no_stop)\n\n        @utf8          @pid         11312  c-00019181-1        @begin \n            3             3             3             1             3 \n   @languages           eng @participants           ste       teacher \n            3            21             3          1577             7 \n          lou         child           jer           cat           chr \n          103            30           137            74           110 \n          unk      @options         multi           @id             | \n            6             3             3            18           180 \n     gathburn         @date   16-may-1984         @tape      location \n           18             1             1             1             1 \n          1.1  @transcriber         ginny    gathercole       rebecca \n            1             1             2             1             1 \n        burns     @location     edinburgh      scotland        @types \n            1             1             2             1             3 \n        cross         group            td           sit           red \n            3             3             3             9            16 \n [ reached getOption(\"max.print\") -- omitted 906 entries ]\n\n# Convert to dataframe\n\nword_frequencies_no_stop_df &lt;- as.data.frame(word_frequencies_no_stop)\n\nWe can compare the results of the two word frequency lists to see the impact of removing stopwords.\n\n# graphs of frequencies before and after removing stopwords\n\nword_frequencies_df &lt;- word_frequencies_df %&gt;%\n  mutate(feat = rownames(word_frequencies_df)) %&gt;%\n  arrange(desc(word_frequencies)) %&gt;%\n  slice_head(n = 20)\n\n\nggplot(word_frequencies_df, aes(x = reorder(feat, - word_frequencies), y = word_frequencies, fill = feat)) +\n  geom_bar(stat = \"identity\") +\n  theme_minimal() +\n  labs(title = \"Top 20 word frequencies before removing stopwords\") +\n  labs(x = \"Word\", y = \"Frequency\")+\n  theme(legend.position = \"none\")\n\n\n\n\n\n\nword_frequencies_no_stop_df &lt;- word_frequencies_no_stop_df %&gt;%\n  mutate(feat = rownames(word_frequencies_no_stop_df)) %&gt;%\n  arrange(desc(word_frequencies_no_stop)) %&gt;%\n  slice_head(n = 20)\n\n\nggplot(word_frequencies_no_stop_df, aes(x = reorder(feat, - word_frequencies_no_stop), y = word_frequencies_no_stop, fill = feat)) +\n  geom_bar(stat = \"identity\") +\n  theme_minimal() +\n  labs(title = \"Top 20 word frequencies after removing stopwords and punctuation\") +\n  labs(x = \"Word\", y = \"Frequency\") +\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\nAs you can see, the build in functions for removing punctuation and stop words are not always ideal. You may want to create your own list of words to remove or use a different method to remove them. You can also use the tokens function with the remove argument to remove specific words. The code below shows how to remove the word “teacher” from the CHILDES_tokens object.\n\n# custom removal of words\n\n# Create a custom list of stop words\ncustom_stopwords &lt;- c(\"ste\", \"&lt;\", \"&gt;\", \"xxx\", \"ger\", \"|\", \"kat\", \"jer\", \"0\", \"geo\", \"=\", \"chr\", \"+\")\n\nCHILDES_tokens_no_stop &lt;- CHILDES_tokens %&gt;%\n  tokens(remove_punct = TRUE) %&gt;%\n  tokens_remove(stopwords(\"en\")) %&gt;%\n  tokens_remove(custom_stopwords)\n\n# Get word frequencies\n\n# Create a document-feature matrix (DFM)\n\ndfm &lt;- dfm(CHILDES_tokens_no_stop)\n\n\n# Get word frequencies\nword_frequencies_no_stop &lt;- featfreq(dfm)\n\nprint(word_frequencies_no_stop)\n\n        @utf8          @pid         11312  c-00019181-1        @begin \n            3             3             3             1             3 \n   @languages           eng @participants       teacher           lou \n            3            21             3             7           103 \n        child           cat           unk      @options         multi \n           30            74             6             3             3 \n          @id      gathburn         @date   16-may-1984         @tape \n           18            18             1             1             1 \n     location           1.1  @transcriber         ginny    gathercole \n            1             1             1             2             1 \n      rebecca         burns     @location     edinburgh      scotland \n            1             1             1             2             1 \n       @types         cross         group            td           sit \n            3             3             3             3             9 \n          red          seat           two          come        around \n           16             5            22            17             5 \n [ reached getOption(\"max.print\") -- omitted 893 entries ]\n\n# Convert to dataframe\n\nword_frequencies_no_stop_df &lt;- as.data.frame(word_frequencies_no_stop)\n\n\nCHILDES_tokens_no_stop&lt;- CHILDES_tokens_no_stop %&gt;%\n  tokens_remove(custom_stopwords)\n\nword_frequencies_no_stop_df &lt;- word_frequencies_no_stop_df %&gt;%\n  mutate(feat = rownames(word_frequencies_no_stop_df)) %&gt;%\n  arrange(desc(word_frequencies_no_stop)) %&gt;%\n  slice_head(n = 20)\n\n\nggplot(word_frequencies_no_stop_df, aes(x = reorder(feat, - word_frequencies_no_stop), y = word_frequencies_no_stop, fill = feat)) +\n  geom_bar(stat = \"identity\") +\n  theme_minimal() +\n  labs(title = \"Top 20 word frequencies after removing stopwords and punctuation\") +\n  labs(x = \"Word\", y = \"Frequency\") +\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\nWe have seen how to search for a single word or phrase in the corpus. You may want to search for multiple words or phrases at once. This can be done using a dictionary. A dictionary is a list of words or phrases that you want to search for in the corpus. The code below shows how to create a dictionary object using the dictionary function. The dictionary function takes a list of words or phrases as input. You can use the dictionary when making a dfm to create word counts\n\n# Setting up a dictionary to search for\n\ndict &lt;- dictionary(list(parent = c(\"dad\", \"daddy\", \"Daddy\", \"Dad\", \"mum\", \"mummy\", \"Mum\", \"Mummy\"),\n                        colour = c(\"red\", \"orange\" , \"yellow\", \"green\", \"blue\", \"violet\")))\n\n# searching for a phrase\n\n# Create a document-feature matrix (DFM) using the dictionary to search for words\n\ndfm &lt;- CHILDES_tokens_no_stop %&gt;%\n       tokens_lookup(dictionary = dict) %&gt;%\n      dfm()\n\n# display the dfm\ndfm\n\nDocument-feature matrix of: 3 documents, 2 features (16.67% sparse) and 1 docvar.\n                         features\ndocs                      parent colour\n  CHILDES_Gathburn_11.txt      0     29\n  CHILDES_Gathburn_12.txt      2      4\n  CHILDES_Gathburn_13.txt      4     20",
    "crumbs": [
      "Corpus analysis",
      "Corpus Analysis"
    ]
  },
  {
    "objectID": "chapters/A9-Corpus.html#word-clouds",
    "href": "chapters/A9-Corpus.html#word-clouds",
    "title": "Corpus Analysis",
    "section": "",
    "text": "A common way to visualise word frequencies is to use a word cloud. A word cloud is a visual representation of text data, where the size of each word indicates its frequency in the text. The quanteda.textplots package can be used to create word clouds in R.\nThe code below shows how to create a word cloud from the CHILDES_tokens_no_stop object. The text_plotwordcloud function is used to create the word cloud from a ‘dfm’ object. The dim.trim function is used to set the minimum frequency of words to include in the word cloud. If low frequencies words are left in, the word cloud is hard to read. The min_termfreq argument is used to set the minimum frequency of words to include in the word cloud. The textplot_wordcloud function is used to create the word cloud.\n\nlibrary(quanteda.textplots)\n\n# Create a word cloud\n# Start from the cleaned dfm object\n\n# Create a custom list of stop words\ncustom_stopwords &lt;- c(\"ste\", \"&lt;\", \"&gt;\", \"xxx\", \"ger\", \"|\", \"kat\", \"jer\", \"0\", \"geo\", \"=\", \"chr\", \"+\")\n\nCHILDES_tokens_no_stop &lt;- CHILDES_tokens %&gt;%\n  tokens(remove_punct = TRUE) %&gt;%\n  tokens_remove(stopwords(\"en\")) %&gt;%\n  tokens_remove(custom_stopwords)\n\n# Get word frequencies\n\n# Create a document-feature matrix (DFM)\n# Trim to remove low frequency words\n\ndfm &lt;- dfm(CHILDES_tokens_no_stop) %&gt;%\n    dfm_trim(min_termfreq = 10, verbose = FALSE)\n\n# Create a word cloud\n\ntextplot_wordcloud(dfm) \n\n\n\n\n\n\n\nThe argument colorcan be use to set a colour gradient by frequency.\n\n# Create a word cloud comparing texts\n \ntextplot_wordcloud(dfm, color =c(\"lightblue\", \"skyblue\", \"blue\", \"darkblue\")) \n\n\n\n\n\n\n\nThe textplot_wordcloud() function has an argument to produce comparative plots by text, by setting the comparison argument to true\n\n# Create a word cloud comparing texts\n \ntextplot_wordcloud(dfm, comparison = TRUE)",
    "crumbs": [
      "Corpus analysis",
      "Corpus Analysis"
    ]
  },
  {
    "objectID": "chapters/A9-Corpus.html#lexical-dispersion-plots",
    "href": "chapters/A9-Corpus.html#lexical-dispersion-plots",
    "title": "Corpus Analysis",
    "section": "",
    "text": "Lexical dispersion plots are a way to visualise the distribution of words in a text. The textplot_xray function from the quanteda.textplots package can be used to create lexical dispersion plots in R. The code below shows how to create a lexical dispersion plot from the CHILDES_tokens_no_stop object. The textplot_xray function is used to create the lexical dispersion plot. Notice kwic search is first used and the regex arguments introduced above can be applied. The plot shows the occuranve of words over time in the transcripts.\n\nlibrary(quanteda.textplots)\n\n\n# Create a lexical dispersion plot\n \nkwic(CHILDES_tokens_no_stop, pattern = \"good\") %&gt;%\n    textplot_xray()\n\n\n\n\n\n\n\nYou can create lexical dispersion plots for multiple words at once. The code below shows how to create a lexical dispersion plot for the words “good” and “like” in the CHILDES_tokens_no_stop object.\n\n# Create a lexical dispersion plot\n\ntextplot_xray(\nkwic(CHILDES_tokens_no_stop, pattern = \"good\"),\nkwic(CHILDES_tokens_no_stop, pattern = \"like\"))",
    "crumbs": [
      "Corpus analysis",
      "Corpus Analysis"
    ]
  },
  {
    "objectID": "chapters/A9-Corpus.html#keyness",
    "href": "chapters/A9-Corpus.html#keyness",
    "title": "Corpus Analysis",
    "section": "\n4.1 Keyness",
    "text": "4.1 Keyness\nKeyness analysis is a way to identify words that are significantly more frequent in one text compared to another. The textstat_keyness function from the quanteda.textstats package can be used to perform keyness analysis in R. The code below shows how to perform keyness analysis on two texts. The textstat_keyness function is used to perform keyness analysis. The target argument is used to specify the texts to compare against. The results are plotted using the textplot_keyness function, specifying the number of words to plot with the n argument and the colours to use with the color argument.\n\nlibrary(quanteda.textplots)\n\n\n# Create a corpus\n\nmanifesto_corpus &lt;- corpus(manifesto_text)\n\n# Label the manifestos\n\ndocvars(manifesto_corpus, \"party\") &lt;- c(\"conservative\", \"DUP\", \"green\", \"labour\", \"liberal_democrat\", \"Plaid_cymru\", \"SNP\")\n\n\n# Subset to green and conservative\n\ngreen_lab_manifesto &lt;- corpus_subset(manifesto_corpus, party == \"green\" | party == \"labour\")\n\n# Remove punctuation and stopwords\n# group by party\n\ndfmat_manifesto &lt;- tokens(green_lab_manifesto, remove_punct = TRUE, \n                          remove_numbers = TRUE, remove_symbols = TRUE) %&gt;%\n  tokens_remove(stopwords(\"english\")) %&gt;%\n  dfm() \n\n# Perform keyness analysis\nkeyness_stat &lt;- textstat_keyness(dfmat_manifesto, target = \"green_manifesto.txt\", measure = \"lr\")\n\n# Plot the keyness analysis\ntextplot_keyness(keyness_stat, color = c(\"green\", \"red\"), n = 20)",
    "crumbs": [
      "Corpus analysis",
      "Corpus Analysis"
    ]
  },
  {
    "objectID": "chapters/A9-Corpus.html#seminar-activities",
    "href": "chapters/A9-Corpus.html#seminar-activities",
    "title": "Corpus Analysis",
    "section": "\n4.2 Seminar activities",
    "text": "4.2 Seminar activities\nThe first tasks use the election manifesto corpus. The manifestos come from: The Manifesto Corpus version 2024-1, :Lehmann, Pola / Franzmann, Simon / Al-Gaddooa, Denise / Burst, Tobias / Ivanusch, Christoph / Lewandowski, Jirka / Regel, Sven / Riethmüller, Felicia / Zehnter, Lisa (2024): Manifesto Corpus. Version: 2024-1. Berlin: WZB Berlin Social Science Center/Göttingen: Institute for Democracy Research (IfDem).\nYou can download the 2019 labour and conservative Liberal Democrat Scottish National, Plaid Cymru, Green Party, Democatic Unionist Party manifestos here.\n\n4.2.1 Task 1 Word clouds\n\nDownload the manifesto texts for the parties. Create a corpus object from the texts. Add metadata to the corpus object to indicate the party of each manifesto. Create a document-feature matrix (DFM) from the corpus object. Produce a table and a graph of the counts of words by frequency.\nHint - when you prepare the data frame for plotting you will want to convert the rownames in the dfm object dataframe to a new column - you can do that with: word_frequencies_df &lt;- word_frequencies_df %&gt;% mutate(feat = rownames(word_frequencies_df)). To make the graph look reasonable you will also need to filter the data frame to get only the top words by frequency.\n\n\n# Load the manifestos\n\n# manifesto_text &lt;- readtext(glue(\"&lt;your manifesto text file folder&gt;\")) \n\n# Create a corpus object\n\nmanifesto_corpus &lt;- corpus(manifesto_text)\n\n# Add metadata to the corpus object\n\ndocvars(manifesto_corpus, \"party\") &lt;- c(\"conserative\", \"DUP\", \"Green,\", \"Labour\", \"Liberal_democrat\", \"Plaid_cymru\", \"SNP\")\n\nsummary(manifesto_corpus)\n\nCorpus consisting of 7 documents, showing 7 documents:\n\n                      Text Types Tokens Sentences            party\n         con_manifesto.txt  3493  34445         1      conserative\n         DUP_manifesto.txt  2543  16435        23              DUP\n       green_manifesto.txt  4317  39279        55           Green,\n         lab_manifesto.txt  4585  45071         1           Labour\n     lib_dem_manifesto.txt  4631  44698         5 Liberal_democrat\n plaid_cymru_manifesto.txt  3870  30239        37      Plaid_cymru\n         SNP_manifesto.txt  3596  35561        16              SNP\n\n# Create a dfm grouped by party\n\ndfmat_manifesto &lt;- tokens(manifesto_corpus) %&gt;%\n  tokens_group(groups = party) %&gt;%\n  dfm()\n\n# Get word frequencies\n\nword_frequencies &lt;- featfreq(dfmat_manifesto)\n\n# Convert to dataframe\n\nword_frequencies_df &lt;- as.data.frame(word_frequencies)\n\n# Prepare the data for plotting by adding a column for features\n# Arrange by frequency and select the top 20 words\n\nword_frequencies_df &lt;- word_frequencies_df %&gt;%\n  mutate(feat = rownames(word_frequencies_df)) %&gt;%\n  arrange(desc(word_frequencies)) %&gt;%\n  slice_head(n = 20)\n\n\n# Plot the word frequencies\n\nggplot(word_frequencies_df, aes(x = reorder(feat, - word_frequencies), y = word_frequencies, fill = feat)) +\n  geom_bar(stat = \"identity\") +\n  theme_minimal() +\n  labs(title = \"Word frequencies in the manifestos\") +\n  labs(x = \"Word\", y = \"Frequency\") +\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\nThe manifesto corpus needs to be cleaned before analysis. Remove punctuation and stopwords from the corpus. Create a new DFM object from the cleaned corpus. Produce a new table and a graph of the counts of words by frequency in the cleaned corpus. You may want to add custom terms to clean the corpus.\nThis time use tokens_group(groups = party) to create graphs of word frequencies by party.\n\n\n# Load the manifestos\n\n# manifesto_text &lt;- readtext(glue(\"&lt;your manifesto text file folder&gt;\")) \n\n# Create a corpus object\n\nmanifesto_corpus &lt;- corpus(manifesto_text)\n\n# Add metadata to the corpus object\n\ndocvars(manifesto_corpus, \"party\") &lt;- c(\"conserative\", \"DUP\", \"Green,\", \"Labour\", \"Liberal_democrat\", \"Plaid_cymru\", \"SNP\")\n\nsummary(manifesto_corpus)\n\nCorpus consisting of 7 documents, showing 7 documents:\n\n                      Text Types Tokens Sentences            party\n         con_manifesto.txt  3493  34445         1      conserative\n         DUP_manifesto.txt  2543  16435        23              DUP\n       green_manifesto.txt  4317  39279        55           Green,\n         lab_manifesto.txt  4585  45071         1           Labour\n     lib_dem_manifesto.txt  4631  44698         5 Liberal_democrat\n plaid_cymru_manifesto.txt  3870  30239        37      Plaid_cymru\n         SNP_manifesto.txt  3596  35561        16              SNP\n\n# Create a dfm grouped by party\n\ncustom_stopwords &lt;- c(\"na\", \"£\")\n\ndfmat_manifesto &lt;- tokens(manifesto_corpus, remove_punct = TRUE, remove_numbers = TRUE, remove_symbols = TRUE) %&gt;%\n  tokens_remove(stopwords(\"en\")) %&gt;%\n  tokens_remove(custom_stopwords) %&gt;%\n  tokens_group(groups = party) %&gt;%\n  dfm()\n\n# Get word frequencies\n\nword_frequencies_by_party &lt;- as.data.frame(as.matrix(dfmat_manifesto))\n\n# Tidy the columns - delete meta-data\n\nword_frequencies_by_party &lt;- word_frequencies_by_party %&gt;%\n  select(-text, -text_en, -cmp_code, -eu_code)\n\n# Get a total count of words across party\n# Prepare the data for plotting by adding a column for features\n# Arrange by frequency and select the top 20 words\n\nword_frequencies_total &lt;- as.data.frame(colSums(word_frequencies_by_party)) \n\n# add column `feat` with rownames\nword_frequencies_total$feat &lt;- rownames(word_frequencies_total)\n\nword_frequencies_total &lt;- word_frequencies_total %&gt;%\n  rename(word_frequencies = \"colSums(word_frequencies_by_party)\") %&gt;%\n  arrange(desc(word_frequencies)) %&gt;%\n  slice_head(n = 20)\n\n\n# Plot the word frequencies\n\nggplot(word_frequencies_df, aes(x = reorder(feat, - word_frequencies), y = word_frequencies, fill = feat)) +\n  geom_bar(stat = \"identity\") +\n  theme_minimal() +\n  labs(title = \"Word frequencies in all the manifestos\") +\n  labs(x = \"Word\", y = \"Frequency\") +\n  theme(legend.position = \"none\") +\n  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))\n\n\n\n\n\n\n# Prepare the data for parties for plotting by pivoting\n\nword_frequencies_by_party$parties &lt;- rownames(word_frequencies_by_party) # turn the row names into a column\n \nparty_frequencies &lt;- word_frequencies_by_party %&gt;%\n  pivot_longer(\n    cols = -parties,          \n    names_to = \"word\",      \n    values_to = \"count\") %&gt;%\n  arrange(desc(count)) %&gt;%\n  slice_head(n = 20)\n\n# Facet plot by party\n\nggplot(party_frequencies, aes(x = reorder(word, - count), y = count, fill = word)) +\n  geom_bar(stat = \"identity\") +\n  theme_minimal() +\n  labs(title = \"Word frequencies in the manifestos by party\") +\n  labs(x = \"Word\", y = \"Frequency\") +\n  theme(legend.position = \"none\") +\n  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1)) +\n  facet_wrap(~parties)\n\n\n\n\n\n\n\n\n4.2.2 Task 2 wordclouds and network analysis\n\nCreate wordclouds for the conservative and labour party manifestos using the textplot_network function. Work with the formatting options to get the best possible output. What patterns can you determine about differences in word use?\nCreate a network plot of the words in the conservative and labour party manifestos using the textplot_network function. Work with the formatting options to get the best possible output. What patterns can you determine about differences in word use?\n\n\nlibrary(quanteda.textplots)\n\n\n# Load the manifestos\n\n# manifesto_text &lt;- readtext(glue(\"&lt;your manifesto text file folder&gt;\")) \n\n# Create a corpus object\n\nmanifesto_corpus &lt;- corpus(manifesto_text)\n\n# Add metadata to the corpus object\n\ndocvars(manifesto_corpus, \"party\") &lt;- c(\"conservative\", \"dup\", \"green,\", \"labour\", \"liberal_democrat\", \"Plaid_cymru\", \"SNP\")\n\nsummary(manifesto_corpus)\n\nCorpus consisting of 7 documents, showing 7 documents:\n\n                      Text Types Tokens Sentences            party\n         con_manifesto.txt  3493  34445         1     conservative\n         DUP_manifesto.txt  2543  16435        23              dup\n       green_manifesto.txt  4317  39279        55           green,\n         lab_manifesto.txt  4585  45071         1           labour\n     lib_dem_manifesto.txt  4631  44698         5 liberal_democrat\n plaid_cymru_manifesto.txt  3870  30239        37      Plaid_cymru\n         SNP_manifesto.txt  3596  35561        16              SNP\n\n# Subset for the conservative and labour party\n\ncon_manifesto &lt;- corpus_subset(manifesto_corpus, party == \"conservative\")\nlab_manifesto &lt;- corpus_subset(manifesto_corpus, party == \"labour\")\n\n\n# Create a dfm grouped for the conservative and labour party, cleaning the corpus\n\ncustom_stopwords &lt;- c(\"na\", \"£\")\n\ndfmat_con_manifesto &lt;- tokens(con_manifesto, remove_punct = TRUE, remove_numbers = TRUE) %&gt;%\n  tokens_remove(stopwords(\"en\")) %&gt;%\n  tokens_remove(custom_stopwords) %&gt;%\n  dfm()\n\ndfmat_lab_manifesto &lt;- tokens(lab_manifesto, remove_punct = TRUE, remove_numbers = TRUE) %&gt;%\n  tokens_remove(stopwords(\"en\")) %&gt;%\n  tokens_remove(custom_stopwords) %&gt;%\n  dfm()\n\n# Create word clouds\n\ntextplot_wordcloud(dfmat_con_manifesto, \n                   min_count = 5, \n                   max_words = 100, \n                   color = \"blue\", \n                   max_size = 5, \n                   min_size = 1)\n\n\n\n\n\n\ntextplot_wordcloud(dfmat_lab_manifesto,\n                   min_count = 5,\n                   max_words = 100, \n                   color = \"red\",\n                   max_size = 5,\n                   min_size = 1)\n\n\n\n\n\n\n\n\n# Create network plots\n# Include only top 20 terms\n\n\ntop_terms &lt;- names(topfeatures(dfmat_con_manifesto, 20))\ndfmat_con_manifesto_filtered &lt;- dfm_select(dfmat_con_manifesto, pattern = top_terms)\n\n\n\ndfmat_lab_manifesto &lt;- tokens(lab_manifesto, remove_punct = TRUE, remove_numbers = TRUE) %&gt;%\n  tokens_remove(stopwords(\"en\")) %&gt;%\n  dfm()\n\n# Include only top 20 terms\ntop_terms &lt;- names(topfeatures(dfmat_lab_manifesto, 20))\ndfmat_lab_manifesto_filtered &lt;- dfm_select(dfmat_lab_manifesto, pattern = top_terms)\n\n\n\n# Produce a network plot\n\ntextplot_network(dfmat_con_manifesto_filtered, min_freq = 50, edge_size = 0.5, edge_color = \"lightblue\", vertex_size = 0.5, vertex_labelsize = 5, vertex_labelcolor = \"darkblue\", vertex_color = \"lightblue\", vertex_alpha = 0.5, repel = TRUE, seed = 1234)\n\n\n\n\n\n\ntextplot_network(dfmat_lab_manifesto_filtered, min_freq = 50, edge_size = 0.5, edge_color = \"red\", vertex_size = 0.5, vertex_labelsize = 5, vertex_labelcolor = \"darkred\", vertex_color = \"red\", vertex_alpha = 0.5, repel = TRUE, seed = 1234)\n\n\n\n\n\n\n\n\n4.2.3 Task 3 keyness analysis\n\nCreate a keyness plot comparing the language in the labour and conservative manifestos. What words are most distinctive in each manifesto?\n\n\nlibrary(quanteda.textplots)\n\n\n# Create a corpus\n\nmanifesto_corpus &lt;- corpus(manifesto_text)\n\n# Label the manifestos\n\ndocvars(manifesto_corpus, \"party\") &lt;- c(\"conservative\", \"DUP\", \"green\", \"labour\", \"liberal_democrat\", \"Plaid_cymru\", \"SNP\")\n\n\n# Subset to labour and conservative\n\ncon_lab_manifesto &lt;- corpus_subset(manifesto_corpus, party == \"conservative\" | party == \"labour\")\n\n# Remove punctuation and stopwords\n# group by party\n\ndfmat_manifesto &lt;- tokens(con_lab_manifesto, remove_punct = TRUE, \n                          remove_numbers = TRUE, remove_symbols = TRUE) %&gt;%\n  tokens_remove(stopwords(\"english\")) %&gt;%\n  dfm() \n\n# Perform keyness analysis\nkeyness_stat &lt;- textstat_keyness(dfmat_manifesto, target = \"lab_manifesto.txt\", measure = \"lr\")\n\n# Plot the keyness analysis\ntextplot_keyness(keyness_stat, color = c(\"blue\", \"red\"), n = 20)\n\n\n\n\n\n\n\n\n4.2.4 Task 4 lexical disperssion plot\n\nCreate a lexical dispersion plot comparing where the word “Brexit” and “economy” appears in the labour, conservative and liberal democrat policy\n\n\nlibrary(quanteda.textplots)\n\n\n# Create a corpus\n\nmanifesto_corpus &lt;- corpus(manifesto_text)\n\n# Label the manifestos\n\ndocvars(manifesto_corpus, \"party\") &lt;- c(\"conservative\", \"DUP\", \"green\", \"labour\", \"liberal_democrat\", \"Plaid_cymru\", \"SNP\")\n\n\n# Subset to labour and conservative\n\ncon_lab_lib_manifesto &lt;- corpus_subset(manifesto_corpus, party == \"conservative\" | party == \"labour\" |\n                                     party == \"liberal_democrat\")\n\ncon_lab_lib_manifesto_tokens &lt;- tokens(con_lab_lib_manifesto, remove_punct = TRUE, \n                          remove_numbers = TRUE, remove_symbols = TRUE) %&gt;%\n  tokens_remove(stopwords(\"en\"))\n                \ntextplot_xray(\nkwic(con_lab_lib_manifesto_tokens, pattern = \"brexit\"),\nkwic(con_lab_lib_manifesto_tokens, pattern = \"economy\"))",
    "crumbs": [
      "Corpus analysis",
      "Corpus Analysis"
    ]
  },
  {
    "objectID": "chapters/04-Intro_to_graphs.html",
    "href": "chapters/04-Intro_to_graphs.html",
    "title": "Making graphs",
    "section": "",
    "text": "The tidyverse includes the incredibly powerful ggplot2 package. This package is pretty much the industry standard for making graphs for publication. ggplot2 is built on the grammar of graphics where you build graphs by specifying underlying attributes and layering geometric objects on top of each other. In the diagram below you can see how a graph is built from geometric objects (the things that are plotted such as points and bars) a scale, and plot annotations (e.g. a key, title etc). You can then apply faceting to the graph to automatically split one graph into multiple plots, allowing you to easily compare different groupings. Publications, such as the Financial Times, make daily use of ggplot2.",
    "crumbs": [
      "Making graphs"
    ]
  },
  {
    "objectID": "chapters/04-Intro_to_graphs.html#sec-geom_bar",
    "href": "chapters/04-Intro_to_graphs.html#sec-geom_bar",
    "title": "Making graphs",
    "section": "2.1 geom_bar",
    "text": "2.1 geom_bar\nThe geom_bar function is versatile, allowing the creation of bar, multiple bar, stacked bar charts and histograms. This first example shows how we can use bar charts to represent the number of cars in a household ST251Q01JA:\n\n1plot_cars &lt;- PISA_2022 %&gt;% filter(!is.na(ST251Q01JA))\n\n2ggplot(data = plot_cars,\n3       aes(x=ST251Q01JA)) +\n4  geom_bar()\n\n\n1\n\nget the PISA_2022 dataset and remove all rows where ST251Q01JA is NA, storing this new dataset as plot_cars\n\n2\n\npass the plot_cars to ggplot, as the dataset we are going to plot\n\n3\n\nspecify the x values to be the values stored in ST251Q01JA, i.e. we will have a bar for each response given in ST251Q01JA: None, One, Two, Three or more.\n\n4\n\ngeom_bar tell ggplot to make bars, it uses the aesthetic from line 5, to plot the x axis, note we haven’t given it a y value, this is auto-calculated from the number of students in each x group.\n\n\n\n\n\n\n\n\n\n\n\nWe can choose to let ggplot split the results into different groups for us by setting a fill option, in this case on the OECD status of the country, i.e. do students in OECD countries have more cars than those not in OECD countries, to do this, we add fill=OECD to the aes on line 2 below:\n\nggplot(data = plot_cars, \n       aes(x=ST251Q01JA, fill=OECD)) + \n  geom_bar()\n\n\n\n\n\n\n\n\nThe bars are now coloured with a key, but, annoyingly, the bars are on top of each other which makes it hard to make direct comparisons. To compare different groups we need the bars to not be stacked, we want them next to each other, or in ggplot language, we want the bars to dodge each other, to do this we add the position=position_dodge() command to line 3 below:\n\n\n\n\n\n\n\n\n\n\n2.1.1 Raising the bars yourself\nggplot can do a lot of the hard work when putting together bar charts, e.g. counting the number of students in each group, but there might also be times when you want to use pipes to calculate summary values that you then want plot. That is, you want to specify the heights of the bars yourself. To do this we will specify the y axis in the aes and use stat=\"indentity\" to tell ggplot that’s what we’re doing. Take the example where you want to find the overall percentage of students for a range of countries getting over 500 in PV1SCIE:\n\n1plot_data &lt;- PISA_2022 %&gt;%\n  group_by(OECD, CNT) %&gt;%\n  summarise(all_students = n(),\n            upper_sci_per = sum(PV1SCIE &gt; 500) / n())\n\n2ggplot(data=plot_data,\n       aes(x=CNT, y=upper_sci_per)) +\n3  geom_bar(aes(fill=OECD),\n4           position=position_dodge(),\n5           stat=\"identity\") +\n6  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))\n\n\n1\n\ncreates a dataframe plot_data that calculates the percentage of students in each country CNT, that have a science grade PV1SCIE over 500\n\n2\n\nas we are setting the heights of the bars ourselves, we need to give the ggplot aes command a y value, in this case y=upper_sci_per\n\n3\n\nthe geom_bar is given a fill value of OECD, this will allow us to see how countries in and out of the OECD compare\n\n4\n\nwe use position=position_dodge() as we want the percentage grades of each country to be next to each other so we can look for differences in heights\n\n5\n\nstat=\"identity\" tells geom_bar that you have defined your own bar heights in the y attribute and not to count the number of rows.\n\n6\n\nthe theme command helps rotate the x-axis labels 90 degrees, so they don’t overlap.\n\n\n\n\n\n\n\n\n\n\n\nAlternatively, you can use the geom_col() function that can handle you setting the y values and not specifying stat=\"identity\"\n\nggplot(data=plot_data, \n       aes(x=CNT, y=upper_sci_per)) +\n  geom_col(aes(fill=OECD), \n           position=position_dodge()) +\n  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))\n\n\n\n2.1.2 Questions\n\n\nCan you spot the 4 errors in this code.\n\n\nggplot(data=schools %&gt;% filter(Phase == \"Secondary\"), \n       x=Region +\n  geom_bar(as(fill=Gender) \n\n\n\nanswer\nggplot(data=schools %&gt;% filter(Phase == \"Secondary\"), \n       aes(x=Region)) + # 1 no aes() around the x value # 2 missing close brackets\n  geom_bar(aes(fill=Gender)) # 3 aes not as # 4 missing closing bracket\n\n\n\nCreate a bar chart showing the total number of students for each grouping of “How satisfied are you with each of the following: The way that you look” WB155Q02HA. Adjust this graph to see if there is a difference for this among females and males:\n\n\n\nanswer\nggplot(data=PISA_2022,\n       aes(x=WB155Q02HA)) +\n  geom_bar() +\n  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))\n\n\n\n\nanswer with gender added\nggplot(data=PISA_2022 %&gt;% filter(!is.na(WB155Q02HA)),\n       aes(x=WB155Q02HA, fill=ST004D01T)) +\n  geom_bar(position=position_dodge()) +\n  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))\n\n\n\nPlot bars for the number of Females and Males ST004D01T who answer each grouping for: “Confident can do in future: : Finding learning resources online on my own” ST355Q03JA. Make sure that the bars position_dodge() each other so we can compare the heights.\n\n\n\nanswer\ngraph_data &lt;- PISA_2022 %&gt;% filter(!is.na(ST355Q03JA))\n\n  ggplot(data=graph_data,\n       aes(x=ST355Q03JA, fill=ST004D01T)) +\n  geom_bar(position=position_dodge()) +\n  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))\n\n\n\nFor France and the United Kingdom, plot the total number of students who gave each answer for ST324Q11JA “Agree/disagree: School has been a waste of time.”. Filter out all the NA values first !is.na(...)\n\n\n\nanswer dataframe\nplot_data &lt;- PISA_2022 %&gt;% \n  filter(CNT %in% c(\"France\", \"United Kingdom\"),\n         !is.na(ST324Q11JA))\n\n\n\n\nanswer\nggplot(plot_data,\n       aes(x=ST324Q11JA, fill=CNT)) +\n  geom_bar(position=position_dodge()) +\n  theme(legend.position = \"bottom\")\n\n\n\nUsing the PISA_2022_school dataset (available here create a table that stores for each country CNT\n\n\nthe total number of full-time teacher, SC018Q01TA01\nthe total number of full-time teachers with a bachelors qualification SC018Q08JA01\nthe total number of full-time teachers with a master’s qualification SC018Q01TA01\nthe total number of full-time teachers with a doctoral qualification SC018Q10JA01\n\nAdd an additional column working out the % of teachers with master’s in each country, call this per_MA\n\n\ncreating the dataframe\nplot_workforce &lt;- PISA_2022_school %&gt;% \n  group_by(CNT) %&gt;% \n  summarise(schools = n(),\n            total = sum(SC018Q01TA01, na.rm=TRUE),\n            BA =    sum(SC018Q08JA01, na.rm=TRUE),\n            PHD =   SC018Q10JA01 %&gt;% sum(na.rm=TRUE),\n            MA =    SC018Q09JA01 %&gt;% sum(na.rm=TRUE),\n            per_MA = MA *100 / total)\n\n\nUsing this dataframe plot a bar graph for each country of the per_MA, use the number of schools as a fill:\n\n\ncreating the graph\nggplot(data=plot_workforce,\n       aes(x=CNT, y=per_MA, fill=schools)) +\n  geom_bar(stat=\"identity\") +\n  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +\n  theme(legend.position=\"top\")\n\n\n\n[Extension] Explore other patterns in the school and student Pisa datasets.",
    "crumbs": [
      "Making graphs"
    ]
  },
  {
    "objectID": "chapters/04-Intro_to_graphs.html#geom_text",
    "href": "chapters/04-Intro_to_graphs.html#geom_text",
    "title": "Making graphs",
    "section": "2.2 geom_text",
    "text": "2.2 geom_text\nOur bar charts look great, but finding the actual value of each bar can be a little clumsy if we have to get a ruler out and read off the y-axis. Better would be for us to have numbers listed at the top of each bar by adding a geom_text element:\n\nplot_cars &lt;- PISA_2022 %&gt;% filter(!is.na(ST251Q01JA))\n\nggplot(data = plot_cars, \n       aes(x=ST251Q01JA, fill=OECD)) + \n  geom_bar(position=position_dodge()) + \n1  geom_text(stat='count',\n2            aes(label=after_stat(count)),\n3            position = position_dodge(width=0.9),\n4            vjust=-0.5)\n\n\n1\n\nline 6 starts the geom_text command, telling the geom to use the count statistic from ggplot, this means it will be able to fetch the number of rows in each grouping.\n\n2\n\nas we want the label to change for each bar element, we put label=after_stat(count) inside aes. The x location of the labels is inherited from line 4 and the y location will be calculated from the height of each bar\n\n3\n\nwe want the labels to align to the bars, so we tell the geom_text to also position_dodge, passing a width=0.9 to the dodge function, so the labels line up above the columns,\n\n4\n\nfinally, on line 9, we vertically adjust the labels vjust, so they sit on top of the columns.\n\n\n\n\n\n\n\n\n\n\n\nRather than adding the count, you might want to add the percentage that each bar represents, we can do this by changing the value given to label on line 5, below:\n\nggplot(data = plot_cars, \n       aes(x=ST251Q01JA, fill=OECD)) + \n  geom_bar(position=position_dodge()) +\n  geom_text(stat='count', \n            aes(label=100*(after_stat(count)/sum(after_stat(count))) %&gt;% round(3), \n            group = OECD), \n            position = position_dodge(width=0.9),\n            vjust=-0.5)",
    "crumbs": [
      "Making graphs"
    ]
  },
  {
    "objectID": "chapters/04-Intro_to_graphs.html#geom_point",
    "href": "chapters/04-Intro_to_graphs.html#geom_point",
    "title": "Making graphs",
    "section": "2.3 geom_point",
    "text": "2.3 geom_point\nTo plot a scatter plot, we use geom_point. For example, to plot reading scores against mathematics scores in the UK we: a) create a data set of reading and science scores after filtering for UK; b) pass the data to ggplot; c) use aes to specify the x and y variables and d) plot with geom_point().\n\n# Create a data.frame of the UK's science and reading scores\n\nUKplot &lt;- PISA_2022 %&gt;%\n  select(CNT, PV1READ, PV1SCIE) %&gt;%\n  filter(CNT == \"United Kingdom\")\n\n# Plot the data on a scatter graph using geom_point\n\nggplot(UKplot, aes(x = PV1READ, y = PV1SCIE)) +\n  geom_point()\n\n\n\n\n\n\n\n\nThat graph is quite dense, so we can use the alpha function to make the points slightly transparent, size to make them smaller, and set their colour. I will also tidy up the axis names and add a line (note that in: geom_smooth(method = \"lm\", colour = \"black\") method = \"lm\" sets the line to a straight (i.e., linear model, lm) line).\n\n# Create a data.frame of the UK's science and reading scores\n\nUKplot &lt;- PISA_2022 %&gt;%\n  select(CNT, PV1READ, PV1SCIE) %&gt;%\n  filter(CNT == \"United Kingdom\")\n\n# Plot the data on a scatter graph using geom_point\n\n4ggplot(UKplot, aes(x = PV1READ, y = PV1SCIE)) +\n5  geom_point(alpha = 0.6, size = 0.1, colour = \"red\") +\n6  xlab(\"Reading score\") +\n7  ylab(\"Science score\") +\n8  geom_smooth(method = \"lm\", colour = \"black\")\n\n\n4\n\nline 4 - set the data to plot and set which variable goes on the x and y axis\n\n5\n\nline 5 - set the point size (size=0.1), colour (colour = \"red\") and opacity (alpha = 0.6)\n\n6\n\nline 6 - set the x-axis title\n\n7\n\nline 7 - set the y-axis title\n\n8\n\nline 8 - plot a straight line (method = \"lm\") and set its colour to black\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nYou can set the colour of points using another variable inside the aesthetics. For example to change the colour of points by gender you can use aes(colour = ST004D01T) which gives the points for male and female students different colours.\n\n# Create a data.frame of the UK's science and reading scores\n\nUKplot &lt;- PISA_2022 %&gt;%\n  select(CNT, PV1READ, PV1SCIE, ST004D01T) %&gt;%\n  filter(CNT == \"United Kingdom\")\n\nggplot(UKplot, aes(x = PV1READ, y = PV1SCIE, colour = ST004D01T)) +             \n  geom_point(alpha = 0.6, size = 0.1) +     \n  xlab(\"Reading score\") +                                   \n  ylab(\"Science score\") +                                   \n  geom_smooth(method = \"lm\", colour = \"black\")     \n\n\n\n\n\n\n\n\nWhen you specify colours by a variable, ggplot with use the default colour palette (a red and a teal colour for two variables). To set your own choice of colours you can use scale_colour_manual(values = c()) linking the values of the varibale to colours. For example:\n\n# Create a data.frame of the UK's science and reading scores\n\nUKplot &lt;- PISA_2022 %&gt;%\n  select(CNT, PV1READ, PV1SCIE, ST004D01T) %&gt;%\n  filter(CNT == \"United Kingdom\")\n\nggplot(UKplot, aes(x = PV1READ, y = PV1SCIE, colour = ST004D01T)) +             \n  geom_point(alpha = 0.6, size = 0.1) +\n  scale_colour_manual(values = c(\"Male\" = \"red\", \"Female\" = \"blue\")) + # Manually change male points to red and female to blue\n  xlab(\"Reading score\") +                                   \n  ylab(\"Science score\") +                                   \n  geom_smooth(method = \"lm\", colour = \"black\")     \n\n\n\n\n\n\n\n\nNote that you need to match the aesthetic you want to change, if you are plotting a bar plot, where the aesthetic impacting the colour is fill (rather than the colour for geom_point above), you need to use scale_fill_manual(values = c(\"Male\" = \"red\", \"Female\" = \"blue\"))\n\n# Create a data.frame of the UK's science scores by gender\n\nUKplot &lt;- PISA_2022 %&gt;%\n  select(CNT, PV1SCIE, ST004D01T) %&gt;%\n  filter(CNT == \"United Kingdom\") %&gt;%\n  group_by(ST004D01T) %&gt;%\n  summarise(mean_sci = mean(PV1SCIE, na.rm = T))\n                            \n# Create a bar plot                            \nggplot(UKplot, aes(x = ST004D01T, y = mean_sci, fill = ST004D01T)) +             \n  geom_bar(stat = \"identity\", position = position_dodge2()) +\n  scale_fill_manual(values = c(\"Male\" = \"lightgreen\", \"Female\" = \"orange\"))  # Manually change bar fill\n\n\n\n\n\n\n\n\n\n\nAdditionally, when we make graphs we often want to label the data set, for example if we were to plot all the countries and their PV1MATH and PV1READ scores, we would get:\n\nplot_data &lt;- PISA_2022 %&gt;%\n  group_by(OECD, CNT) %&gt;%\n  summarise(m_read  = mean(PV1READ, na.rm=\"TRUE\"),\n            m_maths = mean(PV1MATH, na.rm=\"TRUE\"))\n\nggplot(data=plot_data, \n       aes(x=m_read, y=m_maths, colour=OECD)) +\n  geom_point() \n\n\n\n\n\n\n\n\nThis looks great, but we don’t actually know which countries are which. To get this data we need to add text to the graph, using geom_text.\n\nggplot(data=plot_data, \n       aes(x=m_read, y=m_maths, colour=OECD)) +\n  geom_point() +\n  geom_text(aes(label=CNT), \n            colour=\"black\", \n            check_overlap = TRUE)\n\n\n\n\n\n\n\n\nHere we have used colour=\"black\" outside the aes to define the colour for all the labels, and check_overlap = TRUE which removes any labels that are on top of each other. It’s still a little bit hard to understand, and maybe we want to focus on just a few of the labels for countries we are interested in. For example\n\n# make a vector of countries you want to have labels for\nfocus_cnt &lt;- c(\"United Kingdom\", \"France\", \"Argentina\")\n\n# add a new column to the plot_data where these countries are\nplot_data &lt;- plot_data %&gt;% mutate(focus = CNT %in% focus_cnt)\n\nplot_data\n\n# A tibble: 80 × 5\n# Groups:   OECD [2]\n   OECD  CNT                  m_read m_maths focus\n   &lt;fct&gt; &lt;fct&gt;                 &lt;dbl&gt;   &lt;dbl&gt; &lt;lgl&gt;\n 1 No    Albania                359.    368. FALSE\n 2 No    United Arab Emirates   420.    434. FALSE\n 3 No    Argentina              413.    389. TRUE \n 4 No    Bulgaria               405.    418. FALSE\n 5 No    Brazil                 415.    380. FALSE\n 6 No    Brunei Darussalam      428.    440. FALSE\n 7 No    Dominican Republic     354.    340. FALSE\n 8 No    Georgia                374.    390. FALSE\n 9 No    Guatemala              377.    346. FALSE\n10 No    Hong Kong (China)      504.    545. FALSE\n# ℹ 70 more rows\n\n\nNow we can adjust out geom_text to only show those countries that we want to focus on:\n\nggplot(data=plot_data, \n       aes(x=m_read, y=m_maths, colour=OECD)) +\n  geom_point() +\n1  geom_text(data=plot_data %&gt;% filter(focus == TRUE),\n2            aes(label=CNT),\n            colour=\"black\", \n            check_overlap = TRUE)\n\n\n1\n\nchanges the data that is being passed to the geom_text, it no longer uses the data defined in the ggplot command, but has a new dataset, that is filtered on focus == TRUE, i.e. only containing the countries that we want.\n\n2\n\nNote that the x and y mappings from line 2 are inherited by line 6, it’s only the data that we have redefined\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\ngeom_text is great, but you might find that ggrepel package useful as it’ll add lines connecting the text the data points. Using the plot_data from above:\n\nlibrary(ggrepel)\n\nggplot(data=plot_data, \n       aes(x=m_read, y=m_maths, colour=OECD)) +\n  geom_point() +\n  geom_text_repel(data=plot_data %&gt;% filter(focus == TRUE),\n            aes(label=CNT),\n            box.padding = 0.5,\n            max.overlaps = Inf,\n            colour=\"black\")\n\n\n\n\n\n\n\n\n\n\n\n2.3.1 Questions\n\n\nPlot a scatter graph of reading scores on the y-axis (PV1READ) against wealth (HOMEPOS) on the x-axis for students in the UK. Colour the points by gender, add a linear trend line and rename the axes and title\n\n\n\nanswer graph\nUKdata &lt;- PISA_2022 %&gt;%\n  select(PV1READ, CNT, HOMEPOS, ST004D01T) %&gt;%\n  filter(CNT == \"United Kingdom\")\n\nggplot(UKdata, aes(x = HOMEPOS, y = PV1READ, colour = ST004D01T)) + \n geom_point(size =0.1) +\n geom_smooth(method = \"lm\") +\n labs(x= \"Wealth\", y = \"Reading score\", title = \"UK reading vs wealth\")\n\n\n\nUsing the PISA_2022 dataset, plot a graph for students from Norway to look at the relationship between Home Possessions (WLE) HOMEPOS and reading grade PV1READ. Colour each point with the gender ST004D01T of the student. Give the graph sensible x and y labels by using xlab(\"label\") and ylab(\"label\")\n\n\n\nanswer dataframe\ngraph_data &lt;- PISA_2022 %&gt;% filter(CNT == \"Norway\")\n\n\n\n\nanswer graph\nggplot(graph_data,\n       aes(x=HOMEPOS,\n           y=PV1READ)) +\n  geom_point(aes(colour=ST004D01T)) +\n  xlab(\"Home possessions\") +\n  ylab(\"Reading grade\")\n\n\n\nUsing the PISA_2022 dataset for each country CNT, create a graph to explore how the median of the sense of school belonging BELONG relates to the median of the disciplinary climate in mathematics DISCLIM, adjust the colour of each point to reflect the mean of students in each country ESCS.\n\nHINT: You’ll need create a new data frame with summarised variables for median_belong, median_discipline and mean_wealth.\n\n\nanswer dataframe\ngraph_data &lt;- PISA_2022 %&gt;%\n  group_by(OECD, CNT) %&gt;%\n  summarise(median_belong = median(BELONG, na.rm=TRUE),\n            median_discipline = median(DISCLIM, na.rm=TRUE),\n            mean_wealth = mean(ESCS, na.rm=TRUE))\n\n\nHINT: To make your colours stand out more, add + scale_color_gradientn(colours = rainbow(3)) to the end of your plot.\n\n\nanswer graph\n# display a graph of the results\nggplot(data = graph_data, \n       aes(x = median_belong, \n           y = median_discipline)) +\n  geom_point(aes(colour = mean_wealth)) + \n  scale_color_gradientn(colours = rainbow(3))",
    "crumbs": [
      "Making graphs"
    ]
  },
  {
    "objectID": "chapters/04-Intro_to_graphs.html#geom_density",
    "href": "chapters/04-Intro_to_graphs.html#geom_density",
    "title": "Making graphs",
    "section": "2.4 geom_density",
    "text": "2.4 geom_density\nAn alternative type of plot is the density plot, which is a kind of continuous histogram. The density plot can be useful for visualising the achievement scores of students. For example, the mathematics scores of girls and boys (recall the gender variable is ST004D01T) in the US. We use na.omit to omit NAs. Notice, for the plot, I use aes to set my x variable, and then specify that the plot should fill by gender (fill=ST004D01T). Finally, in geom_density(alpha=0.6) I set the alpha to 0.6 to make the fill areas partially transparent.\n\n\n\n\n\n\nTip\n\n\n\nThe y-axis on a density plot is chosen so that the total area under the graph adds up to 1\n\n\n\n# Create a data.frame of US Math data including gender\n\nUSMathplot &lt;- PISA_2022 %&gt;%\n  select(CNT, PV1MATH, ST004D01T) %&gt;%\n  filter(CNT == \"United States\") %&gt;%\n  na.omit()\n\n# Plot a density chart, seeting the fill by gender, and setting the opacity to\n# 0.6 to show both gender plots\n\nggplot(USMathplot, aes(x = PV1MATH, fill = ST004D01T)) +\n  geom_density(alpha = 0.6)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nFor a summary of all the elements of a graph you can change in ggplot - see this help sheet.\n\n\n\n2.4.1 Questions\n\n\nPlot a density graph of maths scores for students in the UK, filling by gender.\n\n\n\nanswer graph\nUKdata &lt;- PISA_2022 %&gt;%\n  select(PV1MATH, CNT, ST004D01T) %&gt;%\n  filter(CNT == \"United Kingdom\")\n\nggplot(UKdata, aes(x = PV1MATH, fill = ST004D01T, alpha = 0.5)) + \n geom_density() +\n labs(x = \"Maths score\", title = \"UK maths score\", fill =\"gender\")\n\n\n\nCreate a dataframe of ESCS (social class data) for the countries: the UK, Brazil, Qatar and Jamaica. Plot the results as a density graph with a curve for each country.\n\n\n\nanswer graph\ncountry_data &lt;- PISA_2022 %&gt;%\n  select(CNT, ESCS) %&gt;%\n  filter(CNT == \"United Kingdom\" | CNT == \"Brazil\" | CNT == \"Qatar\" | CNT == \"Jamaica\")\n\nggplot(country_data, aes(x = ESCS, fill = CNT, alpha = 0.5)) + \n geom_density() +\n labs(x = \"ESCS (class)\", title = \"Distribution of class in 4 countries\", fill =\"country\")",
    "crumbs": [
      "Making graphs"
    ]
  },
  {
    "objectID": "chapters/04-Intro_to_graphs.html#exporting-plots",
    "href": "chapters/04-Intro_to_graphs.html#exporting-plots",
    "title": "Making graphs",
    "section": "3.1 Exporting plots",
    "text": "3.1 Exporting plots\nggplot can export data in a variety of formats suitable for printing, publication and the web. Once you have created a graph and stored it in an object my_graph &lt;- ggplot(..., the command to save the graph to your hard drive is:\nggsave(&lt;file_location_name_and_extension&gt;, &lt;object_name&gt;, width = 5, height = 4, device=&lt;file_ext&gt;)\n\nggsave(\"my_graph.pdf\", my_graph, width = 5, height = 4, device=\"pdf\")\n\nIf you want to change the output format, just change the extension of the file you are saving:\n\n“poverty_size.pdf” perfect for publication and printing, potentially large file size\n“poverty_size.svg” the same as pdf, also suitable for putting on webpages\n“poverty_size.png” smaller file size, suitable for websites and presentations\n“poverty_size.jpg” similar output to png",
    "crumbs": [
      "Making graphs"
    ]
  },
  {
    "objectID": "chapters/04-Intro_to_graphs.html#using-r-to-do-descriptive-statistics-and-plot-graphs",
    "href": "chapters/04-Intro_to_graphs.html#using-r-to-do-descriptive-statistics-and-plot-graphs",
    "title": "Making graphs",
    "section": "4.1 Using R to do descriptive statistics and plot graphs",
    "text": "4.1 Using R to do descriptive statistics and plot graphs\n\n\nYou can find the code used in the video below:\n\n\nShow the code\n# Introduction to plotting graphs\n#\n# Download data from /Users/k1765032/Library/CloudStorage/GoogleDrive-richardandrewbrock@gmail.com/.shortcut-targets-by-id/1c3CkaEBOICzepArDfjQUP34W2BYhFjM4/PISR/Data/PISA/subset/Students_2022_RBDP_none_levels.rds\n# You want the file: Students_2022_RBDP_none_levels.rds\n# and place in your own file system\n# change loc to load the data directly. Loading into R might take a few minutes\nlibrary(tidyverse)\nloc &lt;- \"/Users/k1765032/Library/CloudStorage/GoogleDrive-richardandrewbrock@gmail.com/.shortcut-targets-by-id/1c3CkaEBOICzepArDfjQUP34W2BYhFjM4/PISR/Data/PISA/subset/Students_2022_RBDP_none_levels.rds\"\nPISA_2022 &lt;- read_rds(loc)\n\n# Calculating means of groups\n# The PISA_2022 dataframe is piped to a new dataframe MeanPISA\n# The data are grouped by the country variable (CNT)\n# The countries of interest are chosen (UK, France, Germany and the US)\n# The summarise function is used to output the mean and standard deviation score for each country\n# on the Science Plausible Value (PV1SCIE) and NAs are ignored na.rm=TRUE\n\nMeanPISA &lt;- PISA_2022 %&gt;%\n  group_by(CNT)  %&gt;%\n  filter(CNT==\"United Kingdom\" | CNT== \"France\" | CNT== \"Germany\" | CNT==\"United States\")  %&gt;%\n  summarise(mean_sci = mean(PV1SCIE, na.rm=TRUE), sd_sci= sd(PV1SCIE, na.rm=TRUE)) \nprint(MeanPISA)\n\n\n# To plot data we can use the ggplot function. \n# We will start by plotting a column graph use geom_col\n# We specify the data set for ggplot to use (MeanPisa) and then \n# define the x and y variables:\n# ggplot(MeanPISA,\n#       aes(x=CNT, y=mean_sci))\n# geom_col() (Note the plus is on the line before) plots the graph and the fill colour is set to red\n# The next three lines set the formatting of the axis text and add x and y axis labels\n\nggplot(MeanPISA,\n       aes(x=CNT, y=mean_sci))+\ngeom_col(fill=\"red\") +\n  theme(axis.text.x = element_text(angle = 90, hjust=0.95, vjust=0.2, size=10)) +\n  xlab(\"Country\") +\n  ylab(\"Science Score\")\n\n# For plotting a scatter plot or PISA reading scores against science scores\n#, first we make a managable data set\n# I will filter the data set to include only the UK data\n# and remove any NAs\n\nUKData &lt;- PISA_2022 %&gt;%\n  filter(CNT==\"United Kingdom\") %&gt;%\n  drop_na(PV1SCIE)\n\n# This time I will use ggplot to plot a scatter graph\n# I feed UKDATA to ggplot, specify the x (PISA Reading score)\n# And y (PISA science score). This time, I have linked the colour\n# to a variable (ST004D01T) which is the gender value, giving\n# plot points of different colours for boys and girls\n# To produce a scatter plot, I use geom_point to plot points,\n# Giving the size of point and the transparency (alpha=0.5) -\n# some transparency of points is helpful when plots become dense\n# The x and y lables are added\n# Finally, a line is plotted - geom_smooth(method='lm')\n# sets the line to a linear ('lm') line\n\n  ggplot(UKData,\n       aes(x=PV1READ, y=PV1SCIE, colour=ST004D01T)) +\n  geom_point(size=0.1, alpha=0.5) +\n  ylab(\"Science Score\") +\n  xlab(\"Reading Score\") +\n  geom_smooth(method='lm')\n  \n# Where R becomes very powerful is being able to produce multiple charts rapidly\n# In the code below, I plot reading against science scores as above, but this time\n# Use the entire data set - for the whole world!\n# All the steps are the same, except, I use the facet_wrap, a way to create multiple\n# graph panels - the instruction creates a set of graphs for each country  \n  \n  WorldData &lt;- PISA_2022 %&gt;%\n    drop_na(PV1SCIE)\n  \n  ggplot(WorldData,\n         aes(x=PV1READ, y=PV1SCIE, colour=ST004D01T)) +\n    geom_point(size=0.1, alpha=0.5) +\n    ylab(\"Science Score\") +\n    xlab(\"Reading Score\") +\n    geom_smooth(method='lm') +\n    facet_wrap(CNT~.)",
    "crumbs": [
      "Making graphs"
    ]
  },
  {
    "objectID": "chapters/04-Intro_to_graphs.html#task-1---bar-graphs",
    "href": "chapters/04-Intro_to_graphs.html#task-1---bar-graphs",
    "title": "Making graphs",
    "section": "5.1 Task 1 - Bar graphs",
    "text": "5.1 Task 1 - Bar graphs\n\n\nST038Q08NA asks students in the past 12 months, how often do other students spread nasty rumours about them. Plot a graph of how often students spread rumours in the UK and France.\nExtensions: You can use xlab(\"&lt;x axis label&gt;\") and ylab(\"&lt;x axis label&gt;\") to label the axes. A title can be added using: ggtitle(\"&lt;title\"). ’You can rotate the text on the x axis through 90 degrees using: theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))\n\n\n\n\nAnswer\n# Select country and question data and Filter for the UK and France\nRumplot &lt;- PISA_2022 %&gt;%\n  select(CNT, ST038Q08NA) %&gt;%\n  filter(CNT == \"United Kingdom\"|CNT == \"France\")\n\n# use rumour data to create a graph\n# Set x as the item on culture and fill by the country\n# Remember to use position dodge to plot the bars side by side\nggplot(data = Rumplot,\n       aes(x = ST038Q08NA, fill = CNT)) +\n  geom_bar(position = \"dodge2\") +\n  xlab(\"Do students spread rumours about you?\") +\n  ylab(\"Count\")+\n  ggtitle(\"Spreading rumours: France vs. the UK\") +\n  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))\n  # Rotate axis text\n\n\n\n\nPA195Q01JA asks students how many books are in their home. Plot a bar graph for students in Germany. Then plot a graph splitting the data by gender (ST004D01T).\nHint: to split by bars by a variable use the aes(fill= &lt;variable&gt;).\n\n\n\n\nAnswer\n# Create a data set related to books in Germany and include gender\nBookplot &lt;- PISA_2022 %&gt;%\n  select(CNT, PA195Q01JA, ST004D01T) %&gt;%\n  filter(CNT == \"Germany\")\n\n# use book data to create a graph\nggplot(data = Bookplot,\n       aes(x = PA195Q01JA, fill=PA195Q01JA)) +\n  geom_bar(position = \"dodge2\") +\n  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))+ \n  # To rotate the x-axis text\n  xlab(\"Number of books in the home\")+\n  ylab(\"Count\")+\n  ggtitle(\"Number of books in the home for German students by gender\")\n\n# use fill by gender to split the data\nggplot(data = Bookplot,\n       aes(x = PA195Q01JA, fill = ST004D01T)) +\n  geom_bar(position = \"dodge2\") +\n  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))+ \n  # To rotate the x-axis text\n  xlab(\"Number of books in the home\")+\n  ylab(\"Count\")+\n  ggtitle(\"Number of books in the home for German students by gender\")\n\n\n\n\nPlot a bar graph of the mean science scores of all the countries in the PISA data frame\nHint one: you will need to create a summary dataframe using group_by and summarise and then geom_bar(stat=\"identity\"). Remember to use stat=identity when you want geom_bar to plot the values in the data.frame (because you have already summarised) rather than counting the values.\nHint two: you can reorder the x-axis with the reorder function. Rather than a simple x=CNT you can put x=reorder(CNT, -SciMean) which will reorder the x axis in descending order (because of the - sign) of SciMean.\n\n\n\n\nAnswer\n# Create a data set of science scores, and use group_by and summarise to create mean scores by country\n\nSciplot &lt;- PISA_2022 %&gt;%\n  select(CNT, PV1SCIE) %&gt;%\n  group_by(CNT)%&gt;%\n  summarise(MeanSci = mean(PV1SCIE))\n\n# Use geom_bar to plot the data\n\nggplot(data = Sciplot,\n       aes(x = reorder(CNT, -MeanSci), y = MeanSci, fill = MeanSci)) +\n  geom_bar(stat = \"identity\") +\n  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))",
    "crumbs": [
      "Making graphs"
    ]
  },
  {
    "objectID": "chapters/04-Intro_to_graphs.html#task-2---scatter-graphs",
    "href": "chapters/04-Intro_to_graphs.html#task-2---scatter-graphs",
    "title": "Making graphs",
    "section": "5.2 Task 2 - Scatter graphs",
    "text": "5.2 Task 2 - Scatter graphs\n\n\nFor students in the UK and Brazil, plot science scores (PV1SCIE) by the index of economic, social and cultural status (ESCS). (You may have come across this variable in your studies as socio-economic status, similar to the idea of ‘social class’.) Then try varying the colour of points by country, and add a line for each.\n\n\n\n\nAnswer\nplotdata&lt;-PISA_2022 %&gt;%\n  select(CNT, PV1SCIE, ESCS)%&gt;%\n  filter(CNT == \"United Kingdom\"|CNT == \"Brazil\")\n# Plot the data as a scatter graph with geom_point()\nggplot(data=plotdata,\n       aes(x = ESCS,y = PV1SCIE, colour = CNT)) +\n  geom_point(alpha = 0.2, size = 0.6)+\n  labs(x = \"Index of economic, social and cultural status\",\n       y = \"Science Score\")+\n  (geom_smooth(method = 'lm'))+\n  theme(legend.position = \"bottom\")+\n  labs(CNT = \"Country\") # Changes ST004D01T to gender for the plot\n\n\n\n\nFor students in the UK, plot a graph of science scores (PV1SCIE) against reading scores (PV1READ). Add a straight line and vary the colour of points by students’ gender.\n\n\n\n\nAnswer\nplotdata&lt;-PISA_2022 %&gt;%\n  select(CNT, PV1SCIE, PV1READ, ST004D01T) %&gt;%\n  filter(CNT == \"United Kingdom\")\n# Plot the data as a scatter graph with geom_point()\nggplot(data = plotdata,\n       aes(x = PV1READ, y = PV1SCIE, colour = ST004D01T)) +\n  geom_point(alpha = 0.6, size = 0.6) +\n  labs(x = \"Reading Score\", y = \"Science Score\") +\n  geom_smooth(method = 'lm') +\n  theme(legend.position = \"bottom\")+\n  labs(colour = \"Gender\") # Changes ST004D01T to gender for the plot\n\n\n\n\nChallenging task (!): Plot a graph of mean mathematics score (PV1MATH) by economic, social and cultural status (ESCS) and highlight countries with mathematics scores above 800. An outline of how to achieve this:\n\n\nCreate a data frame of mean PV1MATH and ESCS by country using group_by and summarise. (Don’t forget to use na.RM=TRUE)\nUse mutate and ifelse to add a new variable, called text which contains the names of countires with mathematics scores over 550.\nUse geom_label to add these data points to the x and y coordinates of the countries e.g. geom_text_repel(PV1MATHmean, ESCSmean, label).\n\n\n\n\nAnswer\n# Create a data frame of ESCS scores and mathematics scores\nplotdata&lt;-PISA_2022%&gt;%\n  select(CNT, ESCS, PV1MATH)%&gt;%\n  group_by(CNT)%&gt;% # group_by country\n  summarise(PV1MATHmean = mean(PV1MATH), #calculate means\n            ESCSmean = mean(ESCS, na.rm = TRUE))%&gt;%\n  mutate(text = ifelse(PV1MATHmean &gt; 550, as.character(CNT), \"\")) \n\n# Use mutate to create a newc columns called text\n# If PV1MATHmean is over 800 set text to equal CNT, otherwise set it to blank (\"\")\n\n# Plot the data, putting mean math score on y and ESCS mean on the x\n# Set the colour of points by the mean math score\n\nggplot(plotdata, aes(y=PV1MATHmean, x = ESCSmean, colour = PV1MATHmean))+\n  geom_point()+\n  geom_text_repel(aes(y = PV1MATHmean, x=ESCSmean, label = text))+\n  xlab(\"Mean ESCS score\")+\n  ylab(\"Mean mathematics score\")+\n  ggtitle(\"Comparison of mean mathematics and mean ESCS score\")+ \n  theme(legend.position = \"none\") # Hide the legend",
    "crumbs": [
      "Making graphs"
    ]
  },
  {
    "objectID": "chapters/04-Intro_to_graphs.html#task-3---plot-distributions-of-wealth-scores",
    "href": "chapters/04-Intro_to_graphs.html#task-3---plot-distributions-of-wealth-scores",
    "title": "Making graphs",
    "section": "5.3 Task 3 - Plot distributions of wealth scores",
    "text": "5.3 Task 3 - Plot distributions of wealth scores\n\nUse a scatter plot to show the correlation between HOMEPOS and ESCS. Use a facet_wrap to show the charts for the UK, Japan, Colombia and Sweden. Discuss the different relationships between the two variables across the countries.\n\n\n\n\n\n\n\nTip\n\n\n\nNote that the PISA variable, Economic, Social and Cultural Status ESCS is based on highest parental occupation (‘HISEI’), highest parental education (‘PARED’), and home possessions (‘HOMEPOS’), including books in the home. Do consider the implications of this definition.\n\n\n\n\nShow the answer\n# Create a data frame with the ESCS, gender (ST004D01T) and HOMEPOS variables for the 4 countries \n\nWealthcompPISA&lt;-PISA_2022 %&gt;%\n  select(CNT, ESCS, HOMEPOS, ST004D01T)%&gt;%\n  filter(CNT == \"Japan\" | CNT == \"United Kingdom\" | CNT == \"Colombia\" | CNT == \"Sweden\")\n\n# Use ggplot to create a scatter graph\n# Set the x variable to ESCS and the y to HOMEPOS, set the colour to gender\n# Set point size and transparency\n# Facet wrap to produce graphs for each country\n\nggplot(WealthcompPISA, aes(x = ESCS, y = HOMEPOS, colour=ST004D01T))+\n  geom_point(size=0.1, alpha=0.5)+\n  facet_wrap(.~CNT)",
    "crumbs": [
      "Making graphs"
    ]
  },
  {
    "objectID": "chapters/04-Intro_to_graphs.html#task-4---plot-distributions-of-scores",
    "href": "chapters/04-Intro_to_graphs.html#task-4---plot-distributions-of-scores",
    "title": "Making graphs",
    "section": "5.4 Task 4 - Plot distributions of scores",
    "text": "5.4 Task 4 - Plot distributions of scores\n\n\nUse geom_density to plot distributions to plot the distribution of Japanese and UK mathematics scores - what patterns do you notice?\n\n\n\n\n\n\n\n\nTip\n\n\n\nTo plot a distribution, you can use geom_density to plot a distribution curve. In ggplot you specify the data, and then in aes set the x-value (the variable of interest, and set the fill to change by different groups). Within the geom_density call you can specify the alpha, the opacity of the plot.\nFor example, to plot science scores in the UK by gender, you would use the code below:\n\n# Create a data frame of UK science scores including gender\n\nUKSci&lt;-PISA_2022 %&gt;%\n  select(CNT, PV1SCIE, ST004D01T) %&gt;%\n  filter(CNT == \"United Kingdom\")\n\n# Plot the density chart, changing colour by gender, and setting the alpha (opacity) to 0.5\nggplot(data = UKSci,\n       aes(x = PV1SCIE, fill = ST004D01T)) +\n  geom_density(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\n\nShow the answer\n# Create a data frame of UK and Japanese mathematics scores\n\nJPUKMath&lt;-PISA_2022 %&gt;%\n  select(CNT, PV1MATH) %&gt;%\n  filter(CNT == \"United Kingdom\"|CNT == \"Japan\")\n\n# Plot the density chart, changing colour by country, and setting the alpha (opacity) to 0.5\nggplot(data = JPUKMath,\n       aes(x = PV1MATH, fill = CNT)) +\n  geom_density(alpha = 0.5)",
    "crumbs": [
      "Making graphs"
    ]
  },
  {
    "objectID": "chapters/04-Intro_to_graphs.html#task-5---plot-distributions-of-scores-by-gender",
    "href": "chapters/04-Intro_to_graphs.html#task-5---plot-distributions-of-scores-by-gender",
    "title": "Making graphs",
    "section": "5.5 Task 5 - Plot distributions of scores by gender",
    "text": "5.5 Task 5 - Plot distributions of scores by gender\n\n\nExamine gender differences: Plot the distributions of mathematics achievement in the UK by gender. What patterns can you see?\n\n\n\n\nShow the answer\nUKMathGender &lt;- PISA_2022 %&gt;%\n  select(CNT, PV1MATH, ST004D01T) %&gt;%\n  filter(CNT == \"United Kingdom\")\n\nggplot(data = UKMathGender,\n       aes(x = PV1MATH, fill = ST004D01T)) +\n  geom_density(alpha = 0.5)",
    "crumbs": [
      "Making graphs"
    ]
  },
  {
    "objectID": "chapters/04-Intro_to_graphs.html#task-6---facet-wrap-by-country",
    "href": "chapters/04-Intro_to_graphs.html#task-6---facet-wrap-by-country",
    "title": "Making graphs",
    "section": "5.6 Task 6 - Facet wrap by country",
    "text": "5.6 Task 6 - Facet wrap by country\n\nPlot density graphs of gender differences in mathematics scores in the UK, Spain, Japan, Korea and Finland. Hint use facet_wrap(.~CNT)\n\n\n\nShow the answer\n# Create a data frame of mathematics scores, gender and country\n# Filter by the five countries of interest\n\nMathGender &lt;- PISA_2022 %&gt;%\n  select(CNT, PV1MATH, ST004D01T) %&gt;%\n  filter(CNT == \"United Kingdom\"|CNT == \"Spain\"|CNT == \"Japan\"\n         | CNT==\"Korea\"|CNT == \"Finland\")\n\n# Plot a density graph of mathematics scores, splitting into groups, with coloured fills by gender. Set transparency to 0.5 to show overlap \n\nggplot(data = MathGender,\n       aes(x = PV1MATH, fill = ST004D01T)) +\n  geom_density(alpha = 0.5) +\n  facet_wrap(.~CNT)",
    "crumbs": [
      "Making graphs"
    ]
  },
  {
    "objectID": "chapters/04-Intro_to_graphs.html#task-7---plot-a-scatter-graph",
    "href": "chapters/04-Intro_to_graphs.html#task-7---plot-a-scatter-graph",
    "title": "Making graphs",
    "section": "5.7 Task 7 - Plot a scatter graph",
    "text": "5.7 Task 7 - Plot a scatter graph\n\nPlot a scatter graph of mean mathematics achievement (y-axis) by mean wealth (x-axis) with each country as a single point. Hint: You will first need to use group_by and then summarise to create a data frame of mean scores.\n\n\n\n\n\n\n\nTip\n\n\n\nNote that the competency tests for Vietnam in PISA are all NA at the student level. This is because many students finish compulsory schooling before 15. Hence, we add an na.omit to remove the data from Vietnam\n\n\n\n\nShow the answer\n# Create a summary data frame\n# Group by country, and then summarise the mean meath and wealth scores\n\nWealthdata &lt;- PISA_2022 %&gt;%\n  select(CNT, HOMEPOS, PV1MATH) %&gt;%\n  filter(CNT!=\"Vietnam\")%&gt;%  # To cut Vietnam due to lack of data\n  group_by(CNT) %&gt;%\n  summarise(MeanWealth=mean(HOMEPOS, na.rm = TRUE),\n            MeanMath=mean(PV1MATH, na.rm = TRUE))\n\n# Use ggplot to create a scatter graph\n\nggplot(data = Wealthdata,\n       aes(x = MeanWealth, y = MeanMath)) +\n  geom_point(alpha = 0.5, colour=\"red\") +\n  xlab(\"Home Possessions (Wealth proxy)\") +\n  ylab(\"Mathematics score\")\n\n\n\n\n\n\n\n\n\n\nIn the previous scatter of mathematics vs wealth scores, highlight outlier countries (any score of over 500) in a different colour. Hint, mutate the data frame to include a label column (by the condition of the maths score being over 550). Then set the colour in ggplot by theis label column.\n\n\n\nShow the answer\n# Create a summary data frame\n# Group by country, and then summarise the mean math and wealth scores\n\nWealthdata &lt;- PISA_2022 %&gt;%\n  select(CNT, HOMEPOS, PV1MATH) %&gt;%\n  group_by(CNT) %&gt;%\n  filter(CNT!=\"Vietnam\")%&gt;%\n  summarise(MeanWealth = mean(HOMEPOS, na.rm = TRUE),\n            MeanMath = mean(PV1MATH, na.rm = TRUE)) %&gt;%\n  mutate(label=ifelse(MeanMath &gt; 500, \"Red\", \"Blue\")) # mutate to add a label\n# the column label is \"Red\" if MeanMath &gt; 500 and \"Blue\" otherwise\n\n# Use ggplot to create a scatter graph\n\nggplot(data = Wealthdata,\n       aes(x = MeanWealth, y = MeanMath, colour = label)) +\n  geom_point() +\n  xlab(\"Wealth\") +\n  ylab(\"Mathematics score\")\n\n\n\n\n\n\n\n\n\n\nAdd the country names as a label to the outliers. Hint: add an additional column labelname to which the country name as.charachter(CNT) is added if the MeanMath score is over 500. Hint: you can use geom_label_repel to add the labels. You can set: (aes(label = labelname), colour = \"black\", check_overlap = TRUE) to give the source of the lables (labelname) the colour and to force the lables not to overlap.\n\n\n\nShow the answer\n# Mutate to give a new column labelname, set to the country name (CNT) if Meanmath is over 500, or NA if not.\nWealthdata &lt;- PISA_2022 %&gt;%\n  select(CNT, HOMEPOS, PV1MATH) %&gt;%\n  group_by(CNT) %&gt;%\n  filter(CNT!=\"Vietnam\")%&gt;%\n  summarise(MeanWealth = mean(HOMEPOS, na.rm = TRUE),\n            MeanMath = mean(PV1MATH, na.rm = TRUE)) %&gt;%\n  mutate(label = ifelse(MeanMath&gt;500, \"Red\", \"Blue\")) %&gt;%\n  mutate(labelname = ifelse(MeanMath&gt;500, as.character(CNT), NA))\n  \n# Use geom_label_repel to add the labelname column to the graph\nggplot(data = Wealthdata,\n       aes(x = MeanWealth, y = MeanMath, colour = label)) +\n  geom_point() +\n  geom_label_repel(aes(label = labelname), \n            colour = \"black\", \n            check_overlap = TRUE) +\n  xlab(\"Wealth\") +\n  ylab(\"Mathematics score\")",
    "crumbs": [
      "Making graphs"
    ]
  },
  {
    "objectID": "chapters/04-Intro_to_graphs.html#task-8---plot-likert-responses-using-facet-wrapping",
    "href": "chapters/04-Intro_to_graphs.html#task-8---plot-likert-responses-using-facet-wrapping",
    "title": "Making graphs",
    "section": "5.8 Task 8 - Plot Likert responses using facet wrapping",
    "text": "5.8 Task 8 - Plot Likert responses using facet wrapping\n\nExamine Likert responses by country using facet plot.\nFor ST125Q01NA - How old were you when you started early childhood education? Plot responses, first, for the whole data set, then facet plot for the UK, Germany, Belgium, Austria, France, Poland, Estonia, Finland and Italy.\n• What international differences can you note?\n\n\n\nShow the answer\n# Create a data frame of childhood education data for the whole data frame \nChildhoodEd&lt;-PISA_2022 %&gt;%\n  select(CNT, ST125Q01NA) %&gt;%\n  group_by(CNT)\n\n# Plot a bar graph of responses  \n\nggplot(data = ChildhoodEd,\n       aes(x = ST125Q01NA, fill = ST125Q01NA)) +\n  geom_bar() +\n  xlab(\"How old were you when you started early childhood education?\") +\n  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))\n\n\n\n\n\n\n\n\n\nThen use faceting to split the plots by country\n\n\nShow the answer\n# Repeat filtering for UK, Germany, Belgium, Austria, France, Poland, Estonia, Finland and Italy\n\nChildhoodEd &lt;- PISA_2022 %&gt;%\n  select(CNT, ST125Q01NA) %&gt;%\n  filter(CNT == \"United Kingdom\"|CNT == \"Germany\" | CNT == \"Belgium\"\n         | CNT == \"Austria\"| CNT == \"France\" | CNT == \"Poland\"\n         | CNT == \"Estonia\" | CNT==\"Finland\"| CNT==\"Italy\")\n\n# Plot the data and facet wrap by country\n\nggplot(data = ChildhoodEd,\n       aes(x = ST125Q01NA, fill = CNT))+\n  geom_bar()+\n  xlab(\"How old were you when you started early childhood education?\") +\n  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1)) +\n  facet_wrap(. ~ CNT)",
    "crumbs": [
      "Making graphs"
    ]
  },
  {
    "objectID": "chapters/04-Intro_to_graphs.html#task-9---compare-the-association-between-mathematics-and-science-pv-values-across-three-diverse-countries",
    "href": "chapters/04-Intro_to_graphs.html#task-9---compare-the-association-between-mathematics-and-science-pv-values-across-three-diverse-countries",
    "title": "Making graphs",
    "section": "5.9 Task 9 - Compare the association between mathematics and science PV values across three diverse countries",
    "text": "5.9 Task 9 - Compare the association between mathematics and science PV values across three diverse countries\n\nPlot scatter plots of science versus mathematics achievement in United Kingdom, Qatar and Brazil • What differences can you see between the countries?\n\n\n\nShow the answer\n# Create a data frame of science and mathematics scores, across the countries Including gender)\n\nSciMaths &lt;- PISA_2022 %&gt;%\n  select(CNT, PV1MATH, PV1SCIE, ST004D01T) %&gt;%\n  filter(CNT == \"Colombia\" | CNT == \"New Zealand\" | CNT == \"Qatar\"|\n           CNT == \"Israel\") %&gt;%\n  droplevels()\n\n# Scatter plot the data, faceting by country\n\nggplot(data = SciMaths, \n       aes(x = PV1MATH, y = PV1SCIE, colour = ST004D01T))+\n  geom_point(size = 0.1, alpha = 0.5)+\n  facet_wrap(.~CNT)\n\n\n\n\n\n\n\n\n\nShow the answer\n# Low achieving (filter for scores less than 400)\n\nSciMaths &lt;- PISA_2022 %&gt;%\n  select(CNT, PV1MATH, PV1SCIE, ST004D01T) %&gt;%\n  filter(CNT == \"Colombia\" | CNT == \"New Zealand\" | CNT == \"Qatar\"|\n           CNT == \"Israel\") %&gt;%\n  filter(PV1MATH &lt; 400)%&gt;%\n  filter(PV1SCIE &lt; 400)%&gt;%\n  droplevels()\n\nggplot(data = SciMaths, \n       aes(x = PV1MATH, y = PV1SCIE, colour = ST004D01T))+\n  geom_point(size = 0.1, alpha = 0.5)+\n  facet_wrap(.~CNT)",
    "crumbs": [
      "Making graphs"
    ]
  },
  {
    "objectID": "chapters/04-Intro_to_graphs.html#task-1---binning-data",
    "href": "chapters/04-Intro_to_graphs.html#task-1---binning-data",
    "title": "Making graphs",
    "section": "6.1 Task 1 - Binning data",
    "text": "6.1 Task 1 - Binning data\nFrequency plots are often used to show data following a normal distribution, To produce a frequency plot, we need to divide data into counts, each covering a range of data. This is called ‘binning’. There is a choice to be made here, in how large or small to make the divisions (‘bins’) - this can affect how the data looks when graphed.\nFor example, to produce a frequency plot of science scores in the UK, we can first run a summary command on PV1SCIE to find the minimum and maximum score:\n\n# Find the range of science score\nsummary(PISA_2022$PV1SCIE)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n    0.0   371.7   444.5   450.5   524.7   895.4 \n\n\nIf we wanted to plot a frequency chart of heights, we might divide the range of scores (from 0-895.4) into bins of 20 points. To do this we can use the cut(&lt;field&gt;,&lt;breaks&gt;) function within the mutate command on a ‘data.frame’. The &lt;field&gt; specifies the range (i.e. from around 0-900) and &lt;breaks&gt; the size of bins.\nIn the example below, we use cut(PV1SCIE, breaks=seq(0,900,20)) to create a new vector (column in the table) with the science scores divided up into bins. The specification breaks=seq(0,900,20)) sets how the data are divided up - into bins (i.e. groups of respondents) of scores starting at 0 and rising to 900 in steps of 20.\n\n# Creates distribution of science scores\n\nbinnedsize &lt;- PISA_2022 %&gt;% # Creates a new data frame with binned data\n  select(PV1SCIE, CNT)%&gt;% # Select the columns needed\n  filter(CNT == \"United Kingdom\")%&gt;%\n  mutate(BinnedPV1SCIE = cut(PV1SCIE, breaks=seq(0, 900, 20)))%&gt;%\n  na.omit() # Drop any NAs\n\n# Plot the data as a bar graph\nggplot(binnedsize,\n       aes(x = BinnedPV1SCIE)) +\n  geom_bar(fill = \"dark green\") +\n  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1)) +\n  labs(y = \"Number of responses\", x = \"Scores range\")\n\n\n\n\n\n\n\n\n\nCreate a graph of the binned counts of mathematics scores in Malta. Don’t forget to run a summary command first to get a sense of the range in values.\n\n\n\n\n\n\n\nTip\n\n\n\nTo find out the range of a vector, you can use the range function in the console - for example, to get a sense of the range of science scores for the whole data frame, we can type: range(PISA_2022$PV1SCIE, na.rm=TRUE). Notice that, because there are NAs in the data, we need to tell the function to ignore them, using na.rm=TRUE.\n\n\n\n\nAnswer\n# Creates distribution of schools by size\nbinnedsize &lt;- PISA_2022 %&gt;% # Creates a new data frame with binned data\n  select(PV1MATH, CNT)%&gt;% # Select the column I need\n  filter(CNT == \"Malta\")%&gt;%\n  mutate(BinnedPV1MATH = cut(PV1MATH, breaks=seq(20,900,20)))%&gt;%\n  na.omit() # Drop any NAs\n# Plot the data as a bar graph\nggplot(binnedsize,\n       aes(x = BinnedPV1MATH)) +\n  geom_bar(fill = \"orange\") +\n  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1)) +\n  labs(y = \"Number of schools\", x = \"Pupil range\")\n\n\n\n\n\n\n\n\nTip\n\n\n\nTo find out a range of a vector, you can use the range function in the console - for example, to get a sense of the range of numbers of students on SEN support. I can type: range(DfE_SEN_data$SEN.support)\n\n\n\nPlot a binned geom_bar graph of the HOMEPOS scores in the UK and Belarus on the same axes.\n\n\n\nAnswer\n# Creates distribution of schools by size\nbinnedwealth &lt;- PISA_2022 %&gt;% # Creates a new data frame with binned data\n  select(HOMEPOS, CNT)%&gt;% # Select the column I need\n  filter(CNT == \"Belarus\"| CNT == \"United Kingdom\")%&gt;%\n  mutate(BinnedHOMEPOS = cut(HOMEPOS, breaks=seq(-8, 5, 0.25)))%&gt;%\n  na.omit() # Drop any NAs\n# Plot the data as a bar graph\nggplot(binnedwealth,\n       aes(x = BinnedHOMEPOS, fill = CNT)) +\n  geom_bar() +\n  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1)) +\n  labs(y = \"Frequency\", x = \"Wealth\")",
    "crumbs": [
      "Making graphs"
    ]
  },
  {
    "objectID": "chapters/04-Intro_to_graphs.html#task-2---histograms",
    "href": "chapters/04-Intro_to_graphs.html#task-2---histograms",
    "title": "Making graphs",
    "section": "6.2 Task 2 - Histograms",
    "text": "6.2 Task 2 - Histograms\nAn alternative to binning the data yourself is to use the geom_histogram geom in ggplot. That allows you to plot a histogram and control the size of the bins, without having to bin the data yourself. For example, to create a histogram of wealth scores in the UK, you set the x value in aesto wealth (HOMEPOS) and specify the binwidth within geom_histogram. You can also set a fill colour within the geom_histogram.\n\n# Creates data frame of wealth scores in the UK\nUK_wealth &lt;- PISA_2022 %&gt;% \n  select(HOMEPOS, CNT) %&gt;% # Select the columns needed\n  filter(CNT == \"United Kingdom\") # filter for the UK\n\n# Plot the data as a histogram \nggplot(UK_wealth,\n       aes(x = HOMEPOS)) +\n  geom_histogram(binwidth = 0.1, fill = \"dark green\") \n\n\n\n\n\n\n\n\n\nPlot a histogram of the PV1SCIE science scores for boys and girls in the UK and in Japan. Hint: You will need to use position = position_dodge2() inside the geom_histrogram to make sure the plots ovelap rather than stack.\n\n\n\nAnswer\n# Creates data frame of science scores in the UK and Japan\nSci_scores &lt;- PISA_2022 %&gt;% \n  select(PV1SCIE, CNT, ST004D01T) %&gt;% # Select the columns needed\n  filter(CNT == \"United Kingdom\" | CNT == \"Japan\")  # filter for the UK and Japan\n\n# Plot the data as a histogram \nggplot(Sci_scores,\n       aes(x = PV1SCIE, fill = ST004D01T)) +\n  geom_histogram(binwidth = 30, alpha = 0.5, position = position_dodge2()) +\n  facet_wrap(~CNT)",
    "crumbs": [
      "Making graphs"
    ]
  },
  {
    "objectID": "chapters/04-Intro_to_graphs.html#task-3---plotting-data-on-maps",
    "href": "chapters/04-Intro_to_graphs.html#task-3---plotting-data-on-maps",
    "title": "Making graphs",
    "section": "6.3 Task 3 - Plotting data on maps",
    "text": "6.3 Task 3 - Plotting data on maps\nAs well as graphs, R can also plot data onto maps. The geom_map function will plot a map of a region and you can either plot points (using geom_point) or fill regions by drawing a polygon of the shape of that region (using geom_polygon).\nFor example, imagine we created a data frame of the mean science scores of countries in the PISA data:\n\n# Pipe the total data frame and calculate the mean science scores\n# To match with another data frame we will use, we will rename CNT to region\nWorldSci &lt;- PISA_2022 %&gt;%\n  select(CNT, PV1SCIE) %&gt;%\n  group_by(CNT) %&gt;%\n  summarise(meanSci = mean(PV1SCIE)) %&gt;%\n  rename(region = CNT)\n\nIn order to plot the data onto a map, colouring the countries by science scores, we need data which gives the coordinates of the edges of the countries. This data is available from the map_data function in ggplot. First we load the latitude and longitude data into a new data frame world_data. In the next steps we will then use left_join to combine it with the science data, but we need to tidy the data to match the PISA data, before we can join the two data sets.\n\n# Create a data frame of country latitude and longitude data\nworld_data &lt;- map_data(map = \"world\")\n\nOne quirk of the two data frames (world_data and the PISA data) is that some countries have different names. For example, PISA uses ‘United Kingdom’, but the rworldmap package uses ‘UK’. We can change the names of countries in the PISA data.frame to match those in rworldmap, using the case_when function with mutate. For example, if we want to change all United Kingdom entries to UK we use: mutate(region = case_when(region == \"United Kingdom\" ~ \"UK\". The final part of the case_when sets the default - .default = region - that means if none of the matches are found, then region is set to region - i.e. it is left unchanged.\n\n# The names of two countries in the PISA data frame and world_data data frame don't match (UK/United Kingdom and US/United States). Change the level names in the PISA data to match the world_data\n\n WorldSci &lt;- WorldSci %&gt;%\n   mutate(region = case_when(\n                       region == \"United Kingdom\" ~ \"UK\",\n                       region == \"United States\"  ~ \"USA\",\n                       .default = region))\n\nNow that the country names in the two data frames match, we can use left_join to combine them.\n\n# Add the country latitude and longitude data to the PISA scores\n\nWorldSci &lt;- left_join(WorldSci, world_data, by = \"region\")\n\nTo add labels, you can create a data.frame, with only the country names, and their longitudes and latitudes (the mean of the country longitude and latitude), to use as the labels. You can then add geom_text_repelto add the labels. The repel means the labels won’t overlap. Given the number of countries, using geom_text_repel creates a warning that some labels won’t fit.\nTo plot the data, we use ggplot, with the data frame to WorldSci, and the x and y variables set to long and lat, the longitudes and latitudes. We specify that we want to keep the grouping of the data frame (i.e. by country).\nFirst we use geom_map to plot a blank map using the data - this will be the base for the highlighted countries. In the aes we give the longitudes and latitudes, and, as we want a blank map, set the fill to white and the line colour to black.\nFinally, we use geom_polygon to draw coloured shapes, with the fill changing by the value of meanSci. To make the map look nice, I have used a pre-defined colour scale.\n\n# Use geom_map to plot the basic world map (fill is white, line colour is black)\n# Use geom_polygon to plot the PISA data\n# Add a colour scale\nggplot(data = WorldSci, aes(x = long, y = lat, group=group)) +\n  geom_map(data = world_data, \n           map = world_data, \n           aes(map_id = region), \n           fill = \"white\", \n           colour = \"black\")+\n  geom_polygon(aes(fill = meanSci)) +\n  scale_fill_viridis_c(option = \"viridis\")\n\n\n\n\n\n\n\n\nIn ggplot, by default, the aesthetics are passed from one layer to the next. In our first aes call we set a grouping (group=group). However, when we come to the labeling function geom_text_repel, the data frame Labels is not grouped. We therefore need to use new aesthetics and want to ignore the original aesthetics (aes(x=long, y=lat, group=group,label=region))) we previously set.We do this with the command inherit.aes = FALSE (i.e. do not inherit the previous aesthetics).\nTo neaten up the labels we use the ggrepel package to get the geom_text_repel function. You’ll need to make sure that you have installed the ggrepel package, for a reminder on how to install packages see ?@sec-installation. This ensures that text labels don’t overlap. Then in geom_text_repel(data=Labels, inherit.aes = FALSE, aes(x=long, y=lat,label=region)) we specify the label data.frame, and in aes pass the positions of the labels (x=long, y=lat) and specify that the labels are in the region vector.\n\nlibrary(ggrepel)\n\nggplot(data = WorldSci, \n       aes(x = long, y = lat, group = group,label = region)) +\n  geom_map(data = world_data,\n           map = world_data, \n           aes(map_id = region), \n           fill = \"white\",\n           colour = \"black\")+\n  geom_polygon(aes(fill = meanSci)) +\n  scale_fill_viridis_c(option = \"viridis\") +\n  geom_text_repel(data = Labels,\n                 inherit.aes = FALSE,\n                 aes(x = long, y = lat, label = region))\n\n\n\n\n\n\n\n\n\nPlot mean PISA mathematics scores on a world map, labelling the countries.\n\n\n\nAnswer\n# Create a data.frame of mathematics scores\nWorldMath &lt;- PISA_2022 %&gt;%\n  select(CNT, PV1MATH) %&gt;%\n  group_by(CNT) %&gt;%\n  summarise(meanmath = mean(PV1MATH)) %&gt;%\n  rename(region = CNT)\n# The names of two countries in the PISA data frame and world_data data frame don't match (UK/United Kingdom and US/United States). Change the level names in the PISA data to match the world_data\n\nWorldMath &lt;- WorldMath %&gt;%\n   mutate(region = case_when(\n                       region == \"United Kingdom\" ~ \"UK\",\n                       region == \"United States\"  ~ \"USA\",\n                       region == \"Russian Federation\" ~ \"Russia\",\n                       .default = region))\n\n# Create a data frame of country latitude and longitude data\nworld_data &lt;- map_data(map = \"world\")\n\nWorldMath &lt;- left_join(WorldMath, world_data, by = \"region\")\n\n# Use geom_map to plot the basic world map (fill is white, line colour is black)\n# Use geom_polygon to plot the PISA data\n# Add a colour scale\n\nLabels&lt;-WorldMath%&gt;%\n  group_by(region)%&gt;%\n  summarise(meanmath = mean(meanmath), lat = mean(lat), long = mean(long))%&gt;%\n  na.omit()\n\n# Use geom_map to plot the basic world map (fill is white, line colour is black)\n# Use geom_polygon to plot the PISA data\n# Add a colour scale\nggplot(data = WorldMath, \n       aes(x = long, y = lat, group = group,label = region)) +\n  geom_map(data = world_data,\n           map = world_data, \n           aes(map_id = region), \n           fill = \"white\",\n           colour = \"black\")+\n  geom_polygon(aes(fill = meanmath)) +\n  scale_fill_viridis_c(option = \"viridis\") +\n  geom_text_repel(data = Labels,\n                 inherit.aes = FALSE,\n                 aes(x = long, y = lat, label = region))",
    "crumbs": [
      "Making graphs"
    ]
  },
  {
    "objectID": "chapters/04-Intro_to_graphs.html#task-4---violin-plots",
    "href": "chapters/04-Intro_to_graphs.html#task-4---violin-plots",
    "title": "Making graphs",
    "section": "6.4 Task 4 - Violin plots",
    "text": "6.4 Task 4 - Violin plots\nViolin plots are a useful way of showing the distribution of scores across different items. They can make distributions easy to compare, at a glance, and to give a sense of the relative frequency of different scores. In ggplot you can use geom_violin to produce plots. For example, you can compare the distribution of science scores in Spain and Portugal by gender (note the relatively long tail at the bottom of #####):\n\n# Create a data frame of Spain and Portugal science scores including gender\nPISAsubset &lt;- PISA_2022%&gt;%\n  select(CNT, PV1SCIE, ST004D01T)%&gt;%\n  filter(CNT == \"Spain\" | CNT == \"Portugal\")\n\n# Set up the country on the x axis, and score on the y, setting colour by gender\nggplot(PISAsubset, aes(x=CNT, y=PV1SCIE, fill=ST004D01T))+\n  geom_violin()+\n  xlab(\"Country\")+\n  ylab(\"Science Score\")\n\n\n\n\n\n\n\n\nYou can rotate the plot using +coord_flip() and add black dots for the mean using: stat_summary(fun = \"mean\", geom = \"point\", color = \"black\"). You can also try geom= \"crossbar\". Because we have two groups (male and female), we need to add position = position_dodge(width=0.9) to make the dots appear in the right place\n\n# Create a data frame of country science scores including gender\n\nPISAsubset&lt;-PISA_2022%&gt;%\n  select(CNT, PV1SCIE, ST004D01T)%&gt;%\n  filter(CNT == \"United Kingdom\" | CNT == \"Ireland\" |\n         CNT == \"Qatar\" | CNT == \"Brazil\" | CNT == \"Kazakhstan\" |\n           CNT == \"Korea\" | CNT == \"Panama\")\n\n# Set up the country on the x axis, and score on the y, setting colour by gender, flip the axes and add points for the mean\n\nggplot(PISAsubset, aes(x = CNT, y = PV1SCIE, fill = ST004D01T))+\n  geom_violin()+\n  xlab(\"Country\")+\n  ylab(\"Science Score\")+\n  coord_flip()+\n  stat_summary(fun = \"mean\", geom = \"point\", color = \"black\",\n               position = position_dodge(width=0.9))\n\n\n\n\n\n\n\n\n\nPlot violin plots of PISA HOMEPOS scores, by gender, for the UK, US, Sweden and Finland.\n\n\n\nAnswer\n# Create a data frame of WEALTH scores for the 4 countries including gender\nPISAsubset&lt;-PISA_2022%&gt;%\n  select(CNT, HOMEPOS, ST004D01T)%&gt;%\n  filter(CNT == \"United Kingdom\" | CNT == \"Sweden\" | \n           CNT == \"Finland\" | CNT == \"United States\")\n\n# Set up the country on the x axis, and score on the y, setting colour by gender\nggplot(PISAsubset, aes(x=CNT, y=HOMEPOS, fill=ST004D01T))+\n  geom_violin()+\n  xlab(\"Country\")+\n  ylab(\"PISA Wealth measure\")",
    "crumbs": [
      "Making graphs"
    ]
  }
]